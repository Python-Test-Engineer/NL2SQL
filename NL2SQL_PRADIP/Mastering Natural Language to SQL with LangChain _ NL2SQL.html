<!DOCTYPE html>
<!-- saved from url=(0083)https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql -->
<html lang="en" data-theme="light" class=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="image" property="og:image" content="https://hashnode.com/utility/r?url=https%3A%2F%2Fcdn.hashnode.com%2Fres%2Fhashnode%2Fimage%2Fupload%2Fv1710152478787%2Fe57074e2-3303-46ec-8491-11f60aa0bd2d.png%3Fw%3D1200%26h%3D630%26fit%3Dcrop%26crop%3Dentropy%26auto%3Dcompress%2Cformat%26format%3Dwebp%26fm%3Dpng"><link rel="canonical" href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql"><title>Mastering Natural Language to SQL with LangChain | NL2SQL</title><meta name="description" content="Unlock the full potential of database interactions with our guide on Natural Language to SQL using LangChain and LLM."><meta property="og:title" content="Mastering Natural Language to SQL with LangChain | NL2SQL"><meta property="og:description" content="Unlock the full potential of database interactions with our guide on Natural Language to SQL using LangChain and LLM."><meta property="og:site_name" content="FutureSmart AI Blog"><meta property="og:type" content="article"><meta property="og:url" content="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql"><meta name="author" content="Pradip Nichite"><meta property="article:author" content="https://hashnode.com/@pnichite"><link rel="author" href="https://hashnode.com/@pnichite"><link rel="apple-touch-icon" sizes="180x180" href="https://cdn.hashnode.com/res/hashnode/image/upload/v1611242155728/W3_BYVVVh.png"><link rel="icon" type="image/png" sizes="32x32" href="https://cdn.hashnode.com/res/hashnode/image/upload/v1611242173172/AOX1gE2jc.png"><link rel="icon" type="image/png" sizes="16x16" href="https://cdn.hashnode.com/res/hashnode/image/upload/v1611242187756/TRTNYp32O.png"><link rel="mask-icon" href="https://blog.futuresmart.ai/static/images/brand/safari-pinned-tab-new.svg" color="#2962ff"><meta name="msapplication-TileColor" content="#ffffff"><meta name="theme-color" content="#2962FF"><meta name="google-site-verification" content="hjDPYL5JIhkWAQpDvFOQHPr81ODcsYielMtN-_oZQSg"><meta property="twitter:card" content="summary_large_image"><meta property="twitter:title" content="Mastering Natural Language to SQL with LangChain | NL2SQL"><meta property="twitter:description" content="Unlock the full potential of database interactions with our guide on Natural Language to SQL using LangChain and LLM."><meta property="twitter:image" content="https://hashnode.com/utility/r?url=https%3A%2F%2Fcdn.hashnode.com%2Fres%2Fhashnode%2Fimage%2Fupload%2Fv1710152478787%2Fe57074e2-3303-46ec-8491-11f60aa0bd2d.png%3Fw%3D1200%26h%3D630%26fit%3Dcrop%26crop%3Dentropy%26auto%3Dcompress%2Cformat%26format%3Dwebp%26fm%3Dpng"><style>/* Monkai theme */
          .hljs{display:block;overflow-x:auto;padding:.5em;background:#23241f}.hljs,.hljs-subst,.hljs-tag{color:#f8f8f2}.hljs-emphasis,.hljs-strong{color:#a8a8a2}.hljs-bullet,.hljs-link,.hljs-literal,.hljs-number,.hljs-quote,.hljs-regexp{color:#ae81ff}.hljs-code,.hljs-section,.hljs-selector-class,.hljs-title{color:#a6e22e}.hljs-strong{font-weight:700}.hljs-emphasis{font-style:italic}.hljs-attr,.hljs-keyword,.hljs-name,.hljs-selector-tag{color:#f92672}.hljs-attribute,.hljs-symbol{color:#66d9ef}.hljs-class .hljs-title,.hljs-params{color:#f8f8f2}.hljs-addition,.hljs-built_in,.hljs-builtin-name,.hljs-selector-attr,.hljs-selector-id,.hljs-selector-pseudo,.hljs-string,.hljs-template-variable,.hljs-type,.hljs-variable{color:#e6db74}.hljs-comment,.hljs-deletion,.hljs-meta{color:#75715e}
            /* Monkai theme ends */</style><link rel="alternate" type="application/rss+xml" title="RSS Feed for Mastering Natural Language to SQL with LangChain | NL2SQL" href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql/rss.xml"><link rel="preload" as="image" href="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/e57074e2-3303-46ec-8491-11f60aa0bd2d.png"><style>:root { --color-custom-header: #2962FF; }</style><meta name="next-head-count" content="29"><style>#nprogress{pointer-events:none}#nprogress .bar{background:#29d;position:fixed;z-index:1031;top:0;left:0;width:100%;height:2px}#nprogress .peg{display:block;position:absolute;right:0;width:100px;height:100%;box-shadow:0 0 10px #29d,0 0 5px #29d;opacity:1;-webkit-transform:rotate(3deg) translate(0,-4px);-ms-transform:rotate(3deg) translate(0,-4px);transform:rotate(3deg) translate(0,-4px)}#nprogress .spinner{display:block;position:fixed;z-index:1031;top:15px;right:15px}#nprogress .spinner-icon{width:18px;height:18px;box-sizing:border-box;border:solid 2px transparent;border-top-color:#29d;border-left-color:#29d;border-radius:50%;-webkit-animation:nprogress-spinner .4s linear infinite;animation:nprogress-spinner .4s linear infinite}.nprogress-custom-parent{overflow:hidden;position:relative}.nprogress-custom-parent #nprogress .bar,.nprogress-custom-parent #nprogress .spinner{position:absolute}@-webkit-keyframes nprogress-spinner{0%{-webkit-transform:rotate(0)}100%{-webkit-transform:rotate(360deg)}}@keyframes nprogress-spinner{0%{transform:rotate(0)}100%{transform:rotate(360deg)}}</style><script type="text/javascript" async="" src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/js"></script><script src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/iframe-resizer.js.download" async="" defer=""></script><script async="" src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/js(1)"></script><script type="text/javascript">
    window.dataLayer = window.dataLayer || [];
    function gtag(){window.dataLayer.push(arguments);}
    gtag('js', new Date());
  </script><link rel="preload" href="https://blog.futuresmart.ai/_next/static/media/a34f9d1faa5f3315-s.p.woff2" as="font" type="font/woff2" crossorigin="anonymous" data-next-font="size-adjust"><link rel="preload" href="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/883f46e254373107.css" as="style"><link rel="stylesheet" href="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/883f46e254373107.css" data-n-g=""><noscript data-n-css=""></noscript><script defer="" nomodule="" src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/polyfills-c67a75d1b6f99dc8.js.download"></script><script defer="" src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/8820-56721d947d773244.js.download"></script><script defer="" src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/3364-87c2ffca7936c855.js.download"></script><script defer="" src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/8226.64bcf70d809f2c9f.js.download"></script><script defer="" src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/5950-ac4ab424aa3bdc31.js.download"></script><script defer="" src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/7179.58a3a6a905ed3c5b.js.download"></script><script src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/webpack-21840d9d34b4ca26.js.download" defer=""></script><script src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/framework-ce84985cd166733a.js.download" defer=""></script><script src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/main-7636331dc094a8a9.js.download" defer=""></script><script src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/_app-9b7e51f28796fc05.js.download" defer=""></script><script src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/0b5ea8d6-208c5eca82a94965.js.download" defer=""></script><script src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/6365-3d0e1852af604b43.js.download" defer=""></script><script src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/6933-f312215db97b5535.js.download" defer=""></script><script src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/[...slug]-0670863b9e4a6e11.js.download" defer=""></script><script src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/_buildManifest.js.download" defer=""></script><script src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/_ssgManifest.js.download" defer=""></script><style id="__jsx-668768712">@font-face{font-family:"Suisse Intl";src:url("/fonts/SuisseIntl-Book-WebXL.woff2")format("woff2"),url("/fonts/SuisseIntl-Book-WebXL.woff")format("woff");font-weight:450;font-style:normal;font-display:block}@font-face{font-family:"Suisse Intl";src:url("/fonts/SuisseIntl-Medium-WebXL.woff2")format("woff2"),url("/fonts/SuisseIntl-Medium-WebXL.woff")format("woff");font-weight:500;font-style:normal;font-display:block}@font-face{font-family:"Suisse Intl";src:url("/fonts/SuisseIntl-SemiBold-WebXL.woff2")format("woff2"),url("/fonts/SuisseIntl-SemiBold-WebXL.woff")format("woff");font-weight:600;font-style:normal;font-display:block}@font-face{font-family:"Suisse Intl";src:url("/fonts/SuisseIntl-Bold-WebXL.woff2")format("woff2"),url("/fonts/SuisseIntl-Bold-WebXL.woff")format("woff");font-weight:700;font-style:normal;font-display:block}html{--font-inter:__Inter_a184c8;--font-suisse-intl:'Suisse Intl';--font-mermaid:var(--font-inter)}</style><style type="text/css">html[dir=ltr],[data-sonner-toaster][dir=ltr]{--toast-icon-margin-start: -3px;--toast-icon-margin-end: 4px;--toast-svg-margin-start: -1px;--toast-svg-margin-end: 0px;--toast-button-margin-start: auto;--toast-button-margin-end: 0;--toast-close-button-start: 0;--toast-close-button-end: unset;--toast-close-button-transform: translate(-35%, -35%)}html[dir=rtl],[data-sonner-toaster][dir=rtl]{--toast-icon-margin-start: 4px;--toast-icon-margin-end: -3px;--toast-svg-margin-start: 0px;--toast-svg-margin-end: -1px;--toast-button-margin-start: 0;--toast-button-margin-end: auto;--toast-close-button-start: unset;--toast-close-button-end: 0;--toast-close-button-transform: translate(35%, -35%)}[data-sonner-toaster]{position:fixed;width:var(--width);font-family:ui-sans-serif,system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji;--gray1: hsl(0, 0%, 99%);--gray2: hsl(0, 0%, 97.3%);--gray3: hsl(0, 0%, 95.1%);--gray4: hsl(0, 0%, 93%);--gray5: hsl(0, 0%, 90.9%);--gray6: hsl(0, 0%, 88.7%);--gray7: hsl(0, 0%, 85.8%);--gray8: hsl(0, 0%, 78%);--gray9: hsl(0, 0%, 56.1%);--gray10: hsl(0, 0%, 52.3%);--gray11: hsl(0, 0%, 43.5%);--gray12: hsl(0, 0%, 9%);--border-radius: 8px;box-sizing:border-box;padding:0;margin:0;list-style:none;outline:none;z-index:999999999}[data-sonner-toaster][data-x-position=right]{right:max(var(--offset),env(safe-area-inset-right))}[data-sonner-toaster][data-x-position=left]{left:max(var(--offset),env(safe-area-inset-left))}[data-sonner-toaster][data-x-position=center]{left:50%;transform:translate(-50%)}[data-sonner-toaster][data-y-position=top]{top:max(var(--offset),env(safe-area-inset-top))}[data-sonner-toaster][data-y-position=bottom]{bottom:max(var(--offset),env(safe-area-inset-bottom))}[data-sonner-toast]{--y: translateY(100%);--lift-amount: calc(var(--lift) * var(--gap));z-index:var(--z-index);position:absolute;opacity:0;transform:var(--y);touch-action:none;will-change:transform,opacity,height;transition:transform .4s,opacity .4s,height .4s,box-shadow .2s;box-sizing:border-box;outline:none;overflow-wrap:anywhere}[data-sonner-toast][data-styled=true]{padding:16px;background:var(--normal-bg);border:1px solid var(--normal-border);color:var(--normal-text);border-radius:var(--border-radius);box-shadow:0 4px 12px #0000001a;width:var(--width);font-size:13px;display:flex;align-items:center;gap:6px}[data-sonner-toast]:focus-visible{box-shadow:0 4px 12px #0000001a,0 0 0 2px #0003}[data-sonner-toast][data-y-position=top]{top:0;--y: translateY(-100%);--lift: 1;--lift-amount: calc(1 * var(--gap))}[data-sonner-toast][data-y-position=bottom]{bottom:0;--y: translateY(100%);--lift: -1;--lift-amount: calc(var(--lift) * var(--gap))}[data-sonner-toast] [data-description]{font-weight:400;line-height:1.4;color:inherit}[data-sonner-toast] [data-title]{font-weight:500;line-height:1.5;color:inherit}[data-sonner-toast] [data-icon]{display:flex;height:16px;width:16px;position:relative;justify-content:flex-start;align-items:center;flex-shrink:0;margin-left:var(--toast-icon-margin-start);margin-right:var(--toast-icon-margin-end)}[data-sonner-toast][data-promise=true] [data-icon]>svg{opacity:0;transform:scale(.8);transform-origin:center;animation:sonner-fade-in .3s ease forwards}[data-sonner-toast] [data-icon]>*{flex-shrink:0}[data-sonner-toast] [data-icon] svg{margin-left:var(--toast-svg-margin-start);margin-right:var(--toast-svg-margin-end)}[data-sonner-toast] [data-content]{display:flex;flex-direction:column;gap:2px}[data-sonner-toast] [data-button]{border-radius:4px;padding-left:8px;padding-right:8px;height:24px;font-size:12px;color:var(--normal-bg);background:var(--normal-text);margin-left:var(--toast-button-margin-start);margin-right:var(--toast-button-margin-end);border:none;cursor:pointer;outline:none;transition:opacity .4s,box-shadow .2s}[data-sonner-toast] [data-button]:focus-visible{box-shadow:0 0 0 2px #0006}[data-sonner-toast] [data-button]:first-of-type{margin-left:var(--toast-button-margin-start);margin-right:var(--toast-button-margin-end)}[data-sonner-toast] [data-cancel]{color:var(--normal-text);background:rgba(0,0,0,.08)}[data-sonner-toast][data-theme=dark] [data-cancel]{background:rgba(255,255,255,.3)}[data-sonner-toast] [data-close-button]{position:absolute;left:var(--toast-close-button-start);right:var(--toast-close-button-end);top:0;height:20px;width:20px;display:flex;justify-content:center;align-items:center;padding:0;background:var(--gray1);color:var(--gray12);border:1px solid var(--gray4);transform:var(--toast-close-button-transform);border-radius:50%;opacity:0;cursor:pointer;z-index:1;transition:opacity .1s,background .2s,border-color .2s}[data-sonner-toast] [data-close-button]:focus-visible{box-shadow:0 4px 12px #0000001a,0 0 0 2px #0003}[data-sonner-toast] [data-disabled=true]{cursor:not-allowed}[data-sonner-toast]:hover [data-close-button]{opacity:1}[data-sonner-toast]:focus [data-close-button]{opacity:1}[data-sonner-toast]:focus-within [data-close-button]{opacity:1}[data-sonner-toast]:hover [data-close-button]:hover{background:var(--gray2);border-color:var(--gray5)}[data-sonner-toast][data-swiping=true]:before{content:"";position:absolute;left:0;right:0;height:100%}[data-sonner-toast][data-y-position=top][data-swiping=true]:before{bottom:50%;transform:scaleY(3) translateY(50%)}[data-sonner-toast][data-y-position=bottom][data-swiping=true]:before{top:50%;transform:scaleY(3) translateY(-50%)}[data-sonner-toast][data-swiping=false][data-removed=true]:before{content:"";position:absolute;inset:0;transform:scaleY(2)}[data-sonner-toast]:after{content:"";position:absolute;left:0;height:calc(var(--gap) + 1px);bottom:100%;width:100%}[data-sonner-toast][data-mounted=true]{--y: translateY(0);opacity:1}[data-sonner-toast][data-expanded=false][data-front=false]{--scale: var(--toasts-before) * .05 + 1;--y: translateY( calc(var(--lift-amount) * var(--toasts-before)) ) scale(calc(-1 * var(--scale)));height:var(--front-toast-height)}[data-sonner-toast]>*{transition:opacity .4s}[data-sonner-toast][data-expanded=false][data-front=false][data-styled=true]>*{opacity:0}[data-sonner-toast][data-visible=false]{opacity:0;pointer-events:none}[data-sonner-toast][data-mounted=true][data-expanded=true]{--y: translateY(calc(var(--lift) * var(--offset)));height:var(--initial-height)}[data-sonner-toast][data-removed=true][data-front=true][data-swipe-out=false]{--y: translateY(calc(var(--lift) * -100%));opacity:0}[data-sonner-toast][data-removed=true][data-front=false][data-swipe-out=false][data-expanded=true]{--y: translateY( calc(var(--lift) * var(--offset) + var(--lift) * -100%) );opacity:0}[data-sonner-toast][data-removed=true][data-front=false][data-swipe-out=false][data-expanded=false]{--y: translateY(40%);opacity:0;transition:transform .5s,opacity .2s}[data-sonner-toast][data-removed=true][data-front=false]:before{height:calc(var(--initial-height) + 20%)}[data-sonner-toast][data-swiping=true]{transform:var(--y) translateY(var(--swipe-amount, 0px));transition:none}[data-sonner-toast][data-swipe-out=true][data-y-position=bottom],[data-sonner-toast][data-swipe-out=true][data-y-position=top]{animation:swipe-out .2s ease-out forwards}@keyframes swipe-out{0%{transform:translateY(calc(var(--lift) * var(--offset) + var(--swipe-amount)));opacity:1}to{transform:translateY(calc(var(--lift) * var(--offset) + var(--swipe-amount) + var(--lift) * -100%));opacity:0}}@media (max-width: 600px){[data-sonner-toaster]{position:fixed;--mobile-offset: 16px;right:var(--mobile-offset);left:var(--mobile-offset);width:100%}[data-sonner-toaster] [data-sonner-toast]{left:0;right:0;width:calc(100% - 32px)}[data-sonner-toaster][data-x-position=left]{left:var(--mobile-offset)}[data-sonner-toaster][data-y-position=bottom]{bottom:20px}[data-sonner-toaster][data-y-position=top]{top:20px}[data-sonner-toaster][data-x-position=center]{left:var(--mobile-offset);right:var(--mobile-offset);transform:none}}[data-sonner-toaster][data-theme=light]{--normal-bg: #fff;--normal-border: var(--gray4);--normal-text: var(--gray12);--success-bg: hsl(143, 85%, 96%);--success-border: hsl(145, 92%, 91%);--success-text: hsl(140, 100%, 27%);--info-bg: hsl(208, 100%, 97%);--info-border: hsl(221, 91%, 91%);--info-text: hsl(210, 92%, 45%);--warning-bg: hsl(49, 100%, 97%);--warning-border: hsl(49, 91%, 91%);--warning-text: hsl(31, 92%, 45%);--error-bg: hsl(359, 100%, 97%);--error-border: hsl(359, 100%, 94%);--error-text: hsl(360, 100%, 45%)}[data-sonner-toaster][data-theme=light] [data-sonner-toast][data-invert=true]{--normal-bg: #000;--normal-border: hsl(0, 0%, 20%);--normal-text: var(--gray1)}[data-sonner-toaster][data-theme=dark] [data-sonner-toast][data-invert=true]{--normal-bg: #fff;--normal-border: var(--gray3);--normal-text: var(--gray12)}[data-sonner-toaster][data-theme=dark]{--normal-bg: #000;--normal-border: hsl(0, 0%, 20%);--normal-text: var(--gray1);--success-bg: hsl(150, 100%, 6%);--success-border: hsl(147, 100%, 12%);--success-text: hsl(150, 86%, 65%);--info-bg: hsl(215, 100%, 6%);--info-border: hsl(223, 100%, 12%);--info-text: hsl(216, 87%, 65%);--warning-bg: hsl(64, 100%, 6%);--warning-border: hsl(60, 100%, 12%);--warning-text: hsl(46, 87%, 65%);--error-bg: hsl(358, 76%, 10%);--error-border: hsl(357, 89%, 16%);--error-text: hsl(358, 100%, 81%)}[data-rich-colors=true] [data-sonner-toast][data-type=success],[data-rich-colors=true] [data-sonner-toast][data-type=success] [data-close-button]{background:var(--success-bg);border-color:var(--success-border);color:var(--success-text)}[data-rich-colors=true] [data-sonner-toast][data-type=info],[data-rich-colors=true] [data-sonner-toast][data-type=info] [data-close-button]{background:var(--info-bg);border-color:var(--info-border);color:var(--info-text)}[data-rich-colors=true] [data-sonner-toast][data-type=warning],[data-rich-colors=true] [data-sonner-toast][data-type=warning] [data-close-button]{background:var(--warning-bg);border-color:var(--warning-border);color:var(--warning-text)}[data-rich-colors=true] [data-sonner-toast][data-type=error],[data-rich-colors=true] [data-sonner-toast][data-type=error] [data-close-button]{background:var(--error-bg);border-color:var(--error-border);color:var(--error-text)}.sonner-loading-wrapper{--size: 16px;height:var(--size);width:var(--size);position:absolute;inset:0;z-index:10}.sonner-loading-wrapper[data-visible=false]{transform-origin:center;animation:sonner-fade-out .2s ease forwards}.sonner-spinner{position:relative;top:50%;left:50%;height:var(--size);width:var(--size)}.sonner-loading-bar{animation:sonner-spin 1.2s linear infinite;background:var(--gray11);border-radius:6px;height:8%;left:-10%;position:absolute;top:-3.9%;width:24%}.sonner-loading-bar:nth-child(1){animation-delay:-1.2s;transform:rotate(.0001deg) translate(146%)}.sonner-loading-bar:nth-child(2){animation-delay:-1.1s;transform:rotate(30deg) translate(146%)}.sonner-loading-bar:nth-child(3){animation-delay:-1s;transform:rotate(60deg) translate(146%)}.sonner-loading-bar:nth-child(4){animation-delay:-.9s;transform:rotate(90deg) translate(146%)}.sonner-loading-bar:nth-child(5){animation-delay:-.8s;transform:rotate(120deg) translate(146%)}.sonner-loading-bar:nth-child(6){animation-delay:-.7s;transform:rotate(150deg) translate(146%)}.sonner-loading-bar:nth-child(7){animation-delay:-.6s;transform:rotate(180deg) translate(146%)}.sonner-loading-bar:nth-child(8){animation-delay:-.5s;transform:rotate(210deg) translate(146%)}.sonner-loading-bar:nth-child(9){animation-delay:-.4s;transform:rotate(240deg) translate(146%)}.sonner-loading-bar:nth-child(10){animation-delay:-.3s;transform:rotate(270deg) translate(146%)}.sonner-loading-bar:nth-child(11){animation-delay:-.2s;transform:rotate(300deg) translate(146%)}.sonner-loading-bar:nth-child(12){animation-delay:-.1s;transform:rotate(330deg) translate(146%)}@keyframes sonner-fade-in{0%{opacity:0;transform:scale(.8)}to{opacity:1;transform:scale(1)}}@keyframes sonner-fade-out{0%{opacity:1;transform:scale(1)}to{opacity:0;transform:scale(.8)}}@keyframes sonner-spin{0%{opacity:1}to{opacity:.15}}@media (prefers-reduced-motion){[data-sonner-toast],[data-sonner-toast]>*,.sonner-loading-bar{transition:none!important;animation:none!important}}
</style><link as="script" rel="prefetch" href="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/5772-330b7829e95060dd.js.download"><link as="script" rel="prefetch" href="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/4960-b70b6f04f379686e.js.download"><link as="script" rel="prefetch" href="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/index-77bcfcca4712573b.js.download"><script type="text/javascript" async="" src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/f.txt"></script></head><body class="bg-white leading-normal antialiased dark:bg-slate-950"><input type="hidden" id="hn-user"><style id="__jsx-668768712">@font-face{font-family:"Suisse Intl";src:url("/fonts/SuisseIntl-Book-WebXL.woff2")format("woff2"),url("/fonts/SuisseIntl-Book-WebXL.woff")format("woff");font-weight:450;font-style:normal;font-display:block}@font-face{font-family:"Suisse Intl";src:url("/fonts/SuisseIntl-Medium-WebXL.woff2")format("woff2"),url("/fonts/SuisseIntl-Medium-WebXL.woff")format("woff");font-weight:500;font-style:normal;font-display:block}@font-face{font-family:"Suisse Intl";src:url("/fonts/SuisseIntl-SemiBold-WebXL.woff2")format("woff2"),url("/fonts/SuisseIntl-SemiBold-WebXL.woff")format("woff");font-weight:600;font-style:normal;font-display:block}@font-face{font-family:"Suisse Intl";src:url("/fonts/SuisseIntl-Bold-WebXL.woff2")format("woff2"),url("/fonts/SuisseIntl-Bold-WebXL.woff")format("woff");font-weight:700;font-style:normal;font-display:block}html{--font-inter:__Inter_a184c8;--font-suisse-intl:'Suisse Intl';--font-mermaid:var(--font-inter)}</style><div id="__next"><div class="bg-white dark:bg-slate-950" data-theme="light"><script type="application/ld+json">{"@context":"https://schema.org","@type":"NewsArticle","url":"https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql","mainEntityOfPage":"https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql","headline":"Mastering Natural Language to SQL with LangChain | NL2SQL","description":"Unlock the full potential of database interactions with our guide on Natural Language to SQL using LangChain and LLM.","datePublished":"2024-03-11T10:38:55.566Z","dateModified":"2024-03-11T10:40:28.637Z","isAccessibleForFree":true,"author":{"@type":"Person","name":"Pradip Nichite","url":"https://hashnode.com/@pnichite"},"publisher":{"@type":"Organization","name":"FutureSmart AI Blog","url":"https://blog.futuresmart.ai","logo":"https://hashnode.com/utility/r?url=https%3A%2F%2Fcdn.hashnode.com%2Fres%2Fhashnode%2Fimage%2Fupload%2Fv1559814205701%2Fek9fO-yT0.jpeg%3Fw%3D800%26bm%3Dnormal%26balph%3D100%26txt64%3DRnV0dXJlU21hcnQgQUkgQmxvZw%26txtsize%3D42%26txtfit%3Dmax%26txtalign%3Dmiddle%2Ccenter%26txtfont%3DHelvetica%20Neue%2CBold%26txtclr%3Dffffff%26blend%3D2962FF"},"image":{"@type":"ImageObject","url":"https://cdn.hashnode.com/res/hashnode/image/upload/v1710152478787/e57074e2-3303-46ec-8491-11f60aa0bd2d.png"}}</script><header style="background-color: rgb(41, 98, 255); transform: translateY(-110px);" class="blog-header z-50 w-full border-b relative transform-none md:sticky md:top-0 md:left-0 md:backdrop-blur-lg border-transparent md:border-none"><div class="container mx-auto px-2 md:px-4 md:py-1 2xl:px-10"><div class="relative z-40 flex flex-row items-center justify-between pb-2 pt-8 md:py-4"><div class="mb-2 flex flex-row items-center md:mb-0 text-white"><a aria-label="Back to blog home" class="blog-back-to-home-button focus-ring-base flex flex-row items-center rounded-full font-medium transition duration-100 ease-in-out focus-ring-colors-dark-header hover:bg-white/20 mr-2 p-3" data-state="closed" href="https://blog.futuresmart.ai/"><svg class="h-4 w-4 fill-current pr-1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 10 17"><path d="M7.75135 16.7197L0.885098 9.55347C0.683348 9.31347 0.600098 9.08847 0.600098 8.89722C0.600098 8.70597 0.68331 8.44834 0.850898 8.27509L7.71715 1.10884C8.06035 0.749066 8.6299 0.737366 8.9884 1.08189C9.34933 1.42408 9.36107 1.99576 9.01535 2.35351L2.7466 8.89722L9.0466 15.4747C9.39231 15.831 9.38057 16.404 9.01965 16.7463C8.6626 17.091 8.0926 17.0797 7.75135 16.7197Z"></path></svg></a><div class="mr-2"><button type="button" aria-label="Open blog links" class="blog-bars-button focus-ring-base flex flex-row items-center rounded-full font-medium transition duration-100 ease-in-out focus-ring-colors-dark-header hover:bg-white/20 mr-2 p-2" data-state="closed"><svg class="h-6 w-6 stroke-current" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M20.9889 11.9969H11.9945H3M20.9889 17.8745H3M21 6.12451H3" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></button></div><div class="hidden md:block"><div class="blog-title text-lg md:text-xl text-left break-words font-heading font-semibold leading-snug md:font-bold text-white"><a href="https://blog.futuresmart.ai/?source=top_nav_blog_home" class="focus-ring-base flex flex-row items-center focus-ring-colors-dark-header" aria-label="FutureSmart AI Blog home page">FutureSmart AI Blog</a></div></div></div><div class="flex flex-row items-center text-white"><button type="button" aria-label="Open blog search" class="blog-search-button focus-ring-base flex flex-row items-center rounded-full font-medium transition duration-100 ease-in-out focus-ring-colors-dark-header hover:bg-white/20 mr-2 p-2" data-state="closed"><svg class="h-6 w-6 stroke-current" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none"><path d="M21 21L15.8091 15.8091M18 10.5C18 14.6421 14.6421 18 10.5 18C6.35786 18 3 14.6421 3 10.5C3 6.35786 6.35786 3 10.5 3C14.6421 3 18 6.35786 18 10.5Z" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></button><button type="button" aria-label="Toggle blog theme" class="blog-theme-switcher focus-ring-base flex flex-row items-center rounded-full font-medium transition duration-100 ease-in-out focus-ring-colors-dark-header hover:bg-white/20 mr-2 p-2" data-state="closed"><svg class="h-6 w-6 stroke-current" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none"><path d="M3 11.4489C3 16.7238 7.16904 21 12.3118 21C16.2709 21 19.6529 18.4657 21 14.8925C19.9331 15.4065 18.7418 15.6938 17.485 15.6938C12.9137 15.6938 9.20787 11.8928 9.20787 7.20396C9.20787 5.24299 9.85605 3.4373 10.9446 2C6.45002 2.6783 3 6.65034 3 11.4489Z" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></button><div class="hidden md:mr-2 md:block"><button type="button" class="blog-follow-button focus-ring-base flex flex-row items-center rounded-full border-1-1/2 px-4 py-2 text-center text-sm font-medium transition-colors duration-150 hover:bg-opacity-90 disabled:cursor-not-allowed disabled:opacity-50 text-slate-800 bg-white border-white hover:bg-blue-50 focus-ring-colors-dark-header" aria-label="Follow blog" data-state="closed"><svg class="mr-2 h-5 w-5 stroke-current" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M2.5 19.25C2.5 15.5221 5.52208 12.5 9.25 12.5V12.5C12.9779 12.5 16 15.5221 16 19.25V19.5C16 20.6046 15.1046 21.5 14 21.5H4.5C3.39543 21.5 2.5 20.6046 2.5 19.5V19.25Z" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M12.75 6C12.75 7.933 11.183 9.5 9.25 9.5C7.317 9.5 5.75 7.933 5.75 6C5.75 4.067 7.317 2.5 9.25 2.5C11.183 2.5 12.75 4.067 12.75 6Z" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M19 7.5V10.5M19 10.5V13.5M19 10.5H16M19 10.5H22" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg><span>Follow</span></button></div><div class="hidden md:mr-2 md:block"></div><div class="h-10 w-10 rounded-full"><button type="button" aria-label="Toggle sign-up options" class="focus-ring-base flex flex-row items-center rounded-full font-medium transition duration-100 ease-in-out focus-ring-colors-dark-header hover:bg-white/20 blog-more-icon p-2" id="radix-:ra:" aria-haspopup="menu" aria-expanded="false" data-state="closed"><svg class="h-6 w-6 stroke-current" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6 9L12 15L18 9" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></button></div></div></div><div class="mx-auto my-5 flex w-2/3 flex-row items-center justify-center md:hidden"><div class="blog-title text-2xl text-center break-words font-heading font-semibold leading-snug md:font-bold text-white"><a href="https://blog.futuresmart.ai/?source=top_nav_blog_home" class="focus-ring-base flex flex-row items-center focus-ring-colors-dark-header" aria-label="FutureSmart AI Blog home page">FutureSmart AI Blog</a></div></div><div class="blog-sub-header mb-4 md:hidden" data-testid="blog-sub-header"><div class="md:(mb-0 ml-auto) flex flex-row items-center justify-center gap-x-3"><button type="button" class="blog-follow-button focus-ring-base flex flex-row items-center rounded-full border-1-1/2 px-4 py-2 text-center text-sm font-medium transition-colors duration-150 hover:bg-opacity-90 disabled:cursor-not-allowed disabled:opacity-50 text-slate-800 bg-white border-white hover:bg-blue-50 focus-ring-colors-dark-header" aria-label="Follow blog" data-state="closed"><svg class="mr-2 h-5 w-5 stroke-current" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M2.5 19.25C2.5 15.5221 5.52208 12.5 9.25 12.5V12.5C12.9779 12.5 16 15.5221 16 19.25V19.5C16 20.6046 15.1046 21.5 14 21.5H4.5C3.39543 21.5 2.5 20.6046 2.5 19.5V19.25Z" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M12.75 6C12.75 7.933 11.183 9.5 9.25 9.5C7.317 9.5 5.75 7.933 5.75 6C5.75 4.067 7.317 2.5 9.25 2.5C11.183 2.5 12.75 4.067 12.75 6Z" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path d="M19 7.5V10.5M19 10.5V13.5M19 10.5H16M19 10.5H22" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg><span>Follow</span></button></div><div class="mt-6"><div class="blog-social-media-section flex flex-row flex-wrap gap-y-2 justify-center gap-x-1.5 text-white"><a href="https://www.instagram.com/futuresmart.ai" aria-label="Find me on Instagram, external website, opens in new tab" target="_blank" rel="me noopener" class="focus-ring-base flex flex-row items-center justify-center rounded-full p-2 transition-colors duration-150 focus-ring-colors-dark-header hover:bg-white/20"><svg class="h-5 w-5 fill-current" viewBox="0 0 24 24"><path d="M7.8 2h8.4C19.4 2 22 4.6 22 7.8v8.4a5.8 5.8 0 0 1-5.8 5.8H7.8C4.6 22 2 19.4 2 16.2V7.8A5.8 5.8 0 0 1 7.8 2m-.2 2A3.6 3.6 0 0 0 4 7.6v8.8C4 18.39 5.61 20 7.6 20h8.8a3.6 3.6 0 0 0 3.6-3.6V7.6C20 5.61 18.39 4 16.4 4H7.6m9.65 1.5a1.25 1.25 0 0 1 1.25 1.25A1.25 1.25 0 0 1 17.25 8 1.25 1.25 0 0 1 16 6.75a1.25 1.25 0 0 1 1.25-1.25M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3z"></path></svg></a><a href="https://www.futuresmart.ai/" aria-label="Check out my website, external website, opens in new tab" target="_blank" rel="me noopener" class="focus-ring-base flex flex-row items-center justify-center rounded-full p-2 transition-colors duration-150 focus-ring-colors-dark-header hover:bg-white/20"><svg class="h-5 w-5 fill-current" viewBox="0 0 24 24"><path d="M17.9 17.39c-.26-.8-1.01-1.39-1.9-1.39h-1v-3a1 1 0 0 0-1-1H8v-2h2a1 1 0 0 0 1-1V7h2a2 2 0 0 0 2-2v-.41c2.93 1.18 5 4.05 5 7.41 0 2.08-.8 3.97-2.1 5.39M11 19.93c-3.95-.49-7-3.85-7-7.93 0-.62.08-1.22.21-1.79L9 15v1a2 2 0 0 0 2 2m1-16A10 10 0 0 0 2 12a10 10 0 0 0 10 10 10 10 0 0 0 10-10A10 10 0 0 0 12 2z"></path></svg></a><a href="https://www.youtube.com/c/PradipNichiteAI" aria-label="Subscribe to my channel on YouTube, external website, opens in new tab" target="_blank" rel="me noopener" class="focus-ring-base flex flex-row items-center justify-center rounded-full p-2 transition-colors duration-150 focus-ring-colors-dark-header hover:bg-white/20"><svg class="h-5 w-5 fill-current" viewBox="0 0 576 512"><path d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z"></path></svg></a><a href="https://blog.futuresmart.ai/rss.xml" aria-label="Open blog XML Feed, opens in new tab" target="_blank" rel="me noopener" class="focus-ring-base flex flex-row items-center justify-center rounded-full p-2 transition-colors duration-150 focus-ring-colors-dark-header hover:bg-white/20"><svg class="h-5 w-5 fill-current" viewBox="0 0 448 512"><path d="M80 368c17.645 0 32 14.355 32 32s-14.355 32-32 32-32-14.355-32-32 14.355-32 32-32m0-48c-44.183 0-80 35.817-80 80s35.817 80 80 80 80-35.817 80-80-35.817-80-80-80zm367.996 147.615c-6.449-237.834-198.057-429.163-435.61-435.61C5.609 31.821 0 37.229 0 44.007v24.02c0 6.482 5.147 11.808 11.626 11.992 211.976 6.04 382.316 176.735 388.354 388.354.185 6.479 5.51 11.626 11.992 11.626h24.02c6.78.001 12.187-5.608 12.004-12.384zm-136.239-.05C305.401 305.01 174.966 174.599 12.435 168.243 5.643 167.977 0 173.444 0 180.242v24.024c0 6.431 5.072 11.705 11.497 11.98 136.768 5.847 246.411 115.511 252.258 252.258.275 6.425 5.549 11.497 11.98 11.497h24.024c6.797-.001 12.264-5.644 11.998-12.436z"></path></svg></a></div></div></div></div></header><div class="blog-post-area relative z-40"><main class="blog-post-detail-card pb-24"><article><style>
    [data-rmiz-ghost] {
      position: absolute;
      pointer-events: none;
    }
    [data-rmiz-btn-zoom],
    [data-rmiz-btn-unzoom] {
      background-color: rgba(0, 0, 0, 0.7);
      border-radius: 50%;
      border: none;
      box-shadow: 0 0 1px rgba(255, 255, 255, 0.5);
      color: #fff;
      height: 40px;
      margin: 0;
      outline-offset: 2px;
      padding: 9px;
      touch-action: manipulation;
      width: 40px;
      -webkit-appearance: none;
      -moz-appearance: none;
      appearance: none;
    }
    [data-rmiz-btn-zoom]:not(:focus):not(:active) {
      position: absolute;
      clip: rect(0 0 0 0);
      clip-path: inset(50%);
      height: 1px;
      overflow: hidden;
      pointer-events: none;
      white-space: nowrap;
      width: 1px;
    }
    [data-rmiz-btn-zoom] {
      position: absolute;
      inset: 10px 10px auto auto;
      cursor: zoom-in;
    }
    [data-rmiz-btn-unzoom] {
      position: absolute;
      inset: 20px 20px auto auto;
      cursor: zoom-out;
      z-index: 1;
      display: none;
    }
    [data-rmiz-content="found"] img,
    [data-rmiz-content="found"] svg,
    [data-rmiz-content="found"] [role="img"],
    [data-rmiz-content="found"] [data-zoom] {
      cursor: zoom-in;
    }
    [data-rmiz-modal]::backdrop {
      display: none;
    }
    [data-rmiz-modal][open] {
      position: fixed;
      width: 100vw;
      width: 100dvw;
      height: 100vh;
      height: 100dvh;
      max-width: none;
      max-height: none;
      margin: 0;
      padding: 0;
      border: 0;
      background: transparent;
      overflow: hidden;
    }
    [data-rmiz-modal-overlay] {
      position: absolute;
      inset: 0;
      transition: background-color 0.3s;
    }
    [data-rmiz-modal-overlay="hidden"] {
      background-color: rgba(255, 255, 255, 0);
    }
    [data-rmiz-modal-overlay="visible"] {
      /* This bg color is different from default */
      background-color: rgba(0, 0, 0, 0.5);
    }
    [data-rmiz-modal-content] {
      position: relative;
      width: 100%;
      height: 100%;
    }
    [data-rmiz-modal-img] {
      position: absolute;
      cursor: zoom-out;
      image-rendering: high-quality;
      transform-origin: top left;
      transition: transform 0.3s;
      /* This is added additionally to override prose styles of image*/
      margin: 0 !important;
    }
    @media (prefers-reduced-motion: reduce) {
      [data-rmiz-modal-overlay],
      [data-rmiz-modal-img] {
        transition-duration: 0.01ms !important;
      }
    }
</style><div class="blog-article-page container relative mx-auto grid grid-cols-8"><div class="col-span-full lg:col-span-6 lg:col-start-2"><div class="relative"><span style="box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;padding-top:52.5%"></span><img alt="Mastering Natural Language to SQL with LangChain | NL2SQL" src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/e57074e2-3303-46ec-8491-11f60aa0bd2d.png" decoding="async" data-nimg="responsive" class="mb-0 block w-full" style="position: absolute; inset: 0px; box-sizing: border-box; padding: 0px; border: none; margin: auto; display: block; width: 0px; height: 0px; min-width: 100%; max-width: 100%; min-height: 100%; max-height: 100%;"><noscript><img alt="Mastering Natural Language to SQL with LangChain | NL2SQL" decoding="async" data-nimg="responsive" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="mb-0 block w-full" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1710152478787/e57074e2-3303-46ec-8491-11f60aa0bd2d.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=compress,format&amp;format=webp"/></noscript></span></div><div class="mt-6 break-words px-4 text-center font-heading text-3xl font-bold text-slate-900 dark:text-white md:mt-10 md:px-5 md:text-4xl lg:px-8 xl:px-20 xl:text-5xl mb-8 md:mb-14"><h1 class="leading-tight" data-query="post-title">Mastering Natural Language to SQL with LangChain | NL2SQL</h1></div><div class="relative z-20 mb-8 flex flex-row flex-wrap items-center justify-center px-4 md:-mt-7 md:mb-14 md:text-lg last:md:mb-10"><div class="mb-5 flex w-full flex-row items-center justify-center md:mb-0 md:w-auto md:justify-start"><div style="z-index:1" class="overflow-hidden rounded-full  bg-slate-200  dark:bg-white/20 md:mr-3 h-10 w-10 md:h-12 md:w-12"><a href="https://hashnode.com/@pnichite" class="relative block h-full w-full"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27200%27%20height=%27200%27/%3e"></span><img alt="Pradip Nichite&#39;s photo" src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/sgLB_1lXJ.jpeg" decoding="async" data-nimg="intrinsic" class="relative z-20 block w-full rounded-full" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"></span></a></div><a href="https://hashnode.com/@pnichite" class="ml-2 font-semibold text-slate-600 dark:text-white md:ml-0"><span>Pradip Nichite</span></a></div><div class="mb-5 flex w-full flex-row items-center justify-center md:mb-0 md:w-auto md:justify-start"><span class="mx-3 hidden font-bold text-slate-500 md:block">·</span><a href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql" class="tooltip-handle text-slate-600 dark:text-slate-400" data-title="Mar 11, 2024 10:38"><time datetime="2024-03-11T10:38:55.566Z">Mar 11, 2024</time></a><span class="mx-3 block font-bold text-slate-500">·</span><p class="flex flex-row items-center text-slate-600 dark:text-slate-400"><svg class="mr-2 h-5 w-5 fill-current opacity-75" viewBox="0 0 576 512"><path d="M540.9 56.77c-45.95-16.66-90.23-24.09-129.1-24.75-60.7.94-102.7 17.45-123.8 27.72-21.1-10.27-64.1-26.8-123.2-27.74-40-.05-84.4 8.35-129.7 24.77C14.18 64.33 0 84.41 0 106.7v302.9c0 14.66 6.875 28.06 18.89 36.8 11.81 8.531 26.64 10.98 40.73 6.781 118.9-36.34 209.3 19.05 214.3 22.19C277.8 477.6 281.2 480 287.1 480c6.52 0 10.12-2.373 14.07-4.578 10.78-6.688 98.3-57.66 214.3-22.27 14.11 4.25 28.86 1.75 40.75-6.812C569.1 437.6 576 424.2 576 409.6V106.7c0-22.28-14.2-42.35-35.1-49.93zM272 438.1c-24.95-12.03-71.01-29.37-130.5-29.37-27.83 0-58.5 3.812-91.19 13.77-4.406 1.344-9 .594-12.69-2.047C34.02 417.8 32 413.1 32 409.6V106.7c0-8.859 5.562-16.83 13.86-19.83C87.66 71.7 127.9 63.95 164.5 64c51.8.81 89.7 15.26 107.5 23.66V438.1zm272-28.5c0 4.375-2.016 8.234-5.594 10.84-3.766 2.703-8.297 3.422-12.69 2.125C424.1 391.6 341.3 420.4 304 438.3V87.66c17.8-8.4 55.7-22.85 107.4-23.66 35.31-.063 76.34 7.484 118.8 22.88 8.2 3 13.8 10.96 13.8 19.82v302.9z"></path></svg><span>14<!-- --> min read</span></p></div></div><div class="-mt-7 mb-8 flex flex-col items-center md:mb-14 md:flex-row md:justify-center"><button type="button" class="group mb-2 ml-0 mt-4 flex flex-row items-center overflow-hidden rounded-full bg-slate-100 pl-2 pr-1 text-sm font-semibold leading-snug text-slate-600 hover:bg-slate-200 dark:bg-slate-800 dark:text-slate-200 hover:dark:bg-slate-700 md:mb-0 md:ml-4 md:mt-0" data-state="closed"><div class="mr-3 p-2"><svg class="h-6 w-6 stroke-current" fill="none" viewBox="0 0 22 22" xmlns="http://www.w3.org/2000/svg"><path d="M14.3083 8.97852C14.9383 7.44645 15.2408 5.7389 14.7557 4.08374C14.0577 1.70199 11.5262 0.6286 9.47593 1.19739C8.45082 1.48178 7.53408 2.13598 7.15271 3.35617C6.17303 2.53487 5.03486 2.49894 4.03173 2.79293C1.99015 3.39126 0.447158 5.69084 1.14518 8.07259C1.89721 10.6386 4.31075 12.2888 6.48391 13.2341M14.3083 8.97852C14.0084 8.57633 13.6208 8.25477 13.2004 8.00413C11.373 6.91481 8.63784 7.34826 7.367 9.48015C6.67907 10.6342 6.44594 11.9384 6.48391 13.2341M14.3083 8.97852C14.6489 9.43523 14.8764 9.99591 14.9107 10.6748C16.0645 10.1243 17.1676 10.3511 18.0735 10.909C19.8851 12.0248 20.8205 14.6105 19.5497 16.7423C17.008 21.0062 9.71032 20.7837 9.10119 20.4206C8.65692 20.1558 6.5862 16.7257 6.48391 13.2341" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></div><div class="relative h-8 w-8 rounded-full border-1-1/2 border-slate-100 bg-white group-hover:border-slate-200 dark:border-slate-800 dark:bg-slate-600 group-hover:dark:border-slate-700 [&amp;:not(:first-of-type)]:-ml-3" style="z-index: 1;"><img data-sizes="auto" loading="lazy" src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/mZjAWjTBb.png" data-src="https://cdn.hashnode.com/res/hashnode/image/upload/v1651666559169/mZjAWjTBb.png?w=200&amp;h=200&amp;fit=crop&amp;crop=faces&amp;auto=compress,format&amp;format=webp" width="200" height="200" alt="Shruti Agarwal&#39;s photo" class="lazyload block mr-3 h-full w-full rounded-full"></div><div class="relative h-8 w-8 rounded-full border-1-1/2 border-slate-100 bg-white group-hover:border-slate-200 dark:border-slate-800 dark:bg-slate-600 group-hover:dark:border-slate-700 [&amp;:not(:first-of-type)]:-ml-3" style="z-index: 2;"><img data-sizes="auto" loading="lazy" src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/NShoAk1Jr.jpg" data-src="https://cdn.hashnode.com/res/hashnode/image/upload/v1660887331425/NShoAk1Jr.jpg?w=200&amp;h=200&amp;fit=crop&amp;crop=faces&amp;auto=compress,format&amp;format=webp" width="200" height="200" alt="Sumit Nichite&#39;s photo" class="lazyload block mr-3 h-full w-full rounded-full"></div><div class="relative h-8 w-8 rounded-full border-1-1/2 border-slate-100 bg-white group-hover:border-slate-200 dark:border-slate-800 dark:bg-slate-600 group-hover:dark:border-slate-700 [&amp;:not(:first-of-type)]:-ml-3" style="z-index: 3;"><img data-sizes="auto" loading="lazy" src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/6ba15ce7-b332-475d-8af2-8f01c8a71a63.jpeg" data-src="https://cdn.hashnode.com/res/hashnode/image/upload/v1698974216104/6ba15ce7-b332-475d-8af2-8f01c8a71a63.jpeg?w=200&amp;h=200&amp;fit=crop&amp;crop=faces&amp;auto=compress,format&amp;format=webp" width="200" height="200" alt="Pavan Reddy Medipally&#39;s photo" class="lazyload block mr-3 h-full w-full rounded-full"></div><div class="relative h-8 w-8 rounded-full border-1-1/2 border-slate-100 bg-white group-hover:border-slate-200 dark:border-slate-800 dark:bg-slate-600 group-hover:dark:border-slate-700 [&amp;:not(:first-of-type)]:-ml-3" style="z-index: 4;"><img data-sizes="auto" loading="lazy" src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/f15f6bb1-4164-4835-b739-23f603262a42.jpeg" data-src="https://cdn.hashnode.com/res/hashnode/image/upload/v1715110156065/f15f6bb1-4164-4835-b739-23f603262a42.jpeg?w=200&amp;h=200&amp;fit=crop&amp;crop=faces&amp;auto=compress,format&amp;format=webp" width="200" height="200" alt="Sakalya Mitra&#39;s photo" class="lazyload block mr-3 h-full w-full rounded-full"></div><div class="relative -ml-3 flex h-8 items-center justify-center overflow-hidden rounded-full border-1-1/2 border-slate-100 bg-white px-1 group-hover:border-slate-200 dark:border-slate-800 dark:bg-slate-600 group-hover:dark:border-slate-700" style="z-index: 4; min-width: 2rem;"><p class="truncate text-xs font-normal">+13</p></div></button></div></div></div><div class="blog-content-wrapper article-main-wrapper container relative z-30 mx-auto grid grid-flow-row grid-cols-8 xl:gap-6 2xl:grid-cols-10"><section class="blog-content-main z-20 col-span-8 mb-10 px-4 md:z-10 lg:col-span-6 lg:col-start-2 lg:px-0 xl:col-span-6 xl:col-start-2 2xl:col-span-6 2xl:col-start-3"><div class="relative"><div class="relative w-full overflow-hidden border border-slate-200 bg-white dark:border-slate-800/80 dark:bg-slate-950 mx-auto mb-10 max-w-[812px] rounded-xl"><div class="pr-4"><h2 class="px-6 py-5 pb-4 text-lg font-semibold text-slate-800 dark:text-slate-100"><span>Table of contents</span></h2><ul class="pl-4 dark:border-slate-800"><li><a href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-introduction" aria-label="Introduction" class="mb-1 flex items-center gap-x-2 rounded-lg px-2 focus:outline-none hover:bg-slate-100 focus:bg-slate-100 dark:hover:bg-slate-800 dark:focus:bg-slate-800"><div id="6a4b64cc-4dc7-498c-babd-f79152ec0916" class="w-full break-words py-2 text-base focus:outline-none text-slate-700  dark:text-slate-200">Introduction</div></a></li><li><a href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-building-a-basic-nl2sql-model" aria-label="Building a Basic NL2SQL Model" class="mb-1 flex items-center gap-x-2 rounded-lg px-2 focus:outline-none hover:bg-slate-100 focus:bg-slate-100 dark:hover:bg-slate-800 dark:focus:bg-slate-800"><div id="89f6377b-515f-410a-b612-3b1926dd7e4a" class="w-full break-words py-2 text-base focus:outline-none text-slate-700  dark:text-slate-200">Building a Basic NL2SQL Model</div></a><ul class="pl-4 dark:border-slate-800"><li><a href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-understanding-the-basics" aria-label="Understanding the Basics" class="mb-1 flex items-center gap-x-2 rounded-lg px-2 focus:outline-none hover:bg-slate-100 focus:bg-slate-100 dark:hover:bg-slate-800 dark:focus:bg-slate-800 -mt-1"><span class="text-slate-400 dark:text-slate-500"><svg class="h-4 w-4 stroke-current" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.6665 4L10.6665 8L6.6665 12"></path></svg></span><div id="bb4ff478-b5bb-4962-9895-16c826212a1b" class="w-full break-words py-2 text-base focus:outline-none text-slate-600 dark:text-slate-300">Understanding the Basics</div></a></li><li><a href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-setting-up-langchain" aria-label="Setting Up LangChain" class="mb-1 flex items-center gap-x-2 rounded-lg px-2 focus:outline-none hover:bg-slate-100 focus:bg-slate-100 dark:hover:bg-slate-800 dark:focus:bg-slate-800 -mt-1"><span class="text-slate-400 dark:text-slate-500"><svg class="h-4 w-4 stroke-current" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.6665 4L10.6665 8L6.6665 12"></path></svg></span><div id="ea22420b-75d2-492c-9394-425d5309cb14" class="w-full break-words py-2 text-base focus:outline-none text-slate-600 dark:text-slate-300">Setting Up LangChain</div></a></li><li><a href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-the-first-query" aria-label="The First Query" class="mb-1 flex items-center gap-x-2 rounded-lg px-2 focus:outline-none hover:bg-slate-100 focus:bg-slate-100 dark:hover:bg-slate-800 dark:focus:bg-slate-800 -mt-1"><span class="text-slate-400 dark:text-slate-500"><svg class="h-4 w-4 stroke-current" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.6665 4L10.6665 8L6.6665 12"></path></svg></span><div id="622473cc-a30e-490d-a5a6-055c1bb8156f" class="w-full break-words py-2 text-base focus:outline-none text-slate-600 dark:text-slate-300">The First Query</div></a></li><li><a href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-seeing-the-results" aria-label="Seeing the Results" class="mb-1 flex items-center gap-x-2 rounded-lg px-2 focus:outline-none hover:bg-slate-100 focus:bg-slate-100 dark:hover:bg-slate-800 dark:focus:bg-slate-800 -mt-1"><span class="text-slate-400 dark:text-slate-500"><svg class="h-4 w-4 stroke-current" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.6665 4L10.6665 8L6.6665 12"></path></svg></span><div id="6163595a-a60a-492a-acc2-8301e380bb3a" class="w-full break-words py-2 text-base focus:outline-none text-slate-600 dark:text-slate-300">Seeing the Results</div></a></li><li><a href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-moving-forward" aria-label="Moving Forward" class="mb-1 flex items-center gap-x-2 rounded-lg px-2 focus:outline-none hover:bg-slate-100 focus:bg-slate-100 dark:hover:bg-slate-800 dark:focus:bg-slate-800 -mt-1"><span class="text-slate-400 dark:text-slate-500"><svg class="h-4 w-4 stroke-current" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.6665 4L10.6665 8L6.6665 12"></path></svg></span><div id="3ab1b020-4a7e-49e8-b8b9-8327280d5c38" class="w-full break-words py-2 text-base focus:outline-none text-slate-600 dark:text-slate-300">Moving Forward</div></a></li></ul></li><li><a href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-rephrasing-answers-for-enhanced-clarity" aria-label="Rephrasing Answers for Enhanced Clarity" class="mb-1 flex items-center gap-x-2 rounded-lg px-2 focus:outline-none hover:bg-slate-100 focus:bg-slate-100 dark:hover:bg-slate-800 dark:focus:bg-slate-800"><div id="23abf3fc-5dce-4913-bd2e-6f4deefc4c80" class="w-full break-words py-2 text-base focus:outline-none text-slate-700  dark:text-slate-200">Rephrasing Answers for Enhanced Clarity</div></a><ul class="pl-4 dark:border-slate-800"><li><a href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-implementing-rephrasing-with-langchain" aria-label="Implementing Rephrasing with LangChain" class="mb-1 flex items-center gap-x-2 rounded-lg px-2 focus:outline-none hover:bg-slate-100 focus:bg-slate-100 dark:hover:bg-slate-800 dark:focus:bg-slate-800 -mt-1"><span class="text-slate-400 dark:text-slate-500"><svg class="h-4 w-4 stroke-current" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.6665 4L10.6665 8L6.6665 12"></path></svg></span><div id="2723367f-11b2-4b0b-8f80-ac78795c0455" class="w-full break-words py-2 text-base focus:outline-none text-slate-600 dark:text-slate-300">Implementing Rephrasing with LangChain</div></a></li><li><a href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-example-transforming-sql-results-into-user-friendly-responses" aria-label="Example: Transforming SQL Results into User-Friendly Responses" class="mb-1 flex items-center gap-x-2 rounded-lg px-2 focus:outline-none hover:bg-slate-100 focus:bg-slate-100 dark:hover:bg-slate-800 dark:focus:bg-slate-800 -mt-1"><span class="text-slate-400 dark:text-slate-500"><svg class="h-4 w-4 stroke-current" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.6665 4L10.6665 8L6.6665 12"></path></svg></span><div id="723b6b1a-9890-423f-9e23-39705a3d3a0b" class="w-full break-words py-2 text-base focus:outline-none text-slate-600 dark:text-slate-300">Example: Transforming SQL Results into User-Friendly Responses</div></a></li></ul></li><li><a href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-enhancing-nl2sql-models-with-few-shot-examples" aria-label="Enhancing NL2SQL Models with Few-Shot Examples" class="mb-1 flex items-center gap-x-2 rounded-lg px-2 focus:outline-none hover:bg-slate-100 focus:bg-slate-100 dark:hover:bg-slate-800 dark:focus:bg-slate-800"><div id="6c7b4aff-61de-4eef-92f6-0d3509afb5f7" class="w-full break-words py-2 text-base focus:outline-none text-slate-700  dark:text-slate-200">Enhancing NL2SQL Models with Few-Shot Examples</div></a><ul class="pl-4 dark:border-slate-800"><li><a href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-incorporating-few-shot-examples-into-langchain" aria-label="Incorporating Few-Shot Examples into LangChain" class="mb-1 flex items-center gap-x-2 rounded-lg px-2 focus:outline-none hover:bg-slate-100 focus:bg-slate-100 dark:hover:bg-slate-800 dark:focus:bg-slate-800 -mt-1"><span class="text-slate-400 dark:text-slate-500"><svg class="h-4 w-4 stroke-current" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.6665 4L10.6665 8L6.6665 12"></path></svg></span><div id="29b8ba8c-a202-42aa-bc3a-079048290ff2" class="w-full break-words py-2 text-base focus:outline-none text-slate-600 dark:text-slate-300">Incorporating Few-Shot Examples into LangChain</div></a></li><li><a href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-the-impact-of-few-shot-learning" aria-label="The Impact of Few-Shot Learning" class="mb-1 flex items-center gap-x-2 rounded-lg px-2 focus:outline-none hover:bg-slate-100 focus:bg-slate-100 dark:hover:bg-slate-800 dark:focus:bg-slate-800 -mt-1"><span class="text-slate-400 dark:text-slate-500"><svg class="h-4 w-4 stroke-current" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.6665 4L10.6665 8L6.6665 12"></path></svg></span><div id="48bfcd04-66ab-4ee5-b177-1a75ad1c7e4d" class="w-full break-words py-2 text-base focus:outline-none text-slate-600 dark:text-slate-300">The Impact of Few-Shot Learning</div></a></li></ul></li><li><a href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-dynamic-few-shot-example-selection" aria-label="Dynamic Few-Shot Example Selection:" class="mb-1 flex items-center gap-x-2 rounded-lg px-2 focus:outline-none hover:bg-slate-100 focus:bg-slate-100 dark:hover:bg-slate-800 dark:focus:bg-slate-800"><div id="145d30b6-096f-405f-a44c-c86b4279f723" class="w-full break-words py-2 text-base focus:outline-none text-slate-700  dark:text-slate-200">Dynamic Few-Shot Example Selection:</div></a><ul class="pl-4 dark:border-slate-800"><li><a href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-the-need-for-dynamism" aria-label="The Need for Dynamism" class="mb-1 flex items-center gap-x-2 rounded-lg px-2 focus:outline-none hover:bg-slate-100 focus:bg-slate-100 dark:hover:bg-slate-800 dark:focus:bg-slate-800 -mt-1"><span class="text-slate-400 dark:text-slate-500"><svg class="h-4 w-4 stroke-current" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.6665 4L10.6665 8L6.6665 12"></path></svg></span><div id="29c4be64-f1b4-4156-abc1-41e406f9bc47" class="w-full break-words py-2 text-base focus:outline-none text-slate-600 dark:text-slate-300">The Need for Dynamism</div></a></li><li><a href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-implementing-dynamic-few-shot-selection" aria-label="Implementing Dynamic Few-Shot Selection" class="mb-1 flex items-center gap-x-2 rounded-lg px-2 focus:outline-none hover:bg-slate-100 focus:bg-slate-100 dark:hover:bg-slate-800 dark:focus:bg-slate-800 -mt-1"><span class="text-slate-400 dark:text-slate-500"><svg class="h-4 w-4 stroke-current" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.6665 4L10.6665 8L6.6665 12"></path></svg></span><div id="7f2d3a9d-cdba-4667-8813-116b0f92f119" class="w-full break-words py-2 text-base focus:outline-none text-slate-600 dark:text-slate-300">Implementing Dynamic Few-Shot Selection</div></a></li></ul></li><li><a href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-dynamic-relevant-table-selection" aria-label="Dynamic Relevant Table Selection" class="mb-1 flex items-center gap-x-2 rounded-lg px-2 focus:outline-none hover:bg-slate-100 focus:bg-slate-100 dark:hover:bg-slate-800 dark:focus:bg-slate-800"><div id="8d8fc6ef-2108-4a4f-af9f-80f72789047a" class="w-full break-words py-2 text-base focus:outline-none text-slate-700  dark:text-slate-200">Dynamic Relevant Table Selection</div></a><ul class="pl-4 dark:border-slate-800"><li><a href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-leveraging-smaller-focused-prompts-for-faster-execution" aria-label="Leveraging Smaller, Focused Prompts for Faster Execution" class="mb-1 flex items-center gap-x-2 rounded-lg px-2 focus:outline-none hover:bg-slate-100 focus:bg-slate-100 dark:hover:bg-slate-800 dark:focus:bg-slate-800 -mt-1"><span class="text-slate-400 dark:text-slate-500"><svg class="h-4 w-4 stroke-current" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.6665 4L10.6665 8L6.6665 12"></path></svg></span><div id="6b7f41f4-1020-416a-b891-50a1373b6a91" class="w-full break-words py-2 text-base focus:outline-none text-slate-600 dark:text-slate-300">Leveraging Smaller, Focused Prompts for Faster Execution</div></a></li></ul></li><li><a href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-enhancing-chatbots-with-memory-for-follow-up-database-queries" aria-label="Enhancing Chatbots with Memory for Follow-up Database Queries" class="mb-1 flex items-center gap-x-2 rounded-lg px-2 focus:outline-none hover:bg-slate-100 focus:bg-slate-100 dark:hover:bg-slate-800 dark:focus:bg-slate-800"><div id="0039f550-0787-4861-9971-1cd12bc7f576" class="w-full break-words py-2 text-base focus:outline-none text-slate-700  dark:text-slate-200">Enhancing Chatbots with Memory for Follow-up Database Queries</div></a><ul class="pl-4 dark:border-slate-800"><li><a href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-the-significance-of-memory-in-chatbots" aria-label="The Significance of Memory in Chatbots" class="mb-1 flex items-center gap-x-2 rounded-lg px-2 focus:outline-none hover:bg-slate-100 focus:bg-slate-100 dark:hover:bg-slate-800 dark:focus:bg-slate-800 -mt-1"><span class="text-slate-400 dark:text-slate-500"><svg class="h-4 w-4 stroke-current" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.6665 4L10.6665 8L6.6665 12"></path></svg></span><div id="633b8ee7-b47b-4fa2-b05b-e3ab6e26626a" class="w-full break-words py-2 text-base focus:outline-none text-slate-600 dark:text-slate-300">The Significance of Memory in Chatbots</div></a></li><li><a href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-implementing-memory-in-your-nl2sql-model" aria-label="Implementing Memory in Your NL2SQL Model" class="mb-1 flex items-center gap-x-2 rounded-lg px-2 focus:outline-none hover:bg-slate-100 focus:bg-slate-100 dark:hover:bg-slate-800 dark:focus:bg-slate-800 -mt-1"><span class="text-slate-400 dark:text-slate-500"><svg class="h-4 w-4 stroke-current" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.6665 4L10.6665 8L6.6665 12"></path></svg></span><div id="c24d59b1-7af7-4601-8f48-0c67f3210e3b" class="w-full break-words py-2 text-base focus:outline-none text-slate-600 dark:text-slate-300">Implementing Memory in Your NL2SQL Model</div></a></li><li><a href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-example-scenario-handling-follow-up-questions" aria-label="Example Scenario: Handling Follow-Up Questions" class="mb-1 flex items-center gap-x-2 rounded-lg px-2 focus:outline-none hover:bg-slate-100 focus:bg-slate-100 dark:hover:bg-slate-800 dark:focus:bg-slate-800 -mt-1"><span class="text-slate-400 dark:text-slate-500"><svg class="h-4 w-4 stroke-current" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.6665 4L10.6665 8L6.6665 12"></path></svg></span><div id="4323aad8-b5b2-4ade-9d71-61fdcdc71b2f" class="w-full break-words py-2 text-base focus:outline-none text-slate-600 dark:text-slate-300">Example Scenario: Handling Follow-Up Questions</div></a></li></ul></li><li><a href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-conclusion" aria-label="Conclusion:" class="mb-1 flex items-center gap-x-2 rounded-lg px-2 focus:outline-none hover:bg-slate-100 focus:bg-slate-100 dark:hover:bg-slate-800 dark:focus:bg-slate-800"><div id="b7148ae5-6032-4ffd-bd89-102a74b799a5" class="w-full break-words py-2 text-base focus:outline-none text-slate-700  dark:text-slate-200">Conclusion:</div></a></li></ul></div><div class="relative flex items-center justify-center pb-4"><button type="button" class="flex items-center justify-center gap-1.5 rounded-[28px] px-3 py-2 text-sm font-medium hover:bg-slate-100 dark:hover:bg-slate-800"><span class="text-slate-600 dark:text-slate-300">Show less</span><svg class="h-4 w-4 stroke-current text-slate-500" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M4 9L8 5L12 9" stroke="#a1a1aa" stroke-linecap="round" stroke-linejoin="round"></path></svg></button></div></div><div id="post-content-parent" class="relative mb-10 pb-14"><div id="post-content-wrapper" class="prose prose-base mx-auto mb-10 min-h-30 break-words dark:prose-dark lg:prose-lg"><h2 id="heading-introduction" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-introduction" data-clipboard-text="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-introduction" style="height: 40px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>Introduction</h2>
<p>Welcome to our deep dive into revolutionizing the way we interact with databases using Natural Language Processing (NLP) and LangChain. In today's data-driven world, the ability to query databases without needing to know complex SQL syntax opens up a myriad of possibilities across various industries, from healthcare to finance, making data more accessible to everyone.</p>
<p>This blog post aims to guide you through a comprehensive journey to master NL2SQL using LangChain. We will explore the steps necessary to build an intuitive, efficient, and intelligent NL2SQL model that can understand and process natural language queries, dynamically select relevant database tables, and maintain a conversational context to handle follow-up questions effectively.</p>
<p>By the end of this post, you'll have a solid understanding of:</p>
<ol>
<li><p><strong>Building a Basic NL2SQL Model</strong>: The foundation of translating natural language queries into SQL commands.</p>
</li>
<li><p><strong>Incorporating Few-Shot Learning</strong>: Enhancing model accuracy with examples.</p>
</li>
<li><p><strong>Dynamic Few-Shot Example Selection</strong>: Tailoring examples to the query context for improved relevance.</p>
</li>
<li><p><strong>Dynamic Relevant Table Selection</strong>: Automatically identifying which tables to query based on the natural language input.</p>
</li>
<li><p><strong>Customizing Prompts and Responses</strong>: Fine-tuning the model's interaction to provide clear, concise, and relevant answers.</p>
</li>
<li><p><strong>Adding Memory to Chatbots</strong>: Enabling the model to handle follow-up questions by remembering the context of the conversation.</p>
</li>
</ol>
<p>Through each of these steps, we'll discuss the concepts, show you how to implement them , and illustrate the outcomes , ensuring you have the tools and knowledge needed to bring the power of NL2SQL to your databases.</p>
<p>Let's embark on this exciting journey to unlock the full potential of your data, making database queries as simple as conversing with a friend.</p>
<h2 id="heading-building-a-basic-nl2sql-model" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-building-a-basic-nl2sql-model" data-clipboard-text="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-building-a-basic-nl2sql-model" style="height: 40px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>Building a Basic NL2SQL Model</h2>
<p>The first step in our journey to revolutionize database querying with natural language is constructing a basic NL2SQL model using LangChain. This foundational model serves as the cornerstone for more advanced functionalities we'll explore later. Here's how we begin:</p>
<h4 id="heading-understanding-the-basics" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-understanding-the-basics" data-clipboard-text="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-understanding-the-basics" style="height: 28px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>Understanding the Basics</h4>
<p>At its core, an NL2SQL model aims to translate natural language queries into SQL commands. But how do we start building such a model with LangChain?</p>
<h4 id="heading-setting-up-langchain" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-setting-up-langchain" data-clipboard-text="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-setting-up-langchain" style="height: 28px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>Setting Up LangChain</h4>
<p>LangChain simplifies the process of creating NL2SQL models by providing a flexible framework that integrates seamlessly with existing databases and natural language processing (NLP) models. To get started, you'll need to:</p>
<ol>
<li><p><strong>Install LangChain</strong>: Ensure that LangChain is installed in your environment.</p>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-bash"> pip install langchain_openai langchain_community langchain pymysql chromadb -q
</code></pre></div></div>
</li>
<li><p><strong>Connect to Your Database</strong>: The next step involves establishing a connection to your database. LangChain supports various database systems, so you'll likely find your database among the supported ones. You'll use the database credentials to create a connection that LangChain can use to interact with your data</p>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-python"> <span class="hljs-keyword">import</span> os
 os.environ[<span class="hljs-string">"OPENAI_API_KEY"</span>] = <span class="hljs-string">""</span>

 db_user = <span class="hljs-string">""</span>
 db_password = <span class="hljs-string">""</span>
 db_host = <span class="hljs-string">""</span>
 db_name = <span class="hljs-string">"classicmodels"</span>
 <span class="hljs-keyword">from</span> langchain_community.utilities.sql_database <span class="hljs-keyword">import</span> SQLDatabase
 <span class="hljs-comment"># db = SQLDatabase.from_uri(f"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}",sample_rows_in_table_info=1,include_tables=['customers','orders'],custom_table_info={'customers':"customer"})</span>
 db = SQLDatabase.from_uri(<span class="hljs-string">f"mysql+pymysql://<span class="hljs-subst">{db_user}</span>:<span class="hljs-subst">{db_password}</span>@<span class="hljs-subst">{db_host}</span>/<span class="hljs-subst">{db_name}</span>"</span>)
 print(db.dialect)
 print(db.get_usable_table_names())
 print(db.table_info)
</code></pre></div></div>
</li>
</ol>
<h4 id="heading-the-first-query" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-the-first-query" data-clipboard-text="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-the-first-query" style="height: 28px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>The First Query</h4>
<p>Once the setup is complete, the real magic begins. You can start by formulating a simple query in natural language, such as "Show me all products priced above $100." LangChain takes this input and, through its integration with language models like ChatGPT and your database, generates an SQL query that precisely captures the intent of your request</p>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-python"><span class="hljs-keyword">from</span> langchain.chains <span class="hljs-keyword">import</span> create_sql_query_chain
<span class="hljs-keyword">from</span> langchain_openai <span class="hljs-keyword">import</span> ChatOpenAI

llm = ChatOpenAI(model=<span class="hljs-string">"gpt-3.5-turbo"</span>, temperature=<span class="hljs-number">0</span>)
generate_query = create_sql_query_chain(llm, db)
query = generate_query.invoke({<span class="hljs-string">"question"</span>: <span class="hljs-string">"what is price of `1968 Ford Mustang`"</span>})
<span class="hljs-comment"># "what is price of `1968 Ford Mustang`"</span>
print(query)
</code></pre></div></div>
<h4 id="heading-seeing-the-results" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-seeing-the-results" data-clipboard-text="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-seeing-the-results" style="height: 28px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>Seeing the Results</h4>
<p>Executing the generated SQL query against your database retrieves the data you're looking for, which LangChain can then present in a user-friendly format.</p>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-python"><span class="hljs-keyword">from</span> langchain_community.tools.sql_database.tool <span class="hljs-keyword">import</span> QuerySQLDataBaseTool
execute_query = QuerySQLDataBaseTool(db=db)
execute_query.invoke(query)
</code></pre></div></div>
<h4 id="heading-moving-forward" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-moving-forward" data-clipboard-text="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-moving-forward" style="height: 28px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>Moving Forward</h4>
<p>With the basic NL2SQL model set up, you've taken the first step towards transforming how we interact with databases. However, this is just the beginning. As we progress, we'll explore how to enhance the model's accuracy, handle more complex queries, and even maintain context over a conversation for follow-up questions.</p>
<h2 id="heading-rephrasing-answers-for-enhanced-clarity" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-rephrasing-answers-for-enhanced-clarity" data-clipboard-text="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-rephrasing-answers-for-enhanced-clarity" style="height: 40px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>Rephrasing Answers for Enhanced Clarity</h2>
<p>After your NL2SQL model successfully executes a SQL query, the next pivotal step is to present the data in a manner that's easily understandable by your users. This is where the art of rephrasing SQL results into clear, natural language answers comes into play. Here's how you can achieve this with LangChain:</p>
<h4 id="heading-implementing-rephrasing-with-langchain" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-implementing-rephrasing-with-langchain" data-clipboard-text="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-implementing-rephrasing-with-langchain" style="height: 28px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>Implementing Rephrasing with LangChain</h4>
<ol>
<li><p><strong>Use Prompt Templates</strong>: LangChain allows you to create prompt templates that can guide the model in how to rephrase SQL results. These templates can include placeholders for the original question, the SQL query, and the query result, setting the stage for generating a natural language response</p>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-python"> <span class="hljs-keyword">from</span> operator <span class="hljs-keyword">import</span> itemgetter

 <span class="hljs-keyword">from</span> langchain_core.output_parsers <span class="hljs-keyword">import</span> StrOutputParser
 <span class="hljs-keyword">from</span> langchain_core.prompts <span class="hljs-keyword">import</span> PromptTemplate
 <span class="hljs-keyword">from</span> langchain_core.runnables <span class="hljs-keyword">import</span> RunnablePassthrough

 answer_prompt = PromptTemplate.from_template(
     <span class="hljs-string">"""Given the following user question, corresponding SQL query, and SQL result, answer the user question.

 Question: {question}
 SQL Query: {query}
 SQL Result: {result}
 Answer: """</span>
 )

 rephrase_answer = answer_prompt | llm | StrOutputParser()

 chain = (
     RunnablePassthrough.assign(query=generate_query).assign(
         result=itemgetter(<span class="hljs-string">"query"</span>) | execute_query
     )
     | rephrase_answer
 )

 chain.invoke({<span class="hljs-string">"question"</span>: <span class="hljs-string">"How many customers have an order count greater than 5"</span>})
</code></pre></div></div>
</li>
</ol>
<h4 id="heading-example-transforming-sql-results-into-user-friendly-responses" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-example-transforming-sql-results-into-user-friendly-responses" data-clipboard-text="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-example-transforming-sql-results-into-user-friendly-responses" style="height: 28px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>Example: Transforming SQL Results into User-Friendly Responses</h4>
<p>Let's consider a user asks, "How many customers have an order count greater than 5?" and the SQL query returns a raw numerical result. The rephrasing process would convert this into a more readable answer, such as "There are 2 customers with an order count of more than 5." This step is vital in closing the loop between user queries and database responses, ensuring that the information provided is both useful and easily digestible</p>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-plaintext">There are 2 customers with an order count of more than 5.
</code></pre></div></div>
<p>In the next section, we'll dive into the exciting world of few-shot learning and how it can be used to improve the performance of your NL2SQL model with LangChain. Stay tuned to unlock the full potential of natural language database querying.</p>
<h2 id="heading-enhancing-nl2sql-models-with-few-shot-examples" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-enhancing-nl2sql-models-with-few-shot-examples" data-clipboard-text="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-enhancing-nl2sql-models-with-few-shot-examples" style="height: 40px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>Enhancing NL2SQL Models with Few-Shot Examples</h2>
<p>This technique involves providing the model with a small set of carefully selected examples that demonstrate how to convert natural language questions into SQL queries. Few-shot learning can significantly improve the model's ability to understand and generate precise SQL commands based on user queries, bridging the gap between human language and database querying.</p>
<h4 id="heading-incorporating-few-shot-examples-into-langchain" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-incorporating-few-shot-examples-into-langchain" data-clipboard-text="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-incorporating-few-shot-examples-into-langchain" style="height: 28px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>Incorporating Few-Shot Examples into LangChain</h4>
<ol>
<li><p><strong>Selecting Relevant Examples</strong>: The first step is to curate a set of examples that cover a broad range of query types and complexities. These examples should ideally reflect the most common or critical queries your users might perform</p>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-plaintext"> examples = [
     {
         "input": "List all customers in France with a credit limit over 20,000.",
         "query": "SELECT * FROM customers WHERE country = 'France' AND creditLimit &gt; 20000;"
     },
     {
         "input": "Get the highest payment amount made by any customer.",
         "query": "SELECT MAX(amount) FROM payments;"
     },
    .....
 ]
</code></pre></div></div>
</li>
<li><p><strong>Creating a Few-Shot Learning Template</strong>: With LangChain, you can design a prompt template that incorporates these examples into the model's workflow. The template instructs the model to consider the examples when generating SQL queries from new user questions</p>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-python"> <span class="hljs-keyword">from</span> langchain_core.prompts <span class="hljs-keyword">import</span> ChatPromptTemplate, MessagesPlaceholder,FewShotChatMessagePromptTemplate,PromptTemplate

 example_prompt = ChatPromptTemplate.from_messages(
     [
         (<span class="hljs-string">"human"</span>, <span class="hljs-string">"{input}\nSQLQuery:"</span>),
         (<span class="hljs-string">"ai"</span>, <span class="hljs-string">"{query}"</span>),
     ]
 )
 few_shot_prompt = FewShotChatMessagePromptTemplate(
     example_prompt=example_prompt,
     examples=examples,
     <span class="hljs-comment"># input_variables=["input","top_k"],</span>
     input_variables=[<span class="hljs-string">"input"</span>],
 )
 print(few_shot_prompt.format(input1=<span class="hljs-string">"How many products are there?"</span>))
</code></pre></div></div>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-plaintext"> Human: List all customers in France with a credit limit over 20,000.
 SQLQuery:
 AI: SELECT * FROM customers WHERE country = 'France' AND creditLimit &gt; 20000;
 Human: Get the highest payment amount made by any customer.
 SQLQuery:
 AI: SELECT MAX(amount) FROM payments;
 ......
</code></pre></div></div>
</li>
</ol>
<h4 id="heading-the-impact-of-few-shot-learning" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-the-impact-of-few-shot-learning" data-clipboard-text="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-the-impact-of-few-shot-learning" style="height: 28px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>The Impact of Few-Shot Learning</h4>
<p>By integrating few-shot examples, your NL2SQL model becomes more adept at handling a wider variety of user queries. This not only improves the user experience by providing more accurate and relevant responses but also reduces the potential for errors in SQL query generation.</p>
<p>In the next section, we'll explore the integration of dynamic example selection to further enhance the model's accuracy and relevance, ensuring that your NL2SQL system remains adaptive and responsive to user queries.</p>
<h2 id="heading-dynamic-few-shot-example-selection" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-dynamic-few-shot-example-selection" data-clipboard-text="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-dynamic-few-shot-example-selection" style="height: 40px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>Dynamic Few-Shot Example Selection:</h2>
<p>This advanced technique tailors the few-shot examples provided to the model based on the specific context of the user's query. It ensures that the guidance offered to the model is not just relevant but optimally aligned with the query's nuances, significantly boosting the model's ability to generate accurate SQL queries.</p>
<h4 id="heading-the-need-for-dynamism" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-the-need-for-dynamism" data-clipboard-text="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-the-need-for-dynamism" style="height: 28px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>The Need for Dynamism</h4>
<p>Static few-shot examples, though highly effective, have their limitations. Dynamic selection addresses this by intelligently choosing examples that closely match the intent and context of each new query, providing a customized learning experience for the model with every interaction.</p>
<h4 id="heading-implementing-dynamic-few-shot-selection" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-implementing-dynamic-few-shot-selection" data-clipboard-text="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-implementing-dynamic-few-shot-selection" style="height: 28px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>Implementing Dynamic Few-Shot Selection</h4>
<ol>
<li><p><strong>Example Selector Configuration</strong>: Begin by setting up an example selector that can analyze the semantics of the user's query and compare it with a repository of potential examples. Tools like semantic similarity algorithms and vector embeddings come into play here, identifying which examples are most relevant to the current query</p>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-python"> <span class="hljs-keyword">from</span> langchain_community.vectorstores <span class="hljs-keyword">import</span> Chroma
 <span class="hljs-keyword">from</span> langchain_core.example_selectors <span class="hljs-keyword">import</span> SemanticSimilarityExampleSelector
 <span class="hljs-keyword">from</span> langchain_openai <span class="hljs-keyword">import</span> OpenAIEmbeddings

 vectorstore = Chroma()
 vectorstore.delete_collection()
 example_selector = SemanticSimilarityExampleSelector.from_examples(
     examples,
     OpenAIEmbeddings(),
     vectorstore,
     k=<span class="hljs-number">2</span>,
     input_keys=[<span class="hljs-string">"input"</span>],
 )
 example_selector.select_examples({<span class="hljs-string">"input"</span>: <span class="hljs-string">"how many employees we have?"</span>})
 few_shot_prompt = FewShotChatMessagePromptTemplate(
     example_prompt=example_prompt,
     example_selector=example_selector,
     input_variables=[<span class="hljs-string">"input"</span>,<span class="hljs-string">"top_k"</span>],
 )
 print(few_shot_prompt.format(input=<span class="hljs-string">"How many products are there?"</span>))
</code></pre></div></div>
</li>
<li><p><strong>Integrating with LangChain</strong>: Integrate the example selector with your LangChain workflow. When a new query is received, the selector determines the most relevant few-shot examples before the model generates the SQL query. This ensures that the guidance provided to the model is tailored to the specific requirements of the query</p>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-python"> final_prompt = ChatPromptTemplate.from_messages(
     [
         (<span class="hljs-string">"system"</span>, <span class="hljs-string">"You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run. Unless otherwise specificed.\n\nHere is the relevant table info: {table_info}\n\nBelow are a number of examples of questions and their corresponding SQL queries."</span>),
         few_shot_prompt,
         (<span class="hljs-string">"human"</span>, <span class="hljs-string">"{input}"</span>),
     ]
 )
 print(final_prompt.format(input=<span class="hljs-string">"How many products are there?"</span>,table_info=<span class="hljs-string">"some table info"</span>))
 generate_query = create_sql_query_chain(llm, db,final_prompt)
 chain = (
 RunnablePassthrough.assign(query=generate_query).assign(
     result=itemgetter(<span class="hljs-string">"query"</span>) | execute_query
 )
 | rephrase_answer
 )
 chain.invoke({<span class="hljs-string">"question"</span>: <span class="hljs-string">"How many csutomers with credit limit more than 50000"</span>})
</code></pre></div></div>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-plaintext"> There are 85 customers with a credit limit greater than 50000.
</code></pre></div></div>
</li>
</ol>
<p>By ensuring that the examples used for guidance are always contextually relevant, the model can generate more precise SQL queries, reducing errors and improving user satisfaction. of NL2SQL technology, making data insights more accessible to everyone.</p>
<p>In the following section, we will explore the integration of dynamic relevant table selection, further advancing our NL2SQL model's capabilities to efficiently parse and respond to user queries.</p>
<h2 id="heading-dynamic-relevant-table-selection" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-dynamic-relevant-table-selection" data-clipboard-text="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-dynamic-relevant-table-selection" style="height: 40px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>Dynamic Relevant Table Selection</h2>
<p>In the realm of NL2SQL models, especially when dealing with complex databases featuring 100+ tables. With databases growing in complexity and size, it's impractical and costly in terms of prompt token usage to include the schema of every table in the initial prompt for generating SQL queries. The sheer volume of information would overwhelm the model, leading to slower response times and increased computational costs. Dynamic relevant table selection emerges as a solution to this challenge, focusing the model's attention only on the tables pertinent to the user's query.</p>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-python"><span class="hljs-keyword">from</span> operator <span class="hljs-keyword">import</span> itemgetter
<span class="hljs-keyword">from</span> langchain.chains.openai_tools <span class="hljs-keyword">import</span> create_extraction_chain_pydantic
<span class="hljs-keyword">from</span> langchain_core.pydantic_v1 <span class="hljs-keyword">import</span> BaseModel, Field
<span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> List
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_table_details</span>():</span>
    <span class="hljs-comment"># Read the CSV file into a DataFrame</span>
    table_description = pd.read_csv(<span class="hljs-string">"database_table_descriptions.csv"</span>)
    table_docs = []

    <span class="hljs-comment"># Iterate over the DataFrame rows to create Document objects</span>
    table_details = <span class="hljs-string">""</span>
    <span class="hljs-keyword">for</span> index, row <span class="hljs-keyword">in</span> table_description.iterrows():
        table_details = table_details + <span class="hljs-string">"Table Name:"</span> + row[<span class="hljs-string">'Table'</span>] + <span class="hljs-string">"\n"</span> + <span class="hljs-string">"Table Description:"</span> + row[<span class="hljs-string">'Description'</span>] + <span class="hljs-string">"\n\n"</span>

    <span class="hljs-keyword">return</span> table_details


<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Table</span>(<span class="hljs-params">BaseModel</span>):</span>
    <span class="hljs-string">"""Table in SQL database."""</span>

    name: str = Field(description=<span class="hljs-string">"Name of table in SQL database."</span>)

<span class="hljs-comment"># table_names = "\n".join(db.get_usable_table_names())</span>
table_details = get_table_details()
print(table_details)
</code></pre></div></div>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-plaintext">Table Name:productlines
Table Description:Stores information about the differ....

Table Name:products
Table Description:Contains de....
</code></pre></div></div>
<h4 id="heading-leveraging-smaller-focused-prompts-for-faster-execution" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-leveraging-smaller-focused-prompts-for-faster-execution" data-clipboard-text="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-leveraging-smaller-focused-prompts-for-faster-execution" style="height: 28px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>Leveraging Smaller, Focused Prompts for Faster Execution</h4>
<p>Dynamic relevant table selection hinges on the principle that "less is more." By reducing the scope of information the model needs to consider for each query:</p>
<ol>
<li><p><strong>Improved Model Performance</strong>: Smaller prompts mean the model has fewer tokens to process, which translates to faster execution times. This is particularly crucial for interactive applications where response time is a key component of user satisfaction.</p>
</li>
<li><p><strong>Enhanced Accuracy</strong>: Focusing on only the relevant tables minimizes the risk of generating incorrect SQL queries. This specificity ensures that the model's computational resources are dedicated to understanding and processing only the most pertinent data.</p>
</li>
<li><p><strong>Cost-Efficiency</strong>: Reducing the amount of prompt information also means fewer token usage costs. In the context of cloud-based NLP services, where processing costs can accumulate rapidly, this efficiency is not only a technical but also a financial advantage.</p>
</li>
</ol>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-python">table_details_prompt = <span class="hljs-string">f"""Return the names of ALL the SQL tables that MIGHT be relevant to the user question. \
The tables are:

<span class="hljs-subst">{table_details}</span>

Remember to include ALL POTENTIALLY RELEVANT tables, even if you're not sure that they're needed."""</span>

table_chain = create_extraction_chain_pydantic(Table, llm, system_message=table_details_prompt)
tables = table_chain.invoke({<span class="hljs-string">"input"</span>: <span class="hljs-string">"give me details of customer and their order count"</span>})
tables
</code></pre></div></div>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-plaintext">[Table(name='customers'), Table(name='orders')]
</code></pre></div></div>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_tables</span>(<span class="hljs-params">tables: List[Table]</span>) -&gt; List[str]:</span>
    tables  = [table.name <span class="hljs-keyword">for</span> table <span class="hljs-keyword">in</span> tables]
    <span class="hljs-keyword">return</span> tables

select_table = {<span class="hljs-string">"input"</span>: itemgetter(<span class="hljs-string">"question"</span>)} | create_extraction_chain_pydantic(Table, llm, system_message=table_details_prompt) | get_tables
select_table.invoke({<span class="hljs-string">"question"</span>: <span class="hljs-string">"give me details of customer and their order count"</span>})
</code></pre></div></div>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-plaintext">['customers', 'orders']
</code></pre></div></div>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-python">chain = (
RunnablePassthrough.assign(table_names_to_use=select_table) |
RunnablePassthrough.assign(query=generate_query).assign(
    result=itemgetter(<span class="hljs-string">"query"</span>) | execute_query
)
| rephrase_answer
)
chain.invoke({<span class="hljs-string">"question"</span>: <span class="hljs-string">"How many cutomers with order count more than 5"</span>})
</code></pre></div></div>
<h2 id="heading-enhancing-chatbots-with-memory-for-follow-up-database-queries" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-enhancing-chatbots-with-memory-for-follow-up-database-queries" data-clipboard-text="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-enhancing-chatbots-with-memory-for-follow-up-database-queries" style="height: 40px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>Enhancing Chatbots with Memory for Follow-up Database Queries</h2>
<p>One of the most advanced steps in creating a user-friendly NL2SQL interface is endowing your chatbot with memory. This feature enables the chatbot to handle follow-up questions related to the database intelligently, providing users with a seamless conversational experience. Let's explore how adding memory to your chatbot can revolutionize interactions with your database.</p>
<h4 id="heading-the-significance-of-memory-in-chatbots" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-the-significance-of-memory-in-chatbots" data-clipboard-text="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-the-significance-of-memory-in-chatbots" style="height: 28px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>The Significance of Memory in Chatbots</h4>
<p>In real-world conversations, context matters. A question might relate to or build upon previous interactions. Similarly, when users interact with a database through a chatbot, their follow-up questions often depend on the context established by earlier queries and responses. A chatbot equipped with memory can retain this context, allowing it to generate more accurate and relevant SQL queries for follow-up questions.</p>
<h4 id="heading-implementing-memory-in-your-nl2sql-model" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-implementing-memory-in-your-nl2sql-model" data-clipboard-text="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-implementing-memory-in-your-nl2sql-model" style="height: 28px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>Implementing Memory in Your NL2SQL Model</h4>
<p>To equip your NL2SQL model with memory, consider incorporating a chat message history that tracks the conversation's flow. This history should include both the questions posed by the user and the chatbot's responses, enabling the model to reference previous interactions when generating SQL queries for new questions.</p>
<ol>
<li><p><strong>Setting Up Message History</strong>: Implement a mechanism to record each user query and the corresponding chatbot response. This can be achieved by defining a <code>ChatMessageHistory</code> object that stores this information and can be accessed when needed</p>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-python"> <span class="hljs-keyword">from</span> langchain.memory <span class="hljs-keyword">import</span> ChatMessageHistory
 history = ChatMessageHistory()
</code></pre></div></div>
</li>
<li><p><strong>Leveraging Previous Interactions</strong>: Integrate this message history into your prompt generation process. Before generating a new SQL query, the model should consider the recorded history to understand the conversation's context</p>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-python"> final_prompt = ChatPromptTemplate.from_messages(
     [
         (<span class="hljs-string">"system"</span>, <span class="hljs-string">"You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run. Unless otherwise specificed.\n\nHere is the relevant table info: {table_info}\n\nBelow are a number of examples of questions and their corresponding SQL queries. Those examples are just for referecne and hsould be considered while answering follow up questions"</span>),
         few_shot_prompt,
         MessagesPlaceholder(variable_name=<span class="hljs-string">"messages"</span>),
         (<span class="hljs-string">"human"</span>, <span class="hljs-string">"{input}"</span>),
     ]
 )
 print(final_prompt.format(input=<span class="hljs-string">"How many products are there?"</span>,table_info=<span class="hljs-string">"some table info"</span>,messages=[]))
</code></pre></div></div>
</li>
<li><p><strong>Dynamic Prompt Adaptation</strong>: Use the chat message history to dynamically adapt the prompts sent to the model for generating SQL queries. This adaptation should include information from previous queries and responses, guiding the model in understanding the context of the follow-up question</p>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-python"> generate_query = create_sql_query_chain(llm, db,final_prompt)

 chain = (
 RunnablePassthrough.assign(table_names_to_use=select_table) |
 RunnablePassthrough.assign(query=generate_query).assign(
     result=itemgetter(<span class="hljs-string">"query"</span>) | execute_query
 )
 | rephrase_answer
 )
</code></pre></div></div>
</li>
</ol>
<h4 id="heading-example-scenario-handling-follow-up-questions" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-example-scenario-handling-follow-up-questions" data-clipboard-text="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-example-scenario-handling-follow-up-questions" style="height: 28px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a>Example Scenario: Handling Follow-Up Questions</h4>
<p>Imagine a user first asks, "How many customers have an order count more than 5?" After receiving the answer, they follow up with, "Can you list their names?" With a memory feature, the chatbot can understand that the second question relates to the subset of customers identified in response to the first question, allowing it to generate an accurate follow-up query without needing the user to re-specify the context.</p>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-python">question = <span class="hljs-string">"How many cutomers with order count more than 5"</span>
response = chain.invoke({<span class="hljs-string">"question"</span>: question,<span class="hljs-string">"messages"</span>:history.messages})
There are <span class="hljs-number">2</span> customers <span class="hljs-keyword">with</span> an order count of more than <span class="hljs-number">5.</span>
</code></pre></div></div>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-python">history.add_user_message(question)
history.add_ai_message(response)
history.messages
[HumanMessage(content=<span class="hljs-string">'How many cutomers with order count more than 5'</span>),
 AIMessage(content=<span class="hljs-string">'There are 2 customers with an order count of more than 5.'</span>)]
</code></pre></div></div>
<div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><div style="position:relative;"><div><button class="absolute right-0 top-0 m-2 font-mono text-xs font-semibold uppercase text-white focus:outline-none"><span class="flex flex-row items-center leading-none"><span class="mr-1">Copy</span><svg class="h-4 w-4 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></span></button></div><pre><code class="lang-python">response = chain.invoke({<span class="hljs-string">"question"</span>: <span class="hljs-string">"Can you list there names?"</span>,<span class="hljs-string">"messages"</span>:history.messages})
response
The names of the customers <span class="hljs-keyword">with</span> more than <span class="hljs-number">5</span> orders are Mini Gifts Distributors Ltd. <span class="hljs-keyword">and</span> Euro+ Shopping Channel.
</code></pre></div></div>
<h2 id="heading-conclusion" class="permalink-heading"><a class="permalink-heading-button" title="Permalink" href="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-conclusion" data-clipboard-text="https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql#heading-conclusion" style="height: 40px;"><span class="hidden">Permalink</span><svg class="h-4 w-4 fill-current dark:text-white" viewBox="0 0 512 512"><path d="M301.148 394.702l-79.2 79.19c-50.778 50.799-133.037 50.824-183.84 0-50.799-50.778-50.824-133.037 0-183.84l79.19-79.2a132.833 132.833 0 013.532-3.403c7.55-7.005 19.795-2.004 20.208 8.286.193 4.807.598 9.607 1.216 14.384.481 3.717-.746 7.447-3.397 10.096-16.48 16.469-75.142 75.128-75.3 75.286-36.738 36.759-36.731 96.188 0 132.94 36.759 36.738 96.188 36.731 132.94 0l79.2-79.2.36-.36c36.301-36.672 36.14-96.07-.37-132.58-8.214-8.214-17.577-14.58-27.585-19.109-4.566-2.066-7.426-6.667-7.134-11.67a62.197 62.197 0 012.826-15.259c2.103-6.601 9.531-9.961 15.919-7.28 15.073 6.324 29.187 15.62 41.435 27.868 50.688 50.689 50.679 133.17 0 183.851zm-90.296-93.554c12.248 12.248 26.362 21.544 41.435 27.868 6.388 2.68 13.816-.68 15.919-7.28a62.197 62.197 0 002.826-15.259c.292-5.003-2.569-9.604-7.134-11.67-10.008-4.528-19.371-10.894-27.585-19.109-36.51-36.51-36.671-95.908-.37-132.58l.36-.36 79.2-79.2c36.752-36.731 96.181-36.738 132.94 0 36.731 36.752 36.738 96.181 0 132.94-.157.157-58.819 58.817-75.3 75.286-2.651 2.65-3.878 6.379-3.397 10.096a163.156 163.156 0 011.216 14.384c.413 10.291 12.659 15.291 20.208 8.286a131.324 131.324 0 003.532-3.403l79.19-79.2c50.824-50.803 50.799-133.062 0-183.84-50.802-50.824-133.062-50.799-183.84 0l-79.2 79.19c-50.679 50.682-50.688 133.163 0 183.851z"></path></svg></a><strong>Conclusion:</strong></h2>
<p>Through this guide, we've journeyed through the process of enhancing NL2SQL models using LangChain, showcasing how to transform natural language queries into precise SQL commands. This exploration not only highlights the power of LangChain in making database queries more accessible but also underscores the broader impact of integrating advanced NLP techniques for intuitive data interaction.</p>
<p>For those interested in delving deeper, a <a target="_blank" href="https://youtu.be/fss6CrmQU2Y">video walkthrough</a> and a comprehensive <a target="_blank" href="https://github.com/PradipNichite/Youtube-Tutorials/blob/main/Langchain_NL2SQL_2024.ipynb">GitHub notebook</a> and <a target="_blank" href="https://github.com/PradipNichite/Youtube-Tutorials/tree/main/Langchain%20NL2SQL%20Chatbot">Streamlit Code</a> are available to explore these concepts further. These resources offer visual demonstrations and hands-on examples to help bring these ideas to life in your own projects.</p>
<p>The journey toward more natural and efficient database interactions is ongoing, and with each step, we're making the world of data more accessible to all.</p>
<p>If you're curious about the latest in AI technology, I invite you to visit my project, AI Demos, at <a target="_blank" href="http://aidemos.com/"><strong></strong></a><strong><a href="http://aidemos.com/" class="autolinkedURL autolinkedURL-url" target="_blank">aidemos.com</a></strong><strong>. It's a rich resource offering a wide array of video demos showcasing the most advanced AI tools. My goal with AI Demos is to educate and illuminate the diverse possibilities of AI.</strong></p>
<p>For even more in-depth exploration, be sure to visit my YouTube channel at <a target="_blank" href="https://www.youtube.com/@aidemos.videos">https://www.youtube.com/@aidemos.videos</a><strong>. Here, you'll find a wealth of content that delves into the exciting future of AI and its various applications.</strong></p>
</div><style>.post-floating-bar {
              bottom: -60px;
            }
            .post-floating-bar.animation {
              -webkit-transition: .2s all;
              -o-transition: .2s all;
              transition: .2s all;
              transition-timing-function: ease-in;
            }
            .post-floating-bar.active {
              bottom: 40px
            }
            .post-floating-bar.freeze {
              bottom: 0!important;
              position: absolute!important;
              transition: none!important;
            }
            .post-floating-bar.freeze > div {
              box-shadow: none!important;
            }
            </style><div class="post-floating-bar fixed left-0 right-0 z-50 flex h-12 w-full flex-wrap justify-center 2xl:h-14 active animation"><div class="relative mx-auto flex h-12 shrink flex-wrap items-center justify-center rounded-full border-1/2 border-slate-200 bg-white px-5 py-1 text-sm text-slate-800 shadow-xl dark:border-slate-700 dark:bg-slate-900 dark:text-slate-50 2xl:h-14"><div class="relative"><style>
          @keyframes slideUpAndFade {
            from {
              opacity: 0;
              transform: translateY(2px);
            }
            to {
              opacity: 1;
              transform: translateY(0);
            }
          }

          .reaction-count-tooltip-content {
            box-shadow: hsl(206 22% 7% / 35%) 0px 10px 38px -10px, hsl(206 22% 7% / 20%) 0px 10px 20px -15px;
            user-select: none;
            transition: .2s all;
            animation-duration: 400ms;
            animation-timing-function: cubic-bezier(0.16, 1, 0.3, 1);
            will-change: transform, opacity;
          }
          .reaction-count-tooltip-content[data-state='instant-open'][data-side='top'] {
            animation-name: slideUpAndFade;
          }

          @keyframes shake {
            0% { transform: translateX(0) }
            25% { transform: translateX(1px) }
            50% { transform: translateX(-1px) }
            75% { transform: translateX(1px) }
            100% { transform: translateX(0) }
          }
          .shake {
            animation-name: shake;
            animation-iteration-count: 2;
            animation-duration: 400ms;
            animation-timing-function: cubic-bezier(0.16, 1, 0.3, 1);
            will-change: transform, opacity;
          }
          </style><div class="outline-none! relative flex cursor-pointer items-center"><div class="outline-none! relative flex w-8 cursor-pointer items-center sm:w-10"><button type="button" aria-label="Like this article" class="outline-none absolute z-50 rounded-full p-2 hover:bg-slate-100 focus:outline-none dark:hover:bg-slate-800" data-state="closed"><svg viewBox="0 0 22 20" fill="none" xmlns="http://www.w3.org/2000/svg" class="h-4 w-4 sm:h-5 sm:w-5 2xl:h-6 2xl:w-6 stroke-current text-slate-800 dark:text-slate-50"><path d="M11 19C12 19 21 14.0002 21 7.00043C21 3.50057 18 1.04405 15 1.00065C13.5 0.978943 12 1.50065 11 3.00059C10 1.50065 8.47405 1.00065 7 1.00065C4 1.00065 1 3.50057 1 7.00043C1 14.0002 10 19 11 19Z" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></button></div><div><button type="button" class="outline-none outline-none! text-sm text-slate-800 hover:underline dark:text-slate-200" data-state="closed">21</button></div></div></div><div data-orientation="vertical" aria-orientation="vertical" role="separator" class="my-auto w-px bg-slate-200 dark:bg-slate-700 mx-2 h-5"></div><div data-state="closed" class="outline-none"><button type="button" aria-label="5 comments, open the comments" class="outline-none! flex cursor-pointer items-center rounded-full hover:bg-slate-100 dark:hover:bg-slate-800"><span class="rounded-full p-2"><svg class="h-4 w-4 stroke-current text-slate-800 dark:text-slate-50 sm:h-5 sm:w-5 2xl:h-6 2xl:w-6" viewBox="0 0 18 18" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.5 10.6667H9.83333M6.5 7.75H12.3333M9 16.5C13.1421 16.5 16.5 13.1421 16.5 9C16.5 4.85786 13.1421 1.5 9 1.5C4.85786 1.5 1.5 4.85786 1.5 9C1.5 9.99762 1.69478 10.9497 2.04839 11.8204C2.11606 11.9871 2.1499 12.0704 2.165 12.1377C2.17976 12.2036 2.18516 12.2524 2.18517 12.3199C2.18518 12.3889 2.17265 12.4641 2.14759 12.6145L1.65344 15.5794C1.60169 15.8898 1.57582 16.0451 1.62397 16.1573C1.66611 16.2556 1.7444 16.3339 1.84265 16.376C1.95491 16.4242 2.11015 16.3983 2.42063 16.3466L5.38554 15.8524C5.53591 15.8273 5.61109 15.8148 5.68011 15.8148C5.74763 15.8148 5.79638 15.8202 5.86227 15.835C5.92962 15.8501 6.01294 15.8839 6.17958 15.9516C7.05025 16.3052 8.00238 16.5 9 16.5Z" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span><span class="ml-0.5 pr-2">5</span></button></div><div data-orientation="vertical" aria-orientation="vertical" role="separator" class="my-auto w-px bg-slate-200 dark:bg-slate-700 mx-2 h-5"></div><button class="border border-transparent text-base font-medium leading-relaxed text-slate-700 dark:text-slate-200 disabled:opacity-50 flex flex-row items-center focus:outline-none outline-none rounded-full p-2 hover:bg-slate-100 dark:hover:bg-slate-800" type="button" variant="transparent" aria-label="Open table of contents" data-state="closed"><svg class="h-4 w-4 fill-current text-slate-800 dark:text-slate-50 sm:h-5 sm:w-5 2xl:h-6 2xl:w-6" viewBox="0 0 512 512"><path d="M88 56H40a16 16 0 00-16 16v48a16 16 0 0016 16h48a16 16 0 0016-16V72a16 16 0 00-16-16zm0 160H40a16 16 0 00-16 16v48a16 16 0 0016 16h48a16 16 0 0016-16v-48a16 16 0 00-16-16zm0 160H40a16 16 0 00-16 16v48a16 16 0 0016 16h48a16 16 0 0016-16v-48a16 16 0 00-16-16zm416 24H168a8 8 0 00-8 8v16a8 8 0 008 8h336a8 8 0 008-8v-16a8 8 0 00-8-8zm0-320H168a8 8 0 00-8 8v16a8 8 0 008 8h336a8 8 0 008-8V88a8 8 0 00-8-8zm0 160H168a8 8 0 00-8 8v16a8 8 0 008 8h336a8 8 0 008-8v-16a8 8 0 00-8-8z"></path></svg></button><div data-orientation="vertical" aria-orientation="vertical" role="separator" class="my-auto w-px bg-slate-200 dark:bg-slate-700 mx-2 h-5"></div><button type="button" title="Add Bookmark" aria-label="Add Bookmark" class="outline-none outline-none! flex cursor-pointer items-center" data-state="closed"><span class="rounded-full p-2 hover:bg-slate-100 dark:hover:bg-slate-800"><svg viewBox="0 0 16 20" class="h-4 w-4 scale-[0.97] stroke-current text-slate-800 dark:text-slate-50 sm:h-5 sm:w-5 2xl:h-6 2xl:w-6" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M15.2 19V5.8C15.2 4.11984 15.2 3.27976 14.8731 2.63803C14.5854 2.07354 14.1265 1.6146 13.562 1.32698C12.9203 1 12.0802 1 10.4 1H5.60005C3.91989 1 3.07981 1 2.43808 1.32698C1.87359 1.6146 1.41465 2.07354 1.12703 2.63803C0.800049 3.27976 0.800049 4.11984 0.800049 5.8V19L5.85342 16.4733C6.64052 16.0798 7.03406 15.883 7.44686 15.8055C7.81246 15.737 8.18764 15.737 8.55324 15.8055C8.96603 15.883 9.35959 16.0798 10.1467 16.4733L15.2 19Z" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></span></button><div id="portal-content"></div><div data-orientation="vertical" aria-orientation="vertical" role="separator" class="my-auto w-px bg-slate-200 dark:bg-slate-700 mx-2 h-5"></div><button type="button" id="radix-:r5:" aria-haspopup="menu" aria-expanded="false" data-state="closed" aria-label="Share this article" class="outline-none outline-none! cursor-pointer rounded-full p-2 hover:bg-slate-100 dark:hover:bg-slate-800"><svg viewBox="0 0 18 18" fill="none" xmlns="http://www.w3.org/2000/svg" class="h-4 w-4 stroke-current text-slate-800 dark:text-slate-50 sm:h-5 sm:w-5 2xl:h-6 2xl:w-6"><path d="M6.25 7.91667L11.75 5.08333M6.25 10.0833L11.75 12.9167M6.5 9C6.5 10.3807 5.38071 11.5 4 11.5C2.61929 11.5 1.5 10.3807 1.5 9C1.5 7.61929 2.61929 6.5 4 6.5C5.38071 6.5 6.5 7.61929 6.5 9ZM16.5 4C16.5 5.38071 15.3807 6.5 14 6.5C12.6193 6.5 11.5 5.38071 11.5 4C11.5 2.61929 12.6193 1.5 14 1.5C15.3807 1.5 16.5 2.61929 16.5 4ZM16.5 14C16.5 15.3807 15.3807 16.5 14 16.5C12.6193 16.5 11.5 15.3807 11.5 14C11.5 12.6193 12.6193 11.5 14 11.5C15.3807 11.5 16.5 12.6193 16.5 14Z" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path></svg></button></div></div></div><div class="mb-5 flex w-full flex-row flex-wrap justify-center md:mb-0"><a class="mb-3 mr-3 rounded-lg border bg-slate-100 px-2 py-1 text-base font-medium text-slate-700 hover:bg-slate-200 dark:border-slate-800 dark:bg-slate-800 dark:text-slate-100 dark:hover:bg-slate-700" href="https://blog.futuresmart.ai/tag/langchain?source=tags_bottom_blogs"><span>langchain</span></a><a class="mb-3 mr-3 rounded-lg border bg-slate-100 px-2 py-1 text-base font-medium text-slate-700 hover:bg-slate-200 dark:border-slate-800 dark:bg-slate-800 dark:text-slate-100 dark:hover:bg-slate-700" href="https://blog.futuresmart.ai/tag/nl2sql?source=tags_bottom_blogs"><span>NL2SQL</span></a><a class="mb-3 mr-3 rounded-lg border bg-slate-100 px-2 py-1 text-base font-medium text-slate-700 hover:bg-slate-200 dark:border-slate-800 dark:bg-slate-800 dark:text-slate-100 dark:hover:bg-slate-700" href="https://blog.futuresmart.ai/tag/llm?source=tags_bottom_blogs"><span>llm</span></a><a class="mb-3 mr-3 rounded-lg border bg-slate-100 px-2 py-1 text-base font-medium text-slate-700 hover:bg-slate-200 dark:border-slate-800 dark:bg-slate-800 dark:text-slate-100 dark:hover:bg-slate-700" href="https://blog.futuresmart.ai/tag/text-to-sql?source=tags_bottom_blogs"><span>text to sql</span></a><a class="mb-3 mr-3 rounded-lg border bg-slate-100 px-2 py-1 text-base font-medium text-slate-700 hover:bg-slate-200 dark:border-slate-800 dark:bg-slate-800 dark:text-slate-100 dark:hover:bg-slate-700" href="https://blog.futuresmart.ai/tag/openai?source=tags_bottom_blogs"><span>openai</span></a><a class="mb-3 mr-3 rounded-lg border bg-slate-100 px-2 py-1 text-base font-medium text-slate-700 hover:bg-slate-200 dark:border-slate-800 dark:bg-slate-800 dark:text-slate-100 dark:hover:bg-slate-700" href="https://blog.futuresmart.ai/tag/chatgpt?source=tags_bottom_blogs"><span>chatgpt</span></a></div><div class="mb-5 mt-10 flex flex-col gap-16"><div class="flex-1 px-2"><div class="flex flex-col flex-wrap items-start md:flex-nowrap"><h3 class="mb-4 w-full border-b-1-1/2 pb-2 text-base font-medium tracking-wider text-slate-500 dark:border-slate-800 dark:text-slate-400 ">Written by</h3><div class="flex w-full flex-col gap-12"><div class="flex w-full flex-1 flex-col md:flex-row"><div class="mb-4 flex w-full flex-1 flex-row md:mb-0 "><div class="mr-4 flex flex-row md:mb-0"><a href="https://hashnode.com/@pnichite" class="block h-10 w-10 overflow-hidden rounded-full border dark:border-slate-800 md:h-14 md:w-14"><span style="box-sizing: border-box; display: inline-block; overflow: hidden; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 0px; position: relative; max-width: 100%;"><span style="box-sizing: border-box; display: block; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 0px; max-width: 100%;"><img alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27256%27%20height=%27256%27/%3e" style="display: block; max-width: 100%; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 0px;"></span><img alt="Pradip Nichite" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="block" style="position: absolute; inset: 0px; box-sizing: border-box; padding: 0px; border: none; margin: auto; display: block; width: 0px; height: 0px; min-width: 100%; max-width: 100%; min-height: 100%; max-height: 100%; background-size: cover; background-position: 0% 0%; filter: blur(20px); background-image: url(&quot;https://cdn.hashnode.com/res/hashnode/image/upload/v1629011734354/sgLB_1lXJ.jpeg?w=256&amp;h=256&amp;fit=crop&amp;crop=faces&amp;auto=compress,format&amp;format=webp&amp;fm=blurhash&quot;);"><noscript></noscript></span></a></div><div class="flex flex-1 flex-col justify-center md:justify-start"><div class="flex flex-row items-center md:mb-1"><h2 class="font-sans text-lg font-semibold text-slate-800 dark:text-slate-100"><a href="https://hashnode.com/@pnichite">Pradip Nichite</a></h2></div><div class="hidden pr-2 md:block"><div class="prose text-slate-600 dark:prose-dark dark:text-slate-300"><p>🚀 I'm a Top Rated Plus NLP freelancer on Upwork with over $300K in earnings and a 100% Job Success rate. This journey began in 2022 after years of enriching experience in the field of Data Science.
📚 Starting my career in 2013 as a Software Developer focusing on backend and API development, I soon pursued my interest in Data Science by earning my M.Tech in IT from IIIT Bangalore, specializing in Data Science (2016 - 2018).
💼 Upon graduation, I carved out a path in the industry as a Data Scientist at MiQ (2018 - 2020) and later ascended to the role of Lead Data Scientist at Oracle (2020 - 2022).
🌐 Inspired by my freelancing success, I founded FutureSmart AI in September 2022. We provide custom AI solutions for clients using the latest models and techniques in NLP.
🎥 In addition, I run AI Demos, a platform aimed at educating people about the latest AI tools through engaging video demonstrations.
🧰 My technical toolbox encompasses:
🔧 Languages: Python, JavaScript, SQL.
🧪 ML Libraries: PyTorch, Transformers, LangChain.
🔍 Specialties: Semantic Search, Sentence Transformers, Vector Databases.
🖥️ Web Frameworks: FastAPI, Streamlit, Anvil.
☁️ Other: AWS, AWS RDS, MySQL.
🚀 In the fast-evolving landscape of AI, FutureSmart AI and I stand at the forefront, delivering cutting-edge, custom NLP solutions to clients across various industries.</p>
</div></div></div></div><div class="mb-4 block md:hidden"><div class="prose text-slate-600 dark:prose-dark "><p>🚀 I'm a Top Rated Plus NLP freelancer on Upwork with over $300K in earnings and a 100% Job Success rate. This journey began in 2022 after years of enriching experience in the field of Data Science.
📚 Starting my career in 2013 as a Software Developer focusing on backend and API development, I soon pursued my interest in Data Science by earning my M.Tech in IT from IIIT Bangalore, specializing in Data Science (2016 - 2018).
💼 Upon graduation, I carved out a path in the industry as a Data Scientist at MiQ (2018 - 2020) and later ascended to the role of Lead Data Scientist at Oracle (2020 - 2022).
🌐 Inspired by my freelancing success, I founded FutureSmart AI in September 2022. We provide custom AI solutions for clients using the latest models and techniques in NLP.
🎥 In addition, I run AI Demos, a platform aimed at educating people about the latest AI tools through engaging video demonstrations.
🧰 My technical toolbox encompasses:
🔧 Languages: Python, JavaScript, SQL.
🧪 ML Libraries: PyTorch, Transformers, LangChain.
🔍 Specialties: Semantic Search, Sentence Transformers, Vector Databases.
🖥️ Web Frameworks: FastAPI, Streamlit, Anvil.
☁️ Other: AWS, AWS RDS, MySQL.
🚀 In the fast-evolving landscape of AI, FutureSmart AI and I stand at the forefront, delivering cutting-edge, custom NLP solutions to clients across various industries.</p>
</div></div><div class="flex flex-row items-start"><button type="button" class="author-follow-button tooltip-handle flex flex-row items-center text-center font-normal transition-colors duration-150 rounded-full px-4 py-2 text-sm disabled:opacity-50 disabled:cursor-not-allowed focus:outline-none hover:bg-opacity-90 h-10 border bg-transparent dark:border-slate-800 dark:bg-slate-800 dark:text-slate-300 border-blue-600 text-blue-600 hover:bg-blue-100" data-title="Follow user"><span class="">Follow</span></button></div></div></div></div></div><div class="flex-1 px-2"><div class="flex flex-col flex-wrap items-start md:flex-nowrap"><h3 class="mb-4 w-full border-b-1-1/2 pb-1 text-base font-medium tracking-wider text-slate-500 dark:border-slate-800 dark:text-slate-400 ">Published on</h3><div class="flex w-full flex-1 flex-col md:flex-row"><div class="mb-4 flex w-full flex-1 flex-row md:mb-0"><a href="https://blog.futuresmart.ai/" class="mr-5 block h-10 w-10 overflow-hidden rounded-lg border dark:border-slate-800 md:h-14 md:w-14"><div class="h-full w-full bg-slate-100 p-2 dark:bg-slate-800"><svg class="text-slate-500 dark:text-slate-300" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 40 40"><path stroke="currentColor" d="M5 15.6814H13.75M35 15.6814H24.1667H13.75M13.75 6.50977V15.6814M24.1667 33.4449L29.9715 33.478C32.744 33.4938 35 31.2494 35 28.4754V11.5125C35 8.74955 32.7614 6.50977 30 6.50977H10C7.23858 6.50977 5 8.74955 5 11.5125V28.4878C5 31.257 7.24839 33.4994 10.0161 33.4905L13.75 33.4785L24.1667 33.4449Z" stroke-width="2.5" stroke-linecap="round"></path></svg></div></a><div class="flex flex-1 flex-col justify-center md:justify-start"><h2 class="font-sans text-lg font-semibold text-slate-800 dark:text-slate-100"><a href="https://blog.futuresmart.ai/">FutureSmart AI Blog</a></h2><div class="hidden pr-2 md:block"><div class="prose text-slate-600 dark:prose-dark"><p>FutureSmart AI provides custom Natural Language Processing (NLP) solutions.</p>
</div></div></div></div><div class="mb-4 block md:hidden"><div class="prose text-slate-600 dark:prose-dark"><p>FutureSmart AI provides custom Natural Language Processing (NLP) solutions.</p>
</div></div><div class="flex flex-row items-start"><div class="md:mb-0"><button type="button" class="author-follow-button tooltip-handle flex flex-row items-center text-center font-normal transition-colors duration-150 rounded-full text-sm disabled:opacity-50 disabled:cursor-not-allowed focus:outline-none hover:bg-opacity-90 h-10 border bg-transparent px-5 py-2 dark:border-slate-800 dark:bg-slate-800 dark:text-slate-300 border-blue-600 text-blue-600 hover:bg-blue-100" data-title="Follow blog"><span class="">Follow</span></button></div></div></div></div></div></div></div></section></div><div class="absolute h-px w-px overflow-hidden" id="refNode1" style="top:100px;left:100px">&nbsp;</div><div class="absolute left-0 top-0 h-px w-px overflow-hidden" id="refNode2"></div><div class="absolute z-50 mt-4 hidden"><div class="flex flex-row items-center rounded-lg border border-slate-300 bg-white p-4 text-slate-800 shadow-lg dark:border-white dark:bg-slate-800 dark:text-slate-300"><span class="mr-3 block">Share this</span><a href="https://twitter.com/share?url=https%3A%2F%2Fblog.futuresmart.ai%2Fmastering-natural-language-to-sql-with-langchain-nl2sql&amp;text=%20%40pnichite" class="rounded-full border border-transparent py-1 font-medium text-slate-700 dark:text-slate-200 hover:bg-slate-200 disabled:opacity-50 hover:dark:bg-slate-700 flex flex-row items-center focus:outline-none px-2 text-sm" variant="transparent" target="_blank" rel="noopener"><svg class="h-6 w-6 stroke-current" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10.643 13.346L4.26862 4.86856C3.85863 4.32329 4.2478 3.54408 4.93001 3.54431L7.2184 3.54508C7.47633 3.54517 7.71945 3.66557 7.87585 3.87066L12.9065 10.4675M10.643 13.346L5.19311 20.5093M10.643 13.346L15.8028 20.077C15.9588 20.2805 16.2003 20.4001 16.4567 20.4009L18.7925 20.4082C19.4778 20.4104 19.8683 19.6261 19.4536 19.0805L12.9065 10.4675M12.9065 10.4675L18.2181 3.50928" stroke-width="1.5" stroke-linecap="round"></path></svg></a><a href="http://www.reddit.com/submit?title=Mastering%20Natural%20Language%20to%20SQL%20with%20LangChain%20%7C%20NL2SQL&amp;selftext=true&amp;text=%20https%3A%2F%2Fblog.futuresmart.ai%2Fmastering-natural-language-to-sql-with-langchain-nl2sql" class="rounded-full border border-transparent py-1 font-medium hover:bg-slate-200 disabled:opacity-50 hover:dark:bg-slate-700 flex flex-row items-center focus:outline-none px-2 text-sm text-red-600 dark:text-red-600" variant="transparent" target="_blank" rel="noopener"><svg class="h-6 w-6 fill-current" viewBox="0 0 512 512"><path d="M201.5 305.5c-13.8 0-24.9-11.1-24.9-24.6 0-13.8 11.1-24.9 24.9-24.9 13.6 0 24.6 11.1 24.6 24.9 0 13.6-11.1 24.6-24.6 24.6zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-132.3-41.2c-9.4 0-17.7 3.9-23.8 10-22.4-15.5-52.6-25.5-86.1-26.6l17.4-78.3 55.4 12.5c0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.3 24.9-24.9s-11.1-24.9-24.9-24.9c-9.7 0-18 5.8-22.1 13.8l-61.2-13.6c-3-.8-6.1 1.4-6.9 4.4l-19.1 86.4c-33.2 1.4-63.1 11.3-85.5 26.8-6.1-6.4-14.7-10.2-24.1-10.2-34.9 0-46.3 46.9-14.4 62.8-1.1 5-1.7 10.2-1.7 15.5 0 52.6 59.2 95.2 132 95.2 73.1 0 132.3-42.6 132.3-95.2 0-5.3-.6-10.8-1.9-15.8 31.3-16 19.8-62.5-14.9-62.5zM302.8 331c-18.2 18.2-76.1 17.9-93.6 0-2.2-2.2-6.1-2.2-8.3 0-2.5 2.5-2.5 6.4 0 8.6 22.8 22.8 87.3 22.8 110.2 0 2.5-2.2 2.5-6.1 0-8.6-2.2-2.2-6.1-2.2-8.3 0zm7.7-75c-13.6 0-24.6 11.1-24.6 24.9 0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.1 24.9-24.6 0-13.8-11-24.9-24.9-24.9z"></path></svg></a><button class="rounded-full border border-transparent py-1 font-medium text-slate-700 dark:text-slate-200 hover:bg-slate-200 disabled:opacity-50 hover:dark:bg-slate-700 flex flex-row items-center focus:outline-none px-2 text-sm" type="button" variant="transparent" data-clipboard-text=" https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql" id="text-sharer"><svg class="h-6 w-6 fill-current" viewBox="0 0 384 512"><path d="M336 64h-88.6c.4-2.6.6-5.3.6-8 0-30.9-25.1-56-56-56s-56 25.1-56 56c0 2.7.2 5.4.6 8H48C21.5 64 0 85.5 0 112v352c0 26.5 21.5 48 48 48h288c26.5 0 48-21.5 48-48V112c0-26.5-21.5-48-48-48zM192 32c13.3 0 24 10.7 24 24s-10.7 24-24 24-24-10.7-24-24 10.7-24 24-24zm160 432c0 8.8-7.2 16-16 16H48c-8.8 0-16-7.2-16-16V112c0-8.8 7.2-16 16-16h48v20c0 6.6 5.4 12 12 12h168c6.6 0 12-5.4 12-12V96h48c8.8 0 16 7.2 16 16z"></path></svg></button></div></div><div class="blog-more-articles mb-20 mt-10"><h3 class="blog-more-articles-title mb-5 text-center font-semibold uppercase tracking-wider text-slate-500 dark:text-slate-400">More articles</h3><div class="blog-more-articles-wrapper container mx-auto grid grid-flow-row grid-cols-6 px-4 xl:grid-cols-9 xl:gap-6 2xl:px-0"><div class="mb-5 px-2 dark:border-slate-800 lg:mb-0 col-span-full md:col-span-3 lg:col-span-2 xl:col-span-3"><div class="blog-similar-article-wrapper h-full rounded-lg border p-4 dark:border-slate-800"><div class="blog-similar-author-wrapper mb-3 flex flex-row items-center"><div class="flex flex-row items-center"><div class="mr-2 h-6 w-6 overflow-hidden rounded-full"><a href="https://hashnode.com/@Shreyas2301" class="relative block h-full w-full"><span style="box-sizing: border-box; display: inline-block; overflow: hidden; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 0px; position: relative; max-width: 100%;"><span style="box-sizing: border-box; display: block; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 0px; max-width: 100%;"><img alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2770%27%20height=%2770%27/%3e" style="display: block; max-width: 100%; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 0px;"></span><img alt="Shreyas Dhaware&#39;s photo" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="blog-similar-author-photo author-photo relative z-20 block w-full rounded-full" style="position: absolute; inset: 0px; box-sizing: border-box; padding: 0px; border: none; margin: auto; display: block; width: 0px; height: 0px; min-width: 100%; max-width: 100%; min-height: 100%; max-height: 100%;"><noscript></noscript></span></a></div><a href="https://hashnode.com/@Shreyas2301" class="blog-similar-author-name font-bold text-black dark:text-white">Shreyas Dhaware</a></div></div><a href="https://blog.futuresmart.ai/rag-system-with-async-fastapi-qdrant-langchain-and-openai?source=more_articles_bottom_blogs" class="blog-similar-article-cover post-cover mb-3 block rounded border bg-cover bg-center dark:border-slate-800"><span style="box-sizing: border-box; display: block; overflow: hidden; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 0px; position: relative;"><span style="box-sizing: border-box; display: block; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 52.4% 0px 0px;"></span><img alt="Building a RAG System with Async FastAPI, Qdrant, Langchain and OpenAI" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" class="rounded" style="position: absolute; inset: 0px; box-sizing: border-box; padding: 0px; border: none; margin: auto; display: block; width: 0px; height: 0px; min-width: 100%; max-width: 100%; min-height: 100%; max-height: 100%;"><noscript></noscript></span></a><div class="blog-post-details break-words"><h1 class="mb-2 font-heading text-2xl font-bold leading-tight tracking-tight text-slate-900 dark:text-white"><a href="https://blog.futuresmart.ai/rag-system-with-async-fastapi-qdrant-langchain-and-openai?source=more_articles_bottom_blogs">Building a RAG System with Async FastAPI, Qdrant, Langchain and OpenAI</a></h1><p class="text-base text-slate-700 dark:text-slate-400"><a href="https://blog.futuresmart.ai/rag-system-with-async-fastapi-qdrant-langchain-and-openai?source=more_articles_bottom_blogs">Introduction
In the era of advanced AI applications, Retrieval-Augmented Generation (RAG) stands out…</a></p></div></div></div><div class="mb-5 px-2 dark:border-slate-800 lg:mb-0 col-span-full md:col-span-3 lg:col-span-2 xl:col-span-3"><div class="blog-similar-article-wrapper h-full rounded-lg border p-4 dark:border-slate-800"><div class="blog-similar-author-wrapper mb-3 flex flex-row items-center"><div class="flex flex-row items-center"><div class="mr-2 h-6 w-6 overflow-hidden rounded-full"><a href="https://hashnode.com/@pruthviraj1727" class="relative block h-full w-full"><span style="box-sizing: border-box; display: inline-block; overflow: hidden; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 0px; position: relative; max-width: 100%;"><span style="box-sizing: border-box; display: block; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 0px; max-width: 100%;"><img alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2770%27%20height=%2770%27/%3e" style="display: block; max-width: 100%; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 0px;"></span><img alt="Pruthviraj Mahalunge&#39;s photo" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="blog-similar-author-photo author-photo relative z-20 block w-full rounded-full" style="position: absolute; inset: 0px; box-sizing: border-box; padding: 0px; border: none; margin: auto; display: block; width: 0px; height: 0px; min-width: 100%; max-width: 100%; min-height: 100%; max-height: 100%;"><noscript></noscript></span></a></div><a href="https://hashnode.com/@pruthviraj1727" class="blog-similar-author-name font-bold text-black dark:text-white">Pruthviraj Mahalunge</a></div></div><a href="https://blog.futuresmart.ai/building-an-async-similarity-search-system-from-scratch-with-fastapi-and-qdrant-vectordb?source=more_articles_bottom_blogs" class="blog-similar-article-cover post-cover mb-3 block rounded border bg-cover bg-center dark:border-slate-800"><span style="box-sizing: border-box; display: block; overflow: hidden; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 0px; position: relative;"><span style="box-sizing: border-box; display: block; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 52.4% 0px 0px;"></span><img alt="Building an Async Similarity Search System from scratch with FastAPI and Qdrant VectorDB" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" class="rounded" style="position: absolute; inset: 0px; box-sizing: border-box; padding: 0px; border: none; margin: auto; display: block; width: 0px; height: 0px; min-width: 100%; max-width: 100%; min-height: 100%; max-height: 100%;"><noscript></noscript></span></a><div class="blog-post-details break-words"><h1 class="mb-2 font-heading text-2xl font-bold leading-tight tracking-tight text-slate-900 dark:text-white"><a href="https://blog.futuresmart.ai/building-an-async-similarity-search-system-from-scratch-with-fastapi-and-qdrant-vectordb?source=more_articles_bottom_blogs">Building an Async Similarity Search System from scratch with FastAPI and Qdrant VectorDB</a></h1><p class="text-base text-slate-700 dark:text-slate-400"><a href="https://blog.futuresmart.ai/building-an-async-similarity-search-system-from-scratch-with-fastapi-and-qdrant-vectordb?source=more_articles_bottom_blogs">Introduction
Search engines and retrieval systems have evolved to become remarkably intelligent. The…</a></p></div></div></div><div class="mb-5 px-2 dark:border-slate-800 lg:mb-0 col-span-full md:col-span-3 lg:col-span-2 xl:col-span-3"><div class="blog-similar-article-wrapper h-full rounded-lg border p-4 dark:border-slate-800"><div class="blog-similar-author-wrapper mb-3 flex flex-row items-center"><div class="flex flex-row items-center"><div class="mr-2 h-6 w-6 overflow-hidden rounded-full"><a href="https://hashnode.com/@Shreyas2301" class="relative block h-full w-full"><span style="box-sizing: border-box; display: inline-block; overflow: hidden; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 0px; position: relative; max-width: 100%;"><span style="box-sizing: border-box; display: block; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 0px; max-width: 100%;"><img alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2770%27%20height=%2770%27/%3e" style="display: block; max-width: 100%; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 0px;"></span><img alt="Shreyas Dhaware&#39;s photo" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="blog-similar-author-photo author-photo relative z-20 block w-full rounded-full" style="position: absolute; inset: 0px; box-sizing: border-box; padding: 0px; border: none; margin: auto; display: block; width: 0px; height: 0px; min-width: 100%; max-width: 100%; min-height: 100%; max-height: 100%;"><noscript></noscript></span></a></div><a href="https://hashnode.com/@Shreyas2301" class="blog-similar-author-name font-bold text-black dark:text-white">Shreyas Dhaware</a></div></div><a href="https://blog.futuresmart.ai/comprehensive-guide-to-qdrant-vector-db-installation-and-setup?source=more_articles_bottom_blogs" class="blog-similar-article-cover post-cover mb-3 block rounded border bg-cover bg-center dark:border-slate-800"><span style="box-sizing: border-box; display: block; overflow: hidden; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 0px; position: relative;"><span style="box-sizing: border-box; display: block; width: initial; height: initial; background: none; opacity: 1; border: 0px; margin: 0px; padding: 52.4% 0px 0px;"></span><img alt="Comprehensive guide to Qdrant Vector DB: Installation and Setup" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="responsive" class="rounded" style="position: absolute; inset: 0px; box-sizing: border-box; padding: 0px; border: none; margin: auto; display: block; width: 0px; height: 0px; min-width: 100%; max-width: 100%; min-height: 100%; max-height: 100%;"><noscript></noscript></span></a><div class="blog-post-details break-words"><h1 class="mb-2 font-heading text-2xl font-bold leading-tight tracking-tight text-slate-900 dark:text-white"><a href="https://blog.futuresmart.ai/comprehensive-guide-to-qdrant-vector-db-installation-and-setup?source=more_articles_bottom_blogs">Comprehensive guide to Qdrant Vector DB: Installation and Setup</a></h1><p class="text-base text-slate-700 dark:text-slate-400"><a href="https://blog.futuresmart.ai/comprehensive-guide-to-qdrant-vector-db-installation-and-setup?source=more_articles_bottom_blogs">Introduction:
In the era of AI-driven applications and unstructured data management, vector database…</a></p></div></div></div></div></div><div class="container relative z-20 mx-auto grid grid-flow-row grid-cols-8 xl:gap-6 2xl:grid-cols-10"><div class="blog-comments-section-wrapper col-span-8 px-4 lg:col-span-6 lg:col-start-2 lg:px-0 xl:col-span-6 xl:col-start-2 2xl:col-span-6 2xl:col-start-3"></div></div></article></main></div><div class="blog-footer border-t bg-slate-100 dark:border-slate-800 dark:bg-slate-950"><footer class="container mx-auto grid grid-cols-2 items-center gap-12 px-4 pb-20 pt-10 xl:px-10 2xl:px-24"><div class="col-span-full flex flex-col items-center gap-3 md:col-span-1 md:items-start md:gap-5"><p class="text-sm font-medium text-slate-600 dark:text-slate-400">©2025 FutureSmart AI Blog</p></div><div class="col-span-full md:col-span-1"><div class="flex flex-row flex-wrap justify-center gap-2 text-sm text-slate-800 dark:text-slate-200 md:flex-nowrap md:justify-end"><a class="hover:text-blue-600 dark:hover:text-blue-500" rel="noopener" href="https://blog.futuresmart.ai/archive">Archive</a><span class="font-extrabold text-slate-500 dark:text-slate-400">·</span><a href="https://hashnode.com/privacy?source=blog-footer" class="hover:text-blue-600 dark:hover:text-blue-500">Privacy policy</a><span class="font-extrabold text-slate-500 dark:text-slate-400">·</span><a class="hover:text-blue-600 dark:hover:text-blue-500" href="https://hashnode.com/terms?source=blog-footer">Terms</a></div></div><div class="col-span-full flex flex-row items-center justify-center gap-1 text-slate-600 dark:text-slate-500"><svg fill="none" class="h-3 w-3 stroke-current" viewBox="0 0 24 24"><path stroke="currentColor" stroke-width="1.5" d="M11.2 5.06s.3-1.295.8-1.295.8 1.295.8 1.295c1.34 4.47 1.67 4.8 6.14 6.14 0 0 1.295.3 1.295.8s-1.295.8-1.295.8c-4.47 1.34-4.8 1.67-6.14 6.14 0 0-.3 1.295-.8 1.295s-.8-1.295-.8-1.295c-1.34-4.47-1.67-4.8-6.14-6.14 0 0-1.295-.3-1.295-.8s1.295-.8 1.295-.8c4.47-1.34 4.8-1.67 6.14-6.14Z"></path></svg><svg fill="none" class="h-3 w-3 stroke-current" viewBox="0 0 24 24"><path stroke="currentColor" stroke-width="1.5" d="M11.2 5.06s.3-1.295.8-1.295.8 1.295.8 1.295c1.34 4.47 1.67 4.8 6.14 6.14 0 0 1.295.3 1.295.8s-1.295.8-1.295.8c-4.47 1.34-4.8 1.67-6.14 6.14 0 0-.3 1.295-.8 1.295s-.8-1.295-.8-1.295c-1.34-4.47-1.67-4.8-6.14-6.14 0 0-1.295-.3-1.295-.8s1.295-.8 1.295-.8c4.47-1.34 4.8-1.67 6.14-6.14Z"></path></svg><svg fill="none" class="h-3 w-3 stroke-current" viewBox="0 0 24 24"><path stroke="currentColor" stroke-width="1.5" d="M11.2 5.06s.3-1.295.8-1.295.8 1.295.8 1.295c1.34 4.47 1.67 4.8 6.14 6.14 0 0 1.295.3 1.295.8s-1.295.8-1.295.8c-4.47 1.34-4.8 1.67-6.14 6.14 0 0-.3 1.295-.8 1.295s-.8-1.295-.8-1.295c-1.34-4.47-1.67-4.8-6.14-6.14 0 0-1.295-.3-1.295-.8s1.295-.8 1.295-.8c4.47-1.34 4.8-1.67 6.14-6.14Z"></path></svg><svg fill="none" class="h-3 w-3 stroke-current" viewBox="0 0 24 24"><path stroke="currentColor" stroke-width="1.5" d="M11.2 5.06s.3-1.295.8-1.295.8 1.295.8 1.295c1.34 4.47 1.67 4.8 6.14 6.14 0 0 1.295.3 1.295.8s-1.295.8-1.295.8c-4.47 1.34-4.8 1.67-6.14 6.14 0 0-.3 1.295-.8 1.295s-.8-1.295-.8-1.295c-1.34-4.47-1.67-4.8-6.14-6.14 0 0-1.295-.3-1.295-.8s1.295-.8 1.295-.8c4.47-1.34 4.8-1.67 6.14-6.14Z"></path></svg></div><div class="col-span-full flex flex-col items-center justify-center gap-5 text-slate-600 dark:text-slate-400"><a href="https://hashnode.com/?source=blog-footer" target="_Blank" rel="noopener" class="hover:text-slate-800 dark:hover:text-slate-50"><svg class="h-8 w-8 fill-current" viewBox="0 0 200 200" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M13.742 66.824c-18.323 18.323-18.323 48.029 0 66.352l53.082 53.082c18.323 18.323 48.029 18.323 66.352 0l53.082-53.082c18.323-18.323 18.323-48.03 0-66.352l-53.082-53.082c-18.323-18.323-48.03-18.323-66.352 0L13.742 66.824zm109.481 56.399c12.826-12.826 12.826-33.62 0-46.446s-33.62-12.826-46.446 0-12.826 33.62 0 46.446 33.62 12.826 46.446 0z"></path></svg></a><p class="text-center text-sm">Powered by Hashnode - Build your developer hub.</p><div class="flex flex-row gap-2"><a href="https://hashnode.com/products/blogs?source=blog-footer" class="block rounded-lg border bg-white px-4 py-2 text-sm hover:bg-slate-50 dark:border-slate-700 dark:bg-slate-900 dark:hover:bg-slate-800">Start your blog</a><a href="https://hashnode.com/products/docs?source=blog-footer" class="block rounded-lg border bg-white px-4 py-2 text-sm hover:bg-slate-50 dark:border-slate-700 dark:bg-slate-900 dark:hover:bg-slate-800">Create docs</a></div></div></footer></div></div></div><script type="text/javascript">
              var SUPPORTS_PASSIVE = false;
              try {
                var opts = Object.defineProperty({}, 'passive', {
                  get: function() {
                    SUPPORTS_PASSIVE = true;
                  }
                });
                window.addEventListener("testPassive", null, opts);
                window.removeEventListener("testPassive", null, opts);
              } catch (e) {}
            </script><script type="text/javascript">
              // Array.prototype.flat polyfill
              if (!Array.prototype.flat) {
                // eslint-disable-next-line no-extend-native
                Object.defineProperty(Array.prototype, 'flat', {
                  configurable: true,
                  writable: true,
                  value() {
                    // eslint-disable-next-line prefer-rest-params
                    const depth = typeof arguments[0] === 'undefined' ? 1 : Number(arguments[0]) || 0;
                    const result = [];
                    const { forEach } = result;

                    // eslint-disable-next-line no-var
                    var flatDeep = function (arr, depth) {
                      forEach.call(arr, (val) => {
                        if (depth > 0 && Array.isArray(val)) {
                          flatDeep(val, depth - 1);
                        } else {
                          result.push(val);
                        }
                      });
                    };

                    flatDeep(this, depth);
                    return result;
                  },
                });
              }
            </script><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":"{\"_id\":\"65eedf3f2e25d54cd93c3d52\",\"partOfPublication\":true,\"author\":{\"_id\":\"610e6befb79d6a11366814e1\",\"name\":\"Pradip Nichite\",\"photo\":\"https://cdn.hashnode.com/res/hashnode/image/upload/v1629011734354/sgLB_1lXJ.jpeg\",\"username\":\"pnichite\",\"bio\":\"\u003cp\u003e🚀 I'm a Top Rated Plus NLP freelancer on Upwork with over $300K in earnings and a 100% Job Success rate. This journey began in 2022 after years of enriching experience in the field of Data Science.\\n📚 Starting my career in 2013 as a Software Developer focusing on backend and API development, I soon pursued my interest in Data Science by earning my M.Tech in IT from IIIT Bangalore, specializing in Data Science (2016 - 2018).\\n💼 Upon graduation, I carved out a path in the industry as a Data Scientist at MiQ (2018 - 2020) and later ascended to the role of Lead Data Scientist at Oracle (2020 - 2022).\\n🌐 Inspired by my freelancing success, I founded FutureSmart AI in September 2022. We provide custom AI solutions for clients using the latest models and techniques in NLP.\\n🎥 In addition, I run AI Demos, a platform aimed at educating people about the latest AI tools through engaging video demonstrations.\\n🧰 My technical toolbox encompasses:\\n🔧 Languages: Python, JavaScript, SQL.\\n🧪 ML Libraries: PyTorch, Transformers, LangChain.\\n🔍 Specialties: Semantic Search, Sentence Transformers, Vector Databases.\\n🖥️ Web Frameworks: FastAPI, Streamlit, Anvil.\\n☁️ Other: AWS, AWS RDS, MySQL.\\n🚀 In the fast-evolving landscape of AI, FutureSmart AI and I stand at the forefront, delivering cutting-edge, custom NLP solutions to clients across various industries.\u003c/p\u003e\\n\",\"socialMedia\":{\"website\":\"https://www.futuresmart.ai/\",\"github\":\"\",\"twitter\":\"\",\"facebook\":\"\",\"stackoverflow\":\"\",\"linkedin\":\"https://www.linkedin.com/in/pradipnichite/\"},\"isDeactivated\":false},\"bookmarkedIn\":[],\"publication\":{\"_id\":\"6294f745136694dfeee8e80c\",\"author\":{\"_id\":\"610e6befb79d6a11366814e1\",\"name\":\"Pradip Nichite\",\"photo\":\"https://cdn.hashnode.com/res/hashnode/image/upload/v1629011734354/sgLB_1lXJ.jpeg\",\"username\":\"pnichite\"},\"badgePageEnabled\":true,\"description\":\"Learn how to build custom Natural Language Processing (NLP) solutions using state-of-the-art models. Use Pytorch, Amazon Lex, FastAPI, and Hugging Face Transformers to create powerful applications.\",\"domain\":\"blog.futuresmart.ai\",\"domainStatus\":{\"ready\":true,\"certIssued\":true},\"wwwPrefixedDomainStatus\":{},\"customCSSEnabled\":false,\"customCSSPublished\":{\"homeMin\":\"\",\"postMin\":\"\",\"staticMin\":\"\"},\"customRules\":[],\"darkModeLogo\":\"\",\"disableFooterBranding\":false,\"isSubscriptionModalDisabled\":false,\"publicMembersCount\":16,\"displayTitle\":\"Building Custom NLP Solutions using state of the art NLP models | FutureSmart AI\",\"fathomCustomDomain\":\"\",\"fathomSiteID\":\"\",\"favicon\":\"\",\"fbPixelID\":\"\",\"gaTrackingID\":\"G-X68KZGCNTQ\",\"gTagManagerID\":\"\",\"hasBadges\":true,\"headerColor\":\"#2962FF\",\"hideMembersPage\":false,\"hotjarSiteID\":\"\",\"isTeam\":true,\"layout\":\"stacked\",\"matomoURL\":\"\",\"membersPageEnabled\":true,\"menu\":[{\"_id\":\"6294fc0d1ef08fdfc9f632ba\",\"label\":\"website\",\"type\":\"link\",\"url\":\"https://www.futuresmart.ai/\"},{\"_id\":\"6358d50ff001c905d3bc60be\",\"label\":\"Youtube\",\"type\":\"link\",\"url\":\"https://www.youtube.com/c/PradipNichiteAI\"},{\"_id\":\"6358d543c1d1be05714fa376\",\"label\":\"LinkedIN\",\"type\":\"link\",\"url\":\"https://www.linkedin.com/in/pradipnichite/\"},{\"_id\":\"63ca4e7d587fc59d3cd72863\",\"label\":\"AI Demos\",\"type\":\"link\",\"url\":\"https://www.aidemos.com/\"}],\"metaHTML\":\"\u003cp\u003eFutureSmart AI provides custom Natural Language Processing (NLP) solutions.\u003c/p\u003e\\n\",\"metaHTMLSanitized\":\"FutureSmart AI provides custom Natural Language Processing (NLP) solutions.\\n\",\"newsletterEnabled\":false,\"proTeamEnabled\":false,\"newsletterPageEnabled\":true,\"ogImage\":\"\",\"logo\":\"\",\"textSelectionSharerEnabled\":true,\"title\":\"FutureSmart AI Blog\",\"urlPattern\":\"simple\",\"username\":\"pnichite-1653929794900\",\"viewCountVisible\":false,\"wmPaymentPointer\":\"\",\"readTimeHidden\":false,\"links\":{\"twitter\":\"\",\"instagram\":\"https://www.instagram.com/futuresmart.ai\",\"github\":\"\",\"website\":\"https://www.futuresmart.ai/\",\"hashnode\":\"\",\"youtube\":\"https://www.youtube.com/c/PradipNichiteAI\",\"dailydev\":\"\",\"linkedin\":\"\",\"mastodon\":\"\",\"facebook\":\"\"},\"numPosts\":105,\"sponsorship\":{\"content\":\"\",\"contentMarkdown\":\"\"},\"allowContributorEdits\":true,\"allowCrawlingByGPT\":false},\"tags\":[{\"_id\":\"63f859c05e428f179a5cf8f3\",\"slug\":\"langchain\",\"name\":\"langchain\",\"isActive\":true,\"isApproved\":true},{\"_id\":\"63fef3fddc65a8ca9c1e0b0d\",\"slug\":\"nl2sql\",\"name\":\"NL2SQL\",\"isActive\":true,\"isApproved\":true},{\"_id\":\"635ad52efe8087002dee4707\",\"slug\":\"llm\",\"name\":\"llm\",\"isActive\":true,\"isApproved\":true},{\"_id\":\"642f259f311bf43ae82a8390\",\"slug\":\"text-to-sql\",\"name\":\"text to sql\",\"isActive\":true,\"isApproved\":true},{\"_id\":\"5f1a7b4309e95d4d18c3b2ee\",\"slug\":\"openai\",\"name\":\"openai\",\"isActive\":true,\"isApproved\":true},{\"_id\":\"638891761e50d717cbfd7b5b\",\"slug\":\"chatgpt\",\"name\":\"chatgpt\",\"isActive\":true,\"isApproved\":true}],\"coAuthors\":[],\"responseCount\":5,\"replyCount\":0,\"contentMarkdown\":\"## Introduction\\n\\nWelcome to our deep dive into revolutionizing the way we interact with databases using Natural Language Processing (NLP) and LangChain. In today's data-driven world, the ability to query databases without needing to know complex SQL syntax opens up a myriad of possibilities across various industries, from healthcare to finance, making data more accessible to everyone.\\n\\nThis blog post aims to guide you through a comprehensive journey to master NL2SQL using LangChain. We will explore the steps necessary to build an intuitive, efficient, and intelligent NL2SQL model that can understand and process natural language queries, dynamically select relevant database tables, and maintain a conversational context to handle follow-up questions effectively.\\n\\nBy the end of this post, you'll have a solid understanding of:\\n\\n1. **Building a Basic NL2SQL Model**: The foundation of translating natural language queries into SQL commands.\\n    \\n2. **Incorporating Few-Shot Learning**: Enhancing model accuracy with examples.\\n    \\n3. **Dynamic Few-Shot Example Selection**: Tailoring examples to the query context for improved relevance.\\n    \\n4. **Dynamic Relevant Table Selection**: Automatically identifying which tables to query based on the natural language input.\\n    \\n5. **Customizing Prompts and Responses**: Fine-tuning the model's interaction to provide clear, concise, and relevant answers.\\n    \\n6. **Adding Memory to Chatbots**: Enabling the model to handle follow-up questions by remembering the context of the conversation.\\n    \\n\\nThrough each of these steps, we'll discuss the concepts, show you how to implement them , and illustrate the outcomes , ensuring you have the tools and knowledge needed to bring the power of NL2SQL to your databases.\\n\\nLet's embark on this exciting journey to unlock the full potential of your data, making database queries as simple as conversing with a friend.\\n\\n## Building a Basic NL2SQL Model\\n\\nThe first step in our journey to revolutionize database querying with natural language is constructing a basic NL2SQL model using LangChain. This foundational model serves as the cornerstone for more advanced functionalities we'll explore later. Here's how we begin:\\n\\n#### Understanding the Basics\\n\\nAt its core, an NL2SQL model aims to translate natural language queries into SQL commands. But how do we start building such a model with LangChain?\\n\\n#### Setting Up LangChain\\n\\nLangChain simplifies the process of creating NL2SQL models by providing a flexible framework that integrates seamlessly with existing databases and natural language processing (NLP) models. To get started, you'll need to:\\n\\n1. **Install LangChain**: Ensure that LangChain is installed in your environment.\\n    \\n    ```bash\\n    pip install langchain_openai langchain_community langchain pymysql chromadb -q\\n    ```\\n    \\n2. **Connect to Your Database**: The next step involves establishing a connection to your database. LangChain supports various database systems, so you'll likely find your database among the supported ones. You'll use the database credentials to create a connection that LangChain can use to interact with your data\\n    \\n    ```python\\n    import os\\n    os.environ[\\\"OPENAI_API_KEY\\\"] = \\\"\\\"\\n    \\n    db_user = \\\"\\\"\\n    db_password = \\\"\\\"\\n    db_host = \\\"\\\"\\n    db_name = \\\"classicmodels\\\"\\n    from langchain_community.utilities.sql_database import SQLDatabase\\n    # db = SQLDatabase.from_uri(f\\\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\\\",sample_rows_in_table_info=1,include_tables=['customers','orders'],custom_table_info={'customers':\\\"customer\\\"})\\n    db = SQLDatabase.from_uri(f\\\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\\\")\\n    print(db.dialect)\\n    print(db.get_usable_table_names())\\n    print(db.table_info)\\n    ```\\n    \\n\\n#### The First Query\\n\\nOnce the setup is complete, the real magic begins. You can start by formulating a simple query in natural language, such as \\\"Show me all products priced above $100.\\\" LangChain takes this input and, through its integration with language models like ChatGPT and your database, generates an SQL query that precisely captures the intent of your request\\n\\n```python\\nfrom langchain.chains import create_sql_query_chain\\nfrom langchain_openai import ChatOpenAI\\n\\nllm = ChatOpenAI(model=\\\"gpt-3.5-turbo\\\", temperature=0)\\ngenerate_query = create_sql_query_chain(llm, db)\\nquery = generate_query.invoke({\\\"question\\\": \\\"what is price of `1968 Ford Mustang`\\\"})\\n# \\\"what is price of `1968 Ford Mustang`\\\"\\nprint(query)\\n```\\n\\n#### Seeing the Results\\n\\nExecuting the generated SQL query against your database retrieves the data you're looking for, which LangChain can then present in a user-friendly format.\\n\\n```python\\nfrom langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\\nexecute_query = QuerySQLDataBaseTool(db=db)\\nexecute_query.invoke(query)\\n```\\n\\n#### Moving Forward\\n\\nWith the basic NL2SQL model set up, you've taken the first step towards transforming how we interact with databases. However, this is just the beginning. As we progress, we'll explore how to enhance the model's accuracy, handle more complex queries, and even maintain context over a conversation for follow-up questions.\\n\\n## Rephrasing Answers for Enhanced Clarity\\n\\nAfter your NL2SQL model successfully executes a SQL query, the next pivotal step is to present the data in a manner that's easily understandable by your users. This is where the art of rephrasing SQL results into clear, natural language answers comes into play. Here's how you can achieve this with LangChain:\\n\\n#### Implementing Rephrasing with LangChain\\n\\n1. **Use Prompt Templates**: LangChain allows you to create prompt templates that can guide the model in how to rephrase SQL results. These templates can include placeholders for the original question, the SQL query, and the query result, setting the stage for generating a natural language response\\n    \\n    ```python\\n    from operator import itemgetter\\n    \\n    from langchain_core.output_parsers import StrOutputParser\\n    from langchain_core.prompts import PromptTemplate\\n    from langchain_core.runnables import RunnablePassthrough\\n    \\n    answer_prompt = PromptTemplate.from_template(\\n        \\\"\\\"\\\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\\n    \\n    Question: {question}\\n    SQL Query: {query}\\n    SQL Result: {result}\\n    Answer: \\\"\\\"\\\"\\n    )\\n    \\n    rephrase_answer = answer_prompt | llm | StrOutputParser()\\n    \\n    chain = (\\n        RunnablePassthrough.assign(query=generate_query).assign(\\n            result=itemgetter(\\\"query\\\") | execute_query\\n        )\\n        | rephrase_answer\\n    )\\n    \\n    chain.invoke({\\\"question\\\": \\\"How many customers have an order count greater than 5\\\"})\\n    ```\\n    \\n\\n#### Example: Transforming SQL Results into User-Friendly Responses\\n\\nLet's consider a user asks, \\\"How many customers have an order count greater than 5?\\\" and the SQL query returns a raw numerical result. The rephrasing process would convert this into a more readable answer, such as \\\"There are 2 customers with an order count of more than 5.\\\" This step is vital in closing the loop between user queries and database responses, ensuring that the information provided is both useful and easily digestible\\n\\n```plaintext\\nThere are 2 customers with an order count of more than 5.\\n```\\n\\nIn the next section, we'll dive into the exciting world of few-shot learning and how it can be used to improve the performance of your NL2SQL model with LangChain. Stay tuned to unlock the full potential of natural language database querying.\\n\\n## Enhancing NL2SQL Models with Few-Shot Examples\\n\\nThis technique involves providing the model with a small set of carefully selected examples that demonstrate how to convert natural language questions into SQL queries. Few-shot learning can significantly improve the model's ability to understand and generate precise SQL commands based on user queries, bridging the gap between human language and database querying.\\n\\n#### Incorporating Few-Shot Examples into LangChain\\n\\n1. **Selecting Relevant Examples**: The first step is to curate a set of examples that cover a broad range of query types and complexities. These examples should ideally reflect the most common or critical queries your users might perform\\n    \\n    ```plaintext\\n    examples = [\\n        {\\n            \\\"input\\\": \\\"List all customers in France with a credit limit over 20,000.\\\",\\n            \\\"query\\\": \\\"SELECT * FROM customers WHERE country = 'France' AND creditLimit \u003e 20000;\\\"\\n        },\\n        {\\n            \\\"input\\\": \\\"Get the highest payment amount made by any customer.\\\",\\n            \\\"query\\\": \\\"SELECT MAX(amount) FROM payments;\\\"\\n        },\\n       .....\\n    ]\\n    ```\\n    \\n2. **Creating a Few-Shot Learning Template**: With LangChain, you can design a prompt template that incorporates these examples into the model's workflow. The template instructs the model to consider the examples when generating SQL queries from new user questions\\n    \\n    ```python\\n    from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder,FewShotChatMessagePromptTemplate,PromptTemplate\\n    \\n    example_prompt = ChatPromptTemplate.from_messages(\\n        [\\n            (\\\"human\\\", \\\"{input}\\\\nSQLQuery:\\\"),\\n            (\\\"ai\\\", \\\"{query}\\\"),\\n        ]\\n    )\\n    few_shot_prompt = FewShotChatMessagePromptTemplate(\\n        example_prompt=example_prompt,\\n        examples=examples,\\n        # input_variables=[\\\"input\\\",\\\"top_k\\\"],\\n        input_variables=[\\\"input\\\"],\\n    )\\n    print(few_shot_prompt.format(input1=\\\"How many products are there?\\\"))\\n    ```\\n    \\n    ```plaintext\\n    Human: List all customers in France with a credit limit over 20,000.\\n    SQLQuery:\\n    AI: SELECT * FROM customers WHERE country = 'France' AND creditLimit \u003e 20000;\\n    Human: Get the highest payment amount made by any customer.\\n    SQLQuery:\\n    AI: SELECT MAX(amount) FROM payments;\\n    ......\\n    ```\\n    \\n\\n#### The Impact of Few-Shot Learning\\n\\nBy integrating few-shot examples, your NL2SQL model becomes more adept at handling a wider variety of user queries. This not only improves the user experience by providing more accurate and relevant responses but also reduces the potential for errors in SQL query generation.\\n\\nIn the next section, we'll explore the integration of dynamic example selection to further enhance the model's accuracy and relevance, ensuring that your NL2SQL system remains adaptive and responsive to user queries.\\n\\n## Dynamic Few-Shot Example Selection:\\n\\nThis advanced technique tailors the few-shot examples provided to the model based on the specific context of the user's query. It ensures that the guidance offered to the model is not just relevant but optimally aligned with the query's nuances, significantly boosting the model's ability to generate accurate SQL queries.\\n\\n#### The Need for Dynamism\\n\\nStatic few-shot examples, though highly effective, have their limitations. Dynamic selection addresses this by intelligently choosing examples that closely match the intent and context of each new query, providing a customized learning experience for the model with every interaction.\\n\\n#### Implementing Dynamic Few-Shot Selection\\n\\n1. **Example Selector Configuration**: Begin by setting up an example selector that can analyze the semantics of the user's query and compare it with a repository of potential examples. Tools like semantic similarity algorithms and vector embeddings come into play here, identifying which examples are most relevant to the current query\\n    \\n    ```python\\n    from langchain_community.vectorstores import Chroma\\n    from langchain_core.example_selectors import SemanticSimilarityExampleSelector\\n    from langchain_openai import OpenAIEmbeddings\\n    \\n    vectorstore = Chroma()\\n    vectorstore.delete_collection()\\n    example_selector = SemanticSimilarityExampleSelector.from_examples(\\n        examples,\\n        OpenAIEmbeddings(),\\n        vectorstore,\\n        k=2,\\n        input_keys=[\\\"input\\\"],\\n    )\\n    example_selector.select_examples({\\\"input\\\": \\\"how many employees we have?\\\"})\\n    few_shot_prompt = FewShotChatMessagePromptTemplate(\\n        example_prompt=example_prompt,\\n        example_selector=example_selector,\\n        input_variables=[\\\"input\\\",\\\"top_k\\\"],\\n    )\\n    print(few_shot_prompt.format(input=\\\"How many products are there?\\\"))\\n    ```\\n    \\n2. **Integrating with LangChain**: Integrate the example selector with your LangChain workflow. When a new query is received, the selector determines the most relevant few-shot examples before the model generates the SQL query. This ensures that the guidance provided to the model is tailored to the specific requirements of the query\\n    \\n    ```python\\n    final_prompt = ChatPromptTemplate.from_messages(\\n        [\\n            (\\\"system\\\", \\\"You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run. Unless otherwise specificed.\\\\n\\\\nHere is the relevant table info: {table_info}\\\\n\\\\nBelow are a number of examples of questions and their corresponding SQL queries.\\\"),\\n            few_shot_prompt,\\n            (\\\"human\\\", \\\"{input}\\\"),\\n        ]\\n    )\\n    print(final_prompt.format(input=\\\"How many products are there?\\\",table_info=\\\"some table info\\\"))\\n    generate_query = create_sql_query_chain(llm, db,final_prompt)\\n    chain = (\\n    RunnablePassthrough.assign(query=generate_query).assign(\\n        result=itemgetter(\\\"query\\\") | execute_query\\n    )\\n    | rephrase_answer\\n    )\\n    chain.invoke({\\\"question\\\": \\\"How many csutomers with credit limit more than 50000\\\"})\\n    ```\\n    \\n    ```plaintext\\n    There are 85 customers with a credit limit greater than 50000.\\n    ```\\n    \\n\\nBy ensuring that the examples used for guidance are always contextually relevant, the model can generate more precise SQL queries, reducing errors and improving user satisfaction. of NL2SQL technology, making data insights more accessible to everyone.\\n\\nIn the following section, we will explore the integration of dynamic relevant table selection, further advancing our NL2SQL model's capabilities to efficiently parse and respond to user queries.\\n\\n## Dynamic Relevant Table Selection\\n\\nIn the realm of NL2SQL models, especially when dealing with complex databases featuring 100+ tables. With databases growing in complexity and size, it's impractical and costly in terms of prompt token usage to include the schema of every table in the initial prompt for generating SQL queries. The sheer volume of information would overwhelm the model, leading to slower response times and increased computational costs. Dynamic relevant table selection emerges as a solution to this challenge, focusing the model's attention only on the tables pertinent to the user's query.\\n\\n```python\\nfrom operator import itemgetter\\nfrom langchain.chains.openai_tools import create_extraction_chain_pydantic\\nfrom langchain_core.pydantic_v1 import BaseModel, Field\\nfrom typing import List\\nimport pandas as pd\\n\\ndef get_table_details():\\n    # Read the CSV file into a DataFrame\\n    table_description = pd.read_csv(\\\"database_table_descriptions.csv\\\")\\n    table_docs = []\\n\\n    # Iterate over the DataFrame rows to create Document objects\\n    table_details = \\\"\\\"\\n    for index, row in table_description.iterrows():\\n        table_details = table_details + \\\"Table Name:\\\" + row['Table'] + \\\"\\\\n\\\" + \\\"Table Description:\\\" + row['Description'] + \\\"\\\\n\\\\n\\\"\\n\\n    return table_details\\n\\n\\nclass Table(BaseModel):\\n    \\\"\\\"\\\"Table in SQL database.\\\"\\\"\\\"\\n\\n    name: str = Field(description=\\\"Name of table in SQL database.\\\")\\n\\n# table_names = \\\"\\\\n\\\".join(db.get_usable_table_names())\\ntable_details = get_table_details()\\nprint(table_details)\\n```\\n\\n```plaintext\\nTable Name:productlines\\nTable Description:Stores information about the differ....\\n\\nTable Name:products\\nTable Description:Contains de....\\n```\\n\\n#### Leveraging Smaller, Focused Prompts for Faster Execution\\n\\nDynamic relevant table selection hinges on the principle that \\\"less is more.\\\" By reducing the scope of information the model needs to consider for each query:\\n\\n1. **Improved Model Performance**: Smaller prompts mean the model has fewer tokens to process, which translates to faster execution times. This is particularly crucial for interactive applications where response time is a key component of user satisfaction.\\n    \\n2. **Enhanced Accuracy**: Focusing on only the relevant tables minimizes the risk of generating incorrect SQL queries. This specificity ensures that the model's computational resources are dedicated to understanding and processing only the most pertinent data.\\n    \\n3. **Cost-Efficiency**: Reducing the amount of prompt information also means fewer token usage costs. In the context of cloud-based NLP services, where processing costs can accumulate rapidly, this efficiency is not only a technical but also a financial advantage.\\n    \\n\\n```python\\ntable_details_prompt = f\\\"\\\"\\\"Return the names of ALL the SQL tables that MIGHT be relevant to the user question. \\\\\\nThe tables are:\\n\\n{table_details}\\n\\nRemember to include ALL POTENTIALLY RELEVANT tables, even if you're not sure that they're needed.\\\"\\\"\\\"\\n\\ntable_chain = create_extraction_chain_pydantic(Table, llm, system_message=table_details_prompt)\\ntables = table_chain.invoke({\\\"input\\\": \\\"give me details of customer and their order count\\\"})\\ntables\\n```\\n\\n```plaintext\\n[Table(name='customers'), Table(name='orders')]\\n```\\n\\n```python\\ndef get_tables(tables: List[Table]) -\u003e List[str]:\\n    tables  = [table.name for table in tables]\\n    return tables\\n\\nselect_table = {\\\"input\\\": itemgetter(\\\"question\\\")} | create_extraction_chain_pydantic(Table, llm, system_message=table_details_prompt) | get_tables\\nselect_table.invoke({\\\"question\\\": \\\"give me details of customer and their order count\\\"})\\n```\\n\\n```plaintext\\n['customers', 'orders']\\n```\\n\\n```python\\nchain = (\\nRunnablePassthrough.assign(table_names_to_use=select_table) |\\nRunnablePassthrough.assign(query=generate_query).assign(\\n    result=itemgetter(\\\"query\\\") | execute_query\\n)\\n| rephrase_answer\\n)\\nchain.invoke({\\\"question\\\": \\\"How many cutomers with order count more than 5\\\"})\\n```\\n\\n## Enhancing Chatbots with Memory for Follow-up Database Queries\\n\\nOne of the most advanced steps in creating a user-friendly NL2SQL interface is endowing your chatbot with memory. This feature enables the chatbot to handle follow-up questions related to the database intelligently, providing users with a seamless conversational experience. Let's explore how adding memory to your chatbot can revolutionize interactions with your database.\\n\\n#### The Significance of Memory in Chatbots\\n\\nIn real-world conversations, context matters. A question might relate to or build upon previous interactions. Similarly, when users interact with a database through a chatbot, their follow-up questions often depend on the context established by earlier queries and responses. A chatbot equipped with memory can retain this context, allowing it to generate more accurate and relevant SQL queries for follow-up questions.\\n\\n#### Implementing Memory in Your NL2SQL Model\\n\\nTo equip your NL2SQL model with memory, consider incorporating a chat message history that tracks the conversation's flow. This history should include both the questions posed by the user and the chatbot's responses, enabling the model to reference previous interactions when generating SQL queries for new questions.\\n\\n1. **Setting Up Message History**: Implement a mechanism to record each user query and the corresponding chatbot response. This can be achieved by defining a `ChatMessageHistory` object that stores this information and can be accessed when needed\\n    \\n    ```python\\n    from langchain.memory import ChatMessageHistory\\n    history = ChatMessageHistory()\\n    ```\\n    \\n2. **Leveraging Previous Interactions**: Integrate this message history into your prompt generation process. Before generating a new SQL query, the model should consider the recorded history to understand the conversation's context\\n    \\n    ```python\\n    final_prompt = ChatPromptTemplate.from_messages(\\n        [\\n            (\\\"system\\\", \\\"You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run. Unless otherwise specificed.\\\\n\\\\nHere is the relevant table info: {table_info}\\\\n\\\\nBelow are a number of examples of questions and their corresponding SQL queries. Those examples are just for referecne and hsould be considered while answering follow up questions\\\"),\\n            few_shot_prompt,\\n            MessagesPlaceholder(variable_name=\\\"messages\\\"),\\n            (\\\"human\\\", \\\"{input}\\\"),\\n        ]\\n    )\\n    print(final_prompt.format(input=\\\"How many products are there?\\\",table_info=\\\"some table info\\\",messages=[]))\\n    ```\\n    \\n3. **Dynamic Prompt Adaptation**: Use the chat message history to dynamically adapt the prompts sent to the model for generating SQL queries. This adaptation should include information from previous queries and responses, guiding the model in understanding the context of the follow-up question\\n    \\n    ```python\\n    generate_query = create_sql_query_chain(llm, db,final_prompt)\\n    \\n    chain = (\\n    RunnablePassthrough.assign(table_names_to_use=select_table) |\\n    RunnablePassthrough.assign(query=generate_query).assign(\\n        result=itemgetter(\\\"query\\\") | execute_query\\n    )\\n    | rephrase_answer\\n    )\\n    ```\\n    \\n\\n#### Example Scenario: Handling Follow-Up Questions\\n\\nImagine a user first asks, \\\"How many customers have an order count more than 5?\\\" After receiving the answer, they follow up with, \\\"Can you list their names?\\\" With a memory feature, the chatbot can understand that the second question relates to the subset of customers identified in response to the first question, allowing it to generate an accurate follow-up query without needing the user to re-specify the context.\\n\\n```python\\nquestion = \\\"How many cutomers with order count more than 5\\\"\\nresponse = chain.invoke({\\\"question\\\": question,\\\"messages\\\":history.messages})\\nThere are 2 customers with an order count of more than 5.\\n```\\n\\n```python\\nhistory.add_user_message(question)\\nhistory.add_ai_message(response)\\nhistory.messages\\n[HumanMessage(content='How many cutomers with order count more than 5'),\\n AIMessage(content='There are 2 customers with an order count of more than 5.')]\\n```\\n\\n```python\\nresponse = chain.invoke({\\\"question\\\": \\\"Can you list there names?\\\",\\\"messages\\\":history.messages})\\nresponse\\nThe names of the customers with more than 5 orders are Mini Gifts Distributors Ltd. and Euro+ Shopping Channel.\\n```\\n\\n## **Conclusion:**\\n\\nThrough this guide, we've journeyed through the process of enhancing NL2SQL models using LangChain, showcasing how to transform natural language queries into precise SQL commands. This exploration not only highlights the power of LangChain in making database queries more accessible but also underscores the broader impact of integrating advanced NLP techniques for intuitive data interaction.\\n\\nFor those interested in delving deeper, a [video walkthrough](https://youtu.be/fss6CrmQU2Y) and a comprehensive [GitHub notebook](https://github.com/PradipNichite/Youtube-Tutorials/blob/main/Langchain_NL2SQL_2024.ipynb) and [Streamlit Code](https://github.com/PradipNichite/Youtube-Tutorials/tree/main/Langchain%20NL2SQL%20Chatbot) are available to explore these concepts further. These resources offer visual demonstrations and hands-on examples to help bring these ideas to life in your own projects.\\n\\nThe journey toward more natural and efficient database interactions is ongoing, and with each step, we're making the world of data more accessible to all.\\n\\nIf you're curious about the latest in AI technology, I invite you to visit my project, AI Demos, at [**aidemos.com**](http://aidemos.com/)**. It's a rich resource offering a wide array of video demos showcasing the most advanced AI tools. My goal with AI Demos is to educate and illuminate the diverse possibilities of AI.**\\n\\nFor even more in-depth exploration, be sure to visit my YouTube channel at [https://www.youtube.com/@aidemos.videos](https://www.youtube.com/@aidemos.videos)**. Here, you'll find a wealth of content that delves into the exciting future of AI and its various applications.**\",\"content\":\"\u003ch2 id=\\\"heading-introduction\\\"\u003eIntroduction\u003c/h2\u003e\\n\u003cp\u003eWelcome to our deep dive into revolutionizing the way we interact with databases using Natural Language Processing (NLP) and LangChain. In today's data-driven world, the ability to query databases without needing to know complex SQL syntax opens up a myriad of possibilities across various industries, from healthcare to finance, making data more accessible to everyone.\u003c/p\u003e\\n\u003cp\u003eThis blog post aims to guide you through a comprehensive journey to master NL2SQL using LangChain. We will explore the steps necessary to build an intuitive, efficient, and intelligent NL2SQL model that can understand and process natural language queries, dynamically select relevant database tables, and maintain a conversational context to handle follow-up questions effectively.\u003c/p\u003e\\n\u003cp\u003eBy the end of this post, you'll have a solid understanding of:\u003c/p\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eBuilding a Basic NL2SQL Model\u003c/strong\u003e: The foundation of translating natural language queries into SQL commands.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eIncorporating Few-Shot Learning\u003c/strong\u003e: Enhancing model accuracy with examples.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eDynamic Few-Shot Example Selection\u003c/strong\u003e: Tailoring examples to the query context for improved relevance.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eDynamic Relevant Table Selection\u003c/strong\u003e: Automatically identifying which tables to query based on the natural language input.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eCustomizing Prompts and Responses\u003c/strong\u003e: Fine-tuning the model's interaction to provide clear, concise, and relevant answers.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eAdding Memory to Chatbots\u003c/strong\u003e: Enabling the model to handle follow-up questions by remembering the context of the conversation.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003cp\u003eThrough each of these steps, we'll discuss the concepts, show you how to implement them , and illustrate the outcomes , ensuring you have the tools and knowledge needed to bring the power of NL2SQL to your databases.\u003c/p\u003e\\n\u003cp\u003eLet's embark on this exciting journey to unlock the full potential of your data, making database queries as simple as conversing with a friend.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-building-a-basic-nl2sql-model\\\"\u003eBuilding a Basic NL2SQL Model\u003c/h2\u003e\\n\u003cp\u003eThe first step in our journey to revolutionize database querying with natural language is constructing a basic NL2SQL model using LangChain. This foundational model serves as the cornerstone for more advanced functionalities we'll explore later. Here's how we begin:\u003c/p\u003e\\n\u003ch4 id=\\\"heading-understanding-the-basics\\\"\u003eUnderstanding the Basics\u003c/h4\u003e\\n\u003cp\u003eAt its core, an NL2SQL model aims to translate natural language queries into SQL commands. But how do we start building such a model with LangChain?\u003c/p\u003e\\n\u003ch4 id=\\\"heading-setting-up-langchain\\\"\u003eSetting Up LangChain\u003c/h4\u003e\\n\u003cp\u003eLangChain simplifies the process of creating NL2SQL models by providing a flexible framework that integrates seamlessly with existing databases and natural language processing (NLP) models. To get started, you'll need to:\u003c/p\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eInstall LangChain\u003c/strong\u003e: Ensure that LangChain is installed in your environment.\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-bash\\\"\u003e pip install langchain_openai langchain_community langchain pymysql chromadb -q\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eConnect to Your Database\u003c/strong\u003e: The next step involves establishing a connection to your database. LangChain supports various database systems, so you'll likely find your database among the supported ones. You'll use the database credentials to create a connection that LangChain can use to interact with your data\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e os\\n os.environ[\u003cspan class=\\\"hljs-string\\\"\u003e\\\"OPENAI_API_KEY\\\"\u003c/span\u003e] = \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\u003c/span\u003e\\n\\n db_user = \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\u003c/span\u003e\\n db_password = \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\u003c/span\u003e\\n db_host = \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\u003c/span\u003e\\n db_name = \u003cspan class=\\\"hljs-string\\\"\u003e\\\"classicmodels\\\"\u003c/span\u003e\\n \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_community.utilities.sql_database \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e SQLDatabase\\n \u003cspan class=\\\"hljs-comment\\\"\u003e# db = SQLDatabase.from_uri(f\\\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\\\",sample_rows_in_table_info=1,include_tables=['customers','orders'],custom_table_info={'customers':\\\"customer\\\"})\u003c/span\u003e\\n db = SQLDatabase.from_uri(\u003cspan class=\\\"hljs-string\\\"\u003ef\\\"mysql+pymysql://\u003cspan class=\\\"hljs-subst\\\"\u003e{db_user}\u003c/span\u003e:\u003cspan class=\\\"hljs-subst\\\"\u003e{db_password}\u003c/span\u003e@\u003cspan class=\\\"hljs-subst\\\"\u003e{db_host}\u003c/span\u003e/\u003cspan class=\\\"hljs-subst\\\"\u003e{db_name}\u003c/span\u003e\\\"\u003c/span\u003e)\\n print(db.dialect)\\n print(db.get_usable_table_names())\\n print(db.table_info)\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003ch4 id=\\\"heading-the-first-query\\\"\u003eThe First Query\u003c/h4\u003e\\n\u003cp\u003eOnce the setup is complete, the real magic begins. You can start by formulating a simple query in natural language, such as \\\"Show me all products priced above $100.\\\" LangChain takes this input and, through its integration with language models like ChatGPT and your database, generates an SQL query that precisely captures the intent of your request\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain.chains \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e create_sql_query_chain\\n\u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_openai \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e ChatOpenAI\\n\\nllm = ChatOpenAI(model=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"gpt-3.5-turbo\\\"\u003c/span\u003e, temperature=\u003cspan class=\\\"hljs-number\\\"\u003e0\u003c/span\u003e)\\ngenerate_query = create_sql_query_chain(llm, db)\\nquery = generate_query.invoke({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"question\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"what is price of `1968 Ford Mustang`\\\"\u003c/span\u003e})\\n\u003cspan class=\\\"hljs-comment\\\"\u003e# \\\"what is price of `1968 Ford Mustang`\\\"\u003c/span\u003e\\nprint(query)\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch4 id=\\\"heading-seeing-the-results\\\"\u003eSeeing the Results\u003c/h4\u003e\\n\u003cp\u003eExecuting the generated SQL query against your database retrieves the data you're looking for, which LangChain can then present in a user-friendly format.\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_community.tools.sql_database.tool \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e QuerySQLDataBaseTool\\nexecute_query = QuerySQLDataBaseTool(db=db)\\nexecute_query.invoke(query)\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch4 id=\\\"heading-moving-forward\\\"\u003eMoving Forward\u003c/h4\u003e\\n\u003cp\u003eWith the basic NL2SQL model set up, you've taken the first step towards transforming how we interact with databases. However, this is just the beginning. As we progress, we'll explore how to enhance the model's accuracy, handle more complex queries, and even maintain context over a conversation for follow-up questions.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-rephrasing-answers-for-enhanced-clarity\\\"\u003eRephrasing Answers for Enhanced Clarity\u003c/h2\u003e\\n\u003cp\u003eAfter your NL2SQL model successfully executes a SQL query, the next pivotal step is to present the data in a manner that's easily understandable by your users. This is where the art of rephrasing SQL results into clear, natural language answers comes into play. Here's how you can achieve this with LangChain:\u003c/p\u003e\\n\u003ch4 id=\\\"heading-implementing-rephrasing-with-langchain\\\"\u003eImplementing Rephrasing with LangChain\u003c/h4\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eUse Prompt Templates\u003c/strong\u003e: LangChain allows you to create prompt templates that can guide the model in how to rephrase SQL results. These templates can include placeholders for the original question, the SQL query, and the query result, setting the stage for generating a natural language response\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e operator \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e itemgetter\\n\\n \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_core.output_parsers \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e StrOutputParser\\n \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_core.prompts \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e PromptTemplate\\n \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_core.runnables \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e RunnablePassthrough\\n\\n answer_prompt = PromptTemplate.from_template(\\n     \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\\\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\\n\\n Question: {question}\\n SQL Query: {query}\\n SQL Result: {result}\\n Answer: \\\"\\\"\\\"\u003c/span\u003e\\n )\\n\\n rephrase_answer = answer_prompt | llm | StrOutputParser()\\n\\n chain = (\\n     RunnablePassthrough.assign(query=generate_query).assign(\\n         result=itemgetter(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"query\\\"\u003c/span\u003e) | execute_query\\n     )\\n     | rephrase_answer\\n )\\n\\n chain.invoke({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"question\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"How many customers have an order count greater than 5\\\"\u003c/span\u003e})\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003ch4 id=\\\"heading-example-transforming-sql-results-into-user-friendly-responses\\\"\u003eExample: Transforming SQL Results into User-Friendly Responses\u003c/h4\u003e\\n\u003cp\u003eLet's consider a user asks, \\\"How many customers have an order count greater than 5?\\\" and the SQL query returns a raw numerical result. The rephrasing process would convert this into a more readable answer, such as \\\"There are 2 customers with an order count of more than 5.\\\" This step is vital in closing the loop between user queries and database responses, ensuring that the information provided is both useful and easily digestible\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-plaintext\\\"\u003eThere are 2 customers with an order count of more than 5.\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eIn the next section, we'll dive into the exciting world of few-shot learning and how it can be used to improve the performance of your NL2SQL model with LangChain. Stay tuned to unlock the full potential of natural language database querying.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-enhancing-nl2sql-models-with-few-shot-examples\\\"\u003eEnhancing NL2SQL Models with Few-Shot Examples\u003c/h2\u003e\\n\u003cp\u003eThis technique involves providing the model with a small set of carefully selected examples that demonstrate how to convert natural language questions into SQL queries. Few-shot learning can significantly improve the model's ability to understand and generate precise SQL commands based on user queries, bridging the gap between human language and database querying.\u003c/p\u003e\\n\u003ch4 id=\\\"heading-incorporating-few-shot-examples-into-langchain\\\"\u003eIncorporating Few-Shot Examples into LangChain\u003c/h4\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eSelecting Relevant Examples\u003c/strong\u003e: The first step is to curate a set of examples that cover a broad range of query types and complexities. These examples should ideally reflect the most common or critical queries your users might perform\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-plaintext\\\"\u003e examples = [\\n     {\\n         \\\"input\\\": \\\"List all customers in France with a credit limit over 20,000.\\\",\\n         \\\"query\\\": \\\"SELECT * FROM customers WHERE country = 'France' AND creditLimit \u0026gt; 20000;\\\"\\n     },\\n     {\\n         \\\"input\\\": \\\"Get the highest payment amount made by any customer.\\\",\\n         \\\"query\\\": \\\"SELECT MAX(amount) FROM payments;\\\"\\n     },\\n    .....\\n ]\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eCreating a Few-Shot Learning Template\u003c/strong\u003e: With LangChain, you can design a prompt template that incorporates these examples into the model's workflow. The template instructs the model to consider the examples when generating SQL queries from new user questions\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_core.prompts \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e ChatPromptTemplate, MessagesPlaceholder,FewShotChatMessagePromptTemplate,PromptTemplate\\n\\n example_prompt = ChatPromptTemplate.from_messages(\\n     [\\n         (\u003cspan class=\\\"hljs-string\\\"\u003e\\\"human\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"{input}\\\\nSQLQuery:\\\"\u003c/span\u003e),\\n         (\u003cspan class=\\\"hljs-string\\\"\u003e\\\"ai\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"{query}\\\"\u003c/span\u003e),\\n     ]\\n )\\n few_shot_prompt = FewShotChatMessagePromptTemplate(\\n     example_prompt=example_prompt,\\n     examples=examples,\\n     \u003cspan class=\\\"hljs-comment\\\"\u003e# input_variables=[\\\"input\\\",\\\"top_k\\\"],\u003c/span\u003e\\n     input_variables=[\u003cspan class=\\\"hljs-string\\\"\u003e\\\"input\\\"\u003c/span\u003e],\\n )\\n print(few_shot_prompt.format(input1=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"How many products are there?\\\"\u003c/span\u003e))\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-plaintext\\\"\u003e Human: List all customers in France with a credit limit over 20,000.\\n SQLQuery:\\n AI: SELECT * FROM customers WHERE country = 'France' AND creditLimit \u0026gt; 20000;\\n Human: Get the highest payment amount made by any customer.\\n SQLQuery:\\n AI: SELECT MAX(amount) FROM payments;\\n ......\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003ch4 id=\\\"heading-the-impact-of-few-shot-learning\\\"\u003eThe Impact of Few-Shot Learning\u003c/h4\u003e\\n\u003cp\u003eBy integrating few-shot examples, your NL2SQL model becomes more adept at handling a wider variety of user queries. This not only improves the user experience by providing more accurate and relevant responses but also reduces the potential for errors in SQL query generation.\u003c/p\u003e\\n\u003cp\u003eIn the next section, we'll explore the integration of dynamic example selection to further enhance the model's accuracy and relevance, ensuring that your NL2SQL system remains adaptive and responsive to user queries.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-dynamic-few-shot-example-selection\\\"\u003eDynamic Few-Shot Example Selection:\u003c/h2\u003e\\n\u003cp\u003eThis advanced technique tailors the few-shot examples provided to the model based on the specific context of the user's query. It ensures that the guidance offered to the model is not just relevant but optimally aligned with the query's nuances, significantly boosting the model's ability to generate accurate SQL queries.\u003c/p\u003e\\n\u003ch4 id=\\\"heading-the-need-for-dynamism\\\"\u003eThe Need for Dynamism\u003c/h4\u003e\\n\u003cp\u003eStatic few-shot examples, though highly effective, have their limitations. Dynamic selection addresses this by intelligently choosing examples that closely match the intent and context of each new query, providing a customized learning experience for the model with every interaction.\u003c/p\u003e\\n\u003ch4 id=\\\"heading-implementing-dynamic-few-shot-selection\\\"\u003eImplementing Dynamic Few-Shot Selection\u003c/h4\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eExample Selector Configuration\u003c/strong\u003e: Begin by setting up an example selector that can analyze the semantics of the user's query and compare it with a repository of potential examples. Tools like semantic similarity algorithms and vector embeddings come into play here, identifying which examples are most relevant to the current query\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_community.vectorstores \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e Chroma\\n \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_core.example_selectors \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e SemanticSimilarityExampleSelector\\n \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_openai \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e OpenAIEmbeddings\\n\\n vectorstore = Chroma()\\n vectorstore.delete_collection()\\n example_selector = SemanticSimilarityExampleSelector.from_examples(\\n     examples,\\n     OpenAIEmbeddings(),\\n     vectorstore,\\n     k=\u003cspan class=\\\"hljs-number\\\"\u003e2\u003c/span\u003e,\\n     input_keys=[\u003cspan class=\\\"hljs-string\\\"\u003e\\\"input\\\"\u003c/span\u003e],\\n )\\n example_selector.select_examples({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"input\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"how many employees we have?\\\"\u003c/span\u003e})\\n few_shot_prompt = FewShotChatMessagePromptTemplate(\\n     example_prompt=example_prompt,\\n     example_selector=example_selector,\\n     input_variables=[\u003cspan class=\\\"hljs-string\\\"\u003e\\\"input\\\"\u003c/span\u003e,\u003cspan class=\\\"hljs-string\\\"\u003e\\\"top_k\\\"\u003c/span\u003e],\\n )\\n print(few_shot_prompt.format(input=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"How many products are there?\\\"\u003c/span\u003e))\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eIntegrating with LangChain\u003c/strong\u003e: Integrate the example selector with your LangChain workflow. When a new query is received, the selector determines the most relevant few-shot examples before the model generates the SQL query. This ensures that the guidance provided to the model is tailored to the specific requirements of the query\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e final_prompt = ChatPromptTemplate.from_messages(\\n     [\\n         (\u003cspan class=\\\"hljs-string\\\"\u003e\\\"system\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run. Unless otherwise specificed.\\\\n\\\\nHere is the relevant table info: {table_info}\\\\n\\\\nBelow are a number of examples of questions and their corresponding SQL queries.\\\"\u003c/span\u003e),\\n         few_shot_prompt,\\n         (\u003cspan class=\\\"hljs-string\\\"\u003e\\\"human\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"{input}\\\"\u003c/span\u003e),\\n     ]\\n )\\n print(final_prompt.format(input=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"How many products are there?\\\"\u003c/span\u003e,table_info=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"some table info\\\"\u003c/span\u003e))\\n generate_query = create_sql_query_chain(llm, db,final_prompt)\\n chain = (\\n RunnablePassthrough.assign(query=generate_query).assign(\\n     result=itemgetter(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"query\\\"\u003c/span\u003e) | execute_query\\n )\\n | rephrase_answer\\n )\\n chain.invoke({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"question\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"How many csutomers with credit limit more than 50000\\\"\u003c/span\u003e})\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-plaintext\\\"\u003e There are 85 customers with a credit limit greater than 50000.\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003cp\u003eBy ensuring that the examples used for guidance are always contextually relevant, the model can generate more precise SQL queries, reducing errors and improving user satisfaction. of NL2SQL technology, making data insights more accessible to everyone.\u003c/p\u003e\\n\u003cp\u003eIn the following section, we will explore the integration of dynamic relevant table selection, further advancing our NL2SQL model's capabilities to efficiently parse and respond to user queries.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-dynamic-relevant-table-selection\\\"\u003eDynamic Relevant Table Selection\u003c/h2\u003e\\n\u003cp\u003eIn the realm of NL2SQL models, especially when dealing with complex databases featuring 100+ tables. With databases growing in complexity and size, it's impractical and costly in terms of prompt token usage to include the schema of every table in the initial prompt for generating SQL queries. The sheer volume of information would overwhelm the model, leading to slower response times and increased computational costs. Dynamic relevant table selection emerges as a solution to this challenge, focusing the model's attention only on the tables pertinent to the user's query.\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e operator \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e itemgetter\\n\u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain.chains.openai_tools \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e create_extraction_chain_pydantic\\n\u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_core.pydantic_v1 \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e BaseModel, Field\\n\u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e typing \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e List\\n\u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e pandas \u003cspan class=\\\"hljs-keyword\\\"\u003eas\u003c/span\u003e pd\\n\\n\u003cspan class=\\\"hljs-function\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003eget_table_details\u003c/span\u003e():\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-comment\\\"\u003e# Read the CSV file into a DataFrame\u003c/span\u003e\\n    table_description = pd.read_csv(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"database_table_descriptions.csv\\\"\u003c/span\u003e)\\n    table_docs = []\\n\\n    \u003cspan class=\\\"hljs-comment\\\"\u003e# Iterate over the DataFrame rows to create Document objects\u003c/span\u003e\\n    table_details = \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003efor\u003c/span\u003e index, row \u003cspan class=\\\"hljs-keyword\\\"\u003ein\u003c/span\u003e table_description.iterrows():\\n        table_details = table_details + \u003cspan class=\\\"hljs-string\\\"\u003e\\\"Table Name:\\\"\u003c/span\u003e + row[\u003cspan class=\\\"hljs-string\\\"\u003e'Table'\u003c/span\u003e] + \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\\n\\\"\u003c/span\u003e + \u003cspan class=\\\"hljs-string\\\"\u003e\\\"Table Description:\\\"\u003c/span\u003e + row[\u003cspan class=\\\"hljs-string\\\"\u003e'Description'\u003c/span\u003e] + \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\\n\\\\n\\\"\u003c/span\u003e\\n\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e table_details\\n\\n\\n\u003cspan class=\\\"hljs-class\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003eclass\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003eTable\u003c/span\u003e(\u003cspan class=\\\"hljs-params\\\"\u003eBaseModel\u003c/span\u003e):\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\\\"Table in SQL database.\\\"\\\"\\\"\u003c/span\u003e\\n\\n    name: str = Field(description=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"Name of table in SQL database.\\\"\u003c/span\u003e)\\n\\n\u003cspan class=\\\"hljs-comment\\\"\u003e# table_names = \\\"\\\\n\\\".join(db.get_usable_table_names())\u003c/span\u003e\\ntable_details = get_table_details()\\nprint(table_details)\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-plaintext\\\"\u003eTable Name:productlines\\nTable Description:Stores information about the differ....\\n\\nTable Name:products\\nTable Description:Contains de....\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch4 id=\\\"heading-leveraging-smaller-focused-prompts-for-faster-execution\\\"\u003eLeveraging Smaller, Focused Prompts for Faster Execution\u003c/h4\u003e\\n\u003cp\u003eDynamic relevant table selection hinges on the principle that \\\"less is more.\\\" By reducing the scope of information the model needs to consider for each query:\u003c/p\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eImproved Model Performance\u003c/strong\u003e: Smaller prompts mean the model has fewer tokens to process, which translates to faster execution times. This is particularly crucial for interactive applications where response time is a key component of user satisfaction.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eEnhanced Accuracy\u003c/strong\u003e: Focusing on only the relevant tables minimizes the risk of generating incorrect SQL queries. This specificity ensures that the model's computational resources are dedicated to understanding and processing only the most pertinent data.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eCost-Efficiency\u003c/strong\u003e: Reducing the amount of prompt information also means fewer token usage costs. In the context of cloud-based NLP services, where processing costs can accumulate rapidly, this efficiency is not only a technical but also a financial advantage.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003etable_details_prompt = \u003cspan class=\\\"hljs-string\\\"\u003ef\\\"\\\"\\\"Return the names of ALL the SQL tables that MIGHT be relevant to the user question. \\\\\\nThe tables are:\\n\\n\u003cspan class=\\\"hljs-subst\\\"\u003e{table_details}\u003c/span\u003e\\n\\nRemember to include ALL POTENTIALLY RELEVANT tables, even if you're not sure that they're needed.\\\"\\\"\\\"\u003c/span\u003e\\n\\ntable_chain = create_extraction_chain_pydantic(Table, llm, system_message=table_details_prompt)\\ntables = table_chain.invoke({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"input\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"give me details of customer and their order count\\\"\u003c/span\u003e})\\ntables\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-plaintext\\\"\u003e[Table(name='customers'), Table(name='orders')]\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-function\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003eget_tables\u003c/span\u003e(\u003cspan class=\\\"hljs-params\\\"\u003etables: List[Table]\u003c/span\u003e) -\u0026gt; List[str]:\u003c/span\u003e\\n    tables  = [table.name \u003cspan class=\\\"hljs-keyword\\\"\u003efor\u003c/span\u003e table \u003cspan class=\\\"hljs-keyword\\\"\u003ein\u003c/span\u003e tables]\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e tables\\n\\nselect_table = {\u003cspan class=\\\"hljs-string\\\"\u003e\\\"input\\\"\u003c/span\u003e: itemgetter(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"question\\\"\u003c/span\u003e)} | create_extraction_chain_pydantic(Table, llm, system_message=table_details_prompt) | get_tables\\nselect_table.invoke({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"question\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"give me details of customer and their order count\\\"\u003c/span\u003e})\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-plaintext\\\"\u003e['customers', 'orders']\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003echain = (\\nRunnablePassthrough.assign(table_names_to_use=select_table) |\\nRunnablePassthrough.assign(query=generate_query).assign(\\n    result=itemgetter(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"query\\\"\u003c/span\u003e) | execute_query\\n)\\n| rephrase_answer\\n)\\nchain.invoke({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"question\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"How many cutomers with order count more than 5\\\"\u003c/span\u003e})\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch2 id=\\\"heading-enhancing-chatbots-with-memory-for-follow-up-database-queries\\\"\u003eEnhancing Chatbots with Memory for Follow-up Database Queries\u003c/h2\u003e\\n\u003cp\u003eOne of the most advanced steps in creating a user-friendly NL2SQL interface is endowing your chatbot with memory. This feature enables the chatbot to handle follow-up questions related to the database intelligently, providing users with a seamless conversational experience. Let's explore how adding memory to your chatbot can revolutionize interactions with your database.\u003c/p\u003e\\n\u003ch4 id=\\\"heading-the-significance-of-memory-in-chatbots\\\"\u003eThe Significance of Memory in Chatbots\u003c/h4\u003e\\n\u003cp\u003eIn real-world conversations, context matters. A question might relate to or build upon previous interactions. Similarly, when users interact with a database through a chatbot, their follow-up questions often depend on the context established by earlier queries and responses. A chatbot equipped with memory can retain this context, allowing it to generate more accurate and relevant SQL queries for follow-up questions.\u003c/p\u003e\\n\u003ch4 id=\\\"heading-implementing-memory-in-your-nl2sql-model\\\"\u003eImplementing Memory in Your NL2SQL Model\u003c/h4\u003e\\n\u003cp\u003eTo equip your NL2SQL model with memory, consider incorporating a chat message history that tracks the conversation's flow. This history should include both the questions posed by the user and the chatbot's responses, enabling the model to reference previous interactions when generating SQL queries for new questions.\u003c/p\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eSetting Up Message History\u003c/strong\u003e: Implement a mechanism to record each user query and the corresponding chatbot response. This can be achieved by defining a \u003ccode\u003eChatMessageHistory\u003c/code\u003e object that stores this information and can be accessed when needed\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain.memory \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e ChatMessageHistory\\n history = ChatMessageHistory()\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eLeveraging Previous Interactions\u003c/strong\u003e: Integrate this message history into your prompt generation process. Before generating a new SQL query, the model should consider the recorded history to understand the conversation's context\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e final_prompt = ChatPromptTemplate.from_messages(\\n     [\\n         (\u003cspan class=\\\"hljs-string\\\"\u003e\\\"system\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run. Unless otherwise specificed.\\\\n\\\\nHere is the relevant table info: {table_info}\\\\n\\\\nBelow are a number of examples of questions and their corresponding SQL queries. Those examples are just for referecne and hsould be considered while answering follow up questions\\\"\u003c/span\u003e),\\n         few_shot_prompt,\\n         MessagesPlaceholder(variable_name=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"messages\\\"\u003c/span\u003e),\\n         (\u003cspan class=\\\"hljs-string\\\"\u003e\\\"human\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"{input}\\\"\u003c/span\u003e),\\n     ]\\n )\\n print(final_prompt.format(input=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"How many products are there?\\\"\u003c/span\u003e,table_info=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"some table info\\\"\u003c/span\u003e,messages=[]))\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eDynamic Prompt Adaptation\u003c/strong\u003e: Use the chat message history to dynamically adapt the prompts sent to the model for generating SQL queries. This adaptation should include information from previous queries and responses, guiding the model in understanding the context of the follow-up question\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e generate_query = create_sql_query_chain(llm, db,final_prompt)\\n\\n chain = (\\n RunnablePassthrough.assign(table_names_to_use=select_table) |\\n RunnablePassthrough.assign(query=generate_query).assign(\\n     result=itemgetter(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"query\\\"\u003c/span\u003e) | execute_query\\n )\\n | rephrase_answer\\n )\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003ch4 id=\\\"heading-example-scenario-handling-follow-up-questions\\\"\u003eExample Scenario: Handling Follow-Up Questions\u003c/h4\u003e\\n\u003cp\u003eImagine a user first asks, \\\"How many customers have an order count more than 5?\\\" After receiving the answer, they follow up with, \\\"Can you list their names?\\\" With a memory feature, the chatbot can understand that the second question relates to the subset of customers identified in response to the first question, allowing it to generate an accurate follow-up query without needing the user to re-specify the context.\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003equestion = \u003cspan class=\\\"hljs-string\\\"\u003e\\\"How many cutomers with order count more than 5\\\"\u003c/span\u003e\\nresponse = chain.invoke({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"question\\\"\u003c/span\u003e: question,\u003cspan class=\\\"hljs-string\\\"\u003e\\\"messages\\\"\u003c/span\u003e:history.messages})\\nThere are \u003cspan class=\\\"hljs-number\\\"\u003e2\u003c/span\u003e customers \u003cspan class=\\\"hljs-keyword\\\"\u003ewith\u003c/span\u003e an order count of more than \u003cspan class=\\\"hljs-number\\\"\u003e5.\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003ehistory.add_user_message(question)\\nhistory.add_ai_message(response)\\nhistory.messages\\n[HumanMessage(content=\u003cspan class=\\\"hljs-string\\\"\u003e'How many cutomers with order count more than 5'\u003c/span\u003e),\\n AIMessage(content=\u003cspan class=\\\"hljs-string\\\"\u003e'There are 2 customers with an order count of more than 5.'\u003c/span\u003e)]\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003eresponse = chain.invoke({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"question\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"Can you list there names?\\\"\u003c/span\u003e,\u003cspan class=\\\"hljs-string\\\"\u003e\\\"messages\\\"\u003c/span\u003e:history.messages})\\nresponse\\nThe names of the customers \u003cspan class=\\\"hljs-keyword\\\"\u003ewith\u003c/span\u003e more than \u003cspan class=\\\"hljs-number\\\"\u003e5\u003c/span\u003e orders are Mini Gifts Distributors Ltd. \u003cspan class=\\\"hljs-keyword\\\"\u003eand\u003c/span\u003e Euro+ Shopping Channel.\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch2 id=\\\"heading-conclusion\\\"\u003e\u003cstrong\u003eConclusion:\u003c/strong\u003e\u003c/h2\u003e\\n\u003cp\u003eThrough this guide, we've journeyed through the process of enhancing NL2SQL models using LangChain, showcasing how to transform natural language queries into precise SQL commands. This exploration not only highlights the power of LangChain in making database queries more accessible but also underscores the broader impact of integrating advanced NLP techniques for intuitive data interaction.\u003c/p\u003e\\n\u003cp\u003eFor those interested in delving deeper, a \u003ca target=\\\"_blank\\\" href=\\\"https://youtu.be/fss6CrmQU2Y\\\"\u003evideo walkthrough\u003c/a\u003e and a comprehensive \u003ca target=\\\"_blank\\\" href=\\\"https://github.com/PradipNichite/Youtube-Tutorials/blob/main/Langchain_NL2SQL_2024.ipynb\\\"\u003eGitHub notebook\u003c/a\u003e and \u003ca target=\\\"_blank\\\" href=\\\"https://github.com/PradipNichite/Youtube-Tutorials/tree/main/Langchain%20NL2SQL%20Chatbot\\\"\u003eStreamlit Code\u003c/a\u003e are available to explore these concepts further. These resources offer visual demonstrations and hands-on examples to help bring these ideas to life in your own projects.\u003c/p\u003e\\n\u003cp\u003eThe journey toward more natural and efficient database interactions is ongoing, and with each step, we're making the world of data more accessible to all.\u003c/p\u003e\\n\u003cp\u003eIf you're curious about the latest in AI technology, I invite you to visit my project, AI Demos, at \u003ca target=\\\"_blank\\\" href=\\\"http://aidemos.com/\\\"\u003e\u003cstrong\u003e\u003ca href=\\\"http://aidemos.com\\\" class=\\\"autolinkedURL autolinkedURL-url\\\" target=\\\"_blank\\\"\u003eaidemos.com\u003c/a\u003e\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e. It's a rich resource offering a wide array of video demos showcasing the most advanced AI tools. My goal with AI Demos is to educate and illuminate the diverse possibilities of AI.\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eFor even more in-depth exploration, be sure to visit my YouTube channel at \u003ca target=\\\"_blank\\\" href=\\\"https://www.youtube.com/@aidemos.videos\\\"\u003ehttps://www.youtube.com/@aidemos.videos\u003c/a\u003e\u003cstrong\u003e. Here, you'll find a wealth of content that delves into the exciting future of AI and its various applications.\u003c/strong\u003e\u003c/p\u003e\\n\",\"cuid\":\"cltmt9d8u000308jy744l8n74\",\"views\":39122,\"title\":\"Mastering Natural Language to SQL with LangChain | NL2SQL\",\"slug\":\"mastering-natural-language-to-sql-with-langchain-nl2sql\",\"dateAdded\":\"2024-03-11T10:38:55.566Z\",\"dateUpdated\":\"2024-03-11T10:40:28.637Z\",\"type\":\"story\",\"coverImage\":\"https://cdn.hashnode.com/res/hashnode/image/upload/v1710152478787/e57074e2-3303-46ec-8491-11f60aa0bd2d.png\",\"isCoverImagePortrait\":false,\"isCoverAttributionHidden\":false,\"brief\":\"Introduction\\nWelcome to our deep dive into revolutionizing the way we interact with databases using Natural Language Processing (NLP) and LangChain. In today's data-driven world, the ability to query databases without needing to know complex SQL synt...\",\"isFollowing\":false,\"totalReactions\":21,\"totalReactionsByCurrentUser\":0,\"series\":null,\"isPinnedToBlog\":false,\"readTime\":14,\"sB\":false,\"isAMA\":false,\"subtitle\":\"\",\"isPartOfSeries\":false,\"hasTags\":true,\"ogImage\":\"\",\"metaTitle\":\"\",\"metaDescription\":\"Unlock the full potential of database interactions with our guide on Natural Language to SQL using LangChain and LLM.\",\"isRepublished\":false,\"autoPublishedFromRSS\":false,\"responses\":[],\"isFeatured\":false,\"hasLatex\":false,\"stickCoverToBottom\":false,\"hideBadges\":false,\"badges\":[],\"isDelisted\":false,\"audioUrls\":{},\"disableComments\":false,\"enableToc\":true,\"toc\":[[{\"id\":\"6a4b64cc-4dc7-498c-babd-f79152ec0916\",\"level\":2,\"slug\":\"introduction\",\"title\":\"Introduction\",\"parentId\":null}],[{\"id\":\"89f6377b-515f-410a-b612-3b1926dd7e4a\",\"level\":2,\"slug\":\"building-a-basic-nl2sql-model\",\"title\":\"Building a Basic NL2SQL Model\",\"parentId\":null}],[{\"id\":\"bb4ff478-b5bb-4962-9895-16c826212a1b\",\"level\":4,\"slug\":\"understanding-the-basics\",\"title\":\"Understanding the Basics\",\"parentId\":\"89f6377b-515f-410a-b612-3b1926dd7e4a\"}],[{\"id\":\"ea22420b-75d2-492c-9394-425d5309cb14\",\"level\":4,\"slug\":\"setting-up-langchain\",\"title\":\"Setting Up LangChain\",\"parentId\":\"89f6377b-515f-410a-b612-3b1926dd7e4a\"}],[{\"id\":\"622473cc-a30e-490d-a5a6-055c1bb8156f\",\"level\":4,\"slug\":\"the-first-query\",\"title\":\"The First Query\",\"parentId\":\"89f6377b-515f-410a-b612-3b1926dd7e4a\"}],[{\"id\":\"6163595a-a60a-492a-acc2-8301e380bb3a\",\"level\":4,\"slug\":\"seeing-the-results\",\"title\":\"Seeing the Results\",\"parentId\":\"89f6377b-515f-410a-b612-3b1926dd7e4a\"}],[{\"id\":\"3ab1b020-4a7e-49e8-b8b9-8327280d5c38\",\"level\":4,\"slug\":\"moving-forward\",\"title\":\"Moving Forward\",\"parentId\":\"89f6377b-515f-410a-b612-3b1926dd7e4a\"}],[{\"id\":\"23abf3fc-5dce-4913-bd2e-6f4deefc4c80\",\"level\":2,\"slug\":\"rephrasing-answers-for-enhanced-clarity\",\"title\":\"Rephrasing Answers for Enhanced Clarity\",\"parentId\":null}],[{\"id\":\"2723367f-11b2-4b0b-8f80-ac78795c0455\",\"level\":4,\"slug\":\"implementing-rephrasing-with-langchain\",\"title\":\"Implementing Rephrasing with LangChain\",\"parentId\":\"23abf3fc-5dce-4913-bd2e-6f4deefc4c80\"}],[{\"id\":\"723b6b1a-9890-423f-9e23-39705a3d3a0b\",\"level\":4,\"slug\":\"example-transforming-sql-results-into-user-friendly-responses\",\"title\":\"Example: Transforming SQL Results into User-Friendly Responses\",\"parentId\":\"23abf3fc-5dce-4913-bd2e-6f4deefc4c80\"}],[{\"id\":\"6c7b4aff-61de-4eef-92f6-0d3509afb5f7\",\"level\":2,\"slug\":\"enhancing-nl2sql-models-with-few-shot-examples\",\"title\":\"Enhancing NL2SQL Models with Few-Shot Examples\",\"parentId\":null}],[{\"id\":\"29b8ba8c-a202-42aa-bc3a-079048290ff2\",\"level\":4,\"slug\":\"incorporating-few-shot-examples-into-langchain\",\"title\":\"Incorporating Few-Shot Examples into LangChain\",\"parentId\":\"6c7b4aff-61de-4eef-92f6-0d3509afb5f7\"}],[{\"id\":\"48bfcd04-66ab-4ee5-b177-1a75ad1c7e4d\",\"level\":4,\"slug\":\"the-impact-of-few-shot-learning\",\"title\":\"The Impact of Few-Shot Learning\",\"parentId\":\"6c7b4aff-61de-4eef-92f6-0d3509afb5f7\"}],[{\"id\":\"145d30b6-096f-405f-a44c-c86b4279f723\",\"level\":2,\"slug\":\"dynamic-few-shot-example-selection\",\"title\":\"Dynamic Few-Shot Example Selection:\",\"parentId\":null}],[{\"id\":\"29c4be64-f1b4-4156-abc1-41e406f9bc47\",\"level\":4,\"slug\":\"the-need-for-dynamism\",\"title\":\"The Need for Dynamism\",\"parentId\":\"145d30b6-096f-405f-a44c-c86b4279f723\"}],[{\"id\":\"7f2d3a9d-cdba-4667-8813-116b0f92f119\",\"level\":4,\"slug\":\"implementing-dynamic-few-shot-selection\",\"title\":\"Implementing Dynamic Few-Shot Selection\",\"parentId\":\"145d30b6-096f-405f-a44c-c86b4279f723\"}],[{\"id\":\"8d8fc6ef-2108-4a4f-af9f-80f72789047a\",\"level\":2,\"slug\":\"dynamic-relevant-table-selection\",\"title\":\"Dynamic Relevant Table Selection\",\"parentId\":null}],[{\"id\":\"6b7f41f4-1020-416a-b891-50a1373b6a91\",\"level\":4,\"slug\":\"leveraging-smaller-focused-prompts-for-faster-execution\",\"title\":\"Leveraging Smaller, Focused Prompts for Faster Execution\",\"parentId\":\"8d8fc6ef-2108-4a4f-af9f-80f72789047a\"}],[{\"id\":\"0039f550-0787-4861-9971-1cd12bc7f576\",\"level\":2,\"slug\":\"enhancing-chatbots-with-memory-for-follow-up-database-queries\",\"title\":\"Enhancing Chatbots with Memory for Follow-up Database Queries\",\"parentId\":null}],[{\"id\":\"633b8ee7-b47b-4fa2-b05b-e3ab6e26626a\",\"level\":4,\"slug\":\"the-significance-of-memory-in-chatbots\",\"title\":\"The Significance of Memory in Chatbots\",\"parentId\":\"0039f550-0787-4861-9971-1cd12bc7f576\"}],[{\"id\":\"c24d59b1-7af7-4601-8f48-0c67f3210e3b\",\"level\":4,\"slug\":\"implementing-memory-in-your-nl2sql-model\",\"title\":\"Implementing Memory in Your NL2SQL Model\",\"parentId\":\"0039f550-0787-4861-9971-1cd12bc7f576\"}],[{\"id\":\"4323aad8-b5b2-4ade-9d71-61fdcdc71b2f\",\"level\":4,\"slug\":\"example-scenario-handling-follow-up-questions\",\"title\":\"Example Scenario: Handling Follow-Up Questions\",\"parentId\":\"0039f550-0787-4861-9971-1cd12bc7f576\"}],[{\"id\":\"b7148ae5-6032-4ffd-bd89-102a74b799a5\",\"level\":2,\"slug\":\"conclusion\",\"title\":\"Conclusion:\",\"parentId\":null}]],\"noIndex\":false}","publication":"{\"__typename\":\"Publication\",\"id\":\"6294f745136694dfeee8e80c\",\"url\":\"https://blog.futuresmart.ai\",\"canonicalURL\":\"https://blog.futuresmart.ai\",\"urlPattern\":\"SIMPLE\",\"title\":\"FutureSmart AI Blog\",\"displayTitle\":\"Building Custom NLP Solutions using state of the art NLP models | FutureSmart AI\",\"hasBadges\":true,\"descriptionSEO\":\"Learn how to build custom Natural Language Processing (NLP) solutions using state-of-the-art models. Use Pytorch, Amazon Lex, FastAPI, and Hugging Face Transformers to create powerful applications.\",\"publicMembers\":{\"totalDocuments\":16},\"about\":{\"html\":\"\u003cp\u003eFutureSmart AI provides custom Natural Language Processing (NLP) solutions.\u003c/p\u003e\\n\",\"text\":\"FutureSmart AI provides custom Natural Language Processing (NLP) solutions.\\n\"},\"features\":{\"proTeam\":{\"isEnabled\":false},\"newsletter\":{\"isEnabled\":false},\"viewCount\":{\"isEnabled\":false},\"readTime\":{\"isEnabled\":true},\"textSelectionSharer\":{\"isEnabled\":true},\"customCSS\":{\"isEnabled\":false,\"published\":null,\"draft\":null},\"gptBotCrawling\":{\"__typename\":\"GPTBotCrawlingFeature\",\"isEnabled\":false}},\"metaTags\":\"\u003cmeta name=\\\"google-site-verification\\\" content=\\\"hjDPYL5JIhkWAQpDvFOQHPr81ODcsYielMtN-_oZQSg\\\" /\u003e\",\"ogMetaData\":{\"image\":null},\"author\":{\"__typename\":\"User\",\"id\":\"610e6befb79d6a11366814e1\",\"name\":\"Pradip Nichite\",\"username\":\"pnichite\",\"profilePicture\":\"https://cdn.hashnode.com/res/hashnode/image/upload/v1629011734354/sgLB_1lXJ.jpeg\"},\"preferences\":{\"__typename\":\"Preferences\",\"logo\":null,\"darkMode\":{\"__typename\":\"DarkModePreferences\",\"logo\":null,\"enabled\":null},\"navbarItems\":[{\"__typename\":\"PublicationNavbarItem\",\"id\":\"6294fc0d1ef08fdfc9f632ba\",\"label\":\"website\",\"url\":\"https://www.futuresmart.ai/\",\"type\":\"link\",\"series\":null,\"page\":null},{\"__typename\":\"PublicationNavbarItem\",\"id\":\"6358d50ff001c905d3bc60be\",\"label\":\"Youtube\",\"url\":\"https://www.youtube.com/c/PradipNichiteAI\",\"type\":\"link\",\"series\":null,\"page\":null},{\"__typename\":\"PublicationNavbarItem\",\"id\":\"6358d543c1d1be05714fa376\",\"label\":\"LinkedIN\",\"url\":\"https://www.linkedin.com/in/pradipnichite/\",\"type\":\"link\",\"series\":null,\"page\":null},{\"__typename\":\"PublicationNavbarItem\",\"id\":\"63ca4e7d587fc59d3cd72863\",\"label\":\"AI Demos\",\"url\":\"https://www.aidemos.com/\",\"type\":\"link\",\"series\":null,\"page\":null}],\"enabledPages\":{\"__typename\":\"PagesPreferences\",\"badges\":false,\"newsletter\":false,\"members\":true},\"layout\":\"stacked\",\"disableFooterBranding\":false,\"isSubscriptionModalDisabled\":false},\"favicon\":null,\"headerColor\":\"#2962FF\",\"integrations\":{\"fbPixelID\":\"\",\"fathomSiteID\":\"\",\"fathomCustomDomainEnabled\":null,\"fathomCustomDomain\":\"\",\"hotjarSiteID\":\"\",\"matomoSiteID\":null,\"matomoURL\":\"\",\"gaTrackingID\":\"G-X68KZGCNTQ\",\"gTagManagerID\":null,\"plausibleAnalyticsEnabled\":null,\"wmPaymentPointer\":\"\",\"koalaPublicKey\":null,\"msClarityID\":null},\"imprintV2\":null,\"postsCount\":{\"totalDocuments\":105},\"isTeam\":true,\"links\":{\"twitter\":\"\",\"instagram\":\"https://www.instagram.com/futuresmart.ai\",\"github\":\"\",\"website\":\"https://www.futuresmart.ai/\",\"hashnode\":\"\",\"youtube\":\"https://www.youtube.com/c/PradipNichiteAI\",\"dailydev\":\"\",\"linkedin\":\"\",\"mastodon\":null,\"facebook\":null,\"bluesky\":null},\"domainInfo\":{\"__typename\":\"DomainInfo\",\"hashnodeSubdomain\":\"pnichite-1653929794900\",\"domain\":{\"__typename\":\"DomainStatus\",\"host\":\"blog.futuresmart.ai\",\"ready\":true},\"wwwPrefixedDomain\":null},\"redirectionRules\":[],\"totalRecommendedPublications\":0,\"sponsorship\":{\"content\":null,\"stripe\":null},\"allowContributorEdits\":true,\"rssImport\":null,\"post\":{\"id\":\"65eedf3f2e25d54cd93c3d52\",\"cuid\":\"cltmt9d8u000308jy744l8n74\",\"title\":\"Mastering Natural Language to SQL with LangChain | NL2SQL\",\"subtitle\":null,\"slug\":\"mastering-natural-language-to-sql-with-langchain-nl2sql\",\"brief\":\"Introduction\\nWelcome to our deep dive into revolutionizing the way we interact with databases using Natural Language Processing (NLP) and LangChain. In today's data-driven world, the ability to query databases without needing to know complex SQL synt...\",\"featured\":false,\"publishedAt\":\"2024-03-11T10:38:55.566Z\",\"updatedAt\":\"2024-03-11T10:40:28.637Z\",\"author\":{\"__typename\":\"User\",\"id\":\"610e6befb79d6a11366814e1\",\"name\":\"Pradip Nichite\",\"username\":\"pnichite\",\"deactivated\":false,\"profilePicture\":\"https://cdn.hashnode.com/res/hashnode/image/upload/v1629011734354/sgLB_1lXJ.jpeg\",\"bio\":{\"html\":\"\u003cp\u003e🚀 I'm a Top Rated Plus NLP freelancer on Upwork with over $300K in earnings and a 100% Job Success rate. This journey began in 2022 after years of enriching experience in the field of Data Science.\\n📚 Starting my career in 2013 as a Software Developer focusing on backend and API development, I soon pursued my interest in Data Science by earning my M.Tech in IT from IIIT Bangalore, specializing in Data Science (2016 - 2018).\\n💼 Upon graduation, I carved out a path in the industry as a Data Scientist at MiQ (2018 - 2020) and later ascended to the role of Lead Data Scientist at Oracle (2020 - 2022).\\n🌐 Inspired by my freelancing success, I founded FutureSmart AI in September 2022. We provide custom AI solutions for clients using the latest models and techniques in NLP.\\n🎥 In addition, I run AI Demos, a platform aimed at educating people about the latest AI tools through engaging video demonstrations.\\n🧰 My technical toolbox encompasses:\\n🔧 Languages: Python, JavaScript, SQL.\\n🧪 ML Libraries: PyTorch, Transformers, LangChain.\\n🔍 Specialties: Semantic Search, Sentence Transformers, Vector Databases.\\n🖥️ Web Frameworks: FastAPI, Streamlit, Anvil.\\n☁️ Other: AWS, AWS RDS, MySQL.\\n🚀 In the fast-evolving landscape of AI, FutureSmart AI and I stand at the forefront, delivering cutting-edge, custom NLP solutions to clients across various industries.\u003c/p\u003e\\n\"},\"socialMediaLinks\":{\"website\":\"https://www.futuresmart.ai/\",\"github\":\"\",\"twitter\":\"\",\"facebook\":\"\",\"stackoverflow\":\"\",\"linkedin\":\"https://www.linkedin.com/in/pradipnichite/\"}},\"coAuthors\":[],\"seo\":{\"title\":null,\"description\":\"Unlock the full potential of database interactions with our guide on Natural Language to SQL using LangChain and LLM.\",\"shouldNotIndex\":false},\"coverImage\":{\"url\":\"https://cdn.hashnode.com/res/hashnode/image/upload/v1710152478787/e57074e2-3303-46ec-8491-11f60aa0bd2d.png\",\"isPortrait\":false,\"attribution\":null,\"isAttributionHidden\":false,\"photographer\":null},\"responseCount\":5,\"reactionCount\":21,\"replyCount\":0,\"content\":{\"html\":\"\u003ch2 id=\\\"heading-introduction\\\"\u003eIntroduction\u003c/h2\u003e\\n\u003cp\u003eWelcome to our deep dive into revolutionizing the way we interact with databases using Natural Language Processing (NLP) and LangChain. In today's data-driven world, the ability to query databases without needing to know complex SQL syntax opens up a myriad of possibilities across various industries, from healthcare to finance, making data more accessible to everyone.\u003c/p\u003e\\n\u003cp\u003eThis blog post aims to guide you through a comprehensive journey to master NL2SQL using LangChain. We will explore the steps necessary to build an intuitive, efficient, and intelligent NL2SQL model that can understand and process natural language queries, dynamically select relevant database tables, and maintain a conversational context to handle follow-up questions effectively.\u003c/p\u003e\\n\u003cp\u003eBy the end of this post, you'll have a solid understanding of:\u003c/p\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eBuilding a Basic NL2SQL Model\u003c/strong\u003e: The foundation of translating natural language queries into SQL commands.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eIncorporating Few-Shot Learning\u003c/strong\u003e: Enhancing model accuracy with examples.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eDynamic Few-Shot Example Selection\u003c/strong\u003e: Tailoring examples to the query context for improved relevance.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eDynamic Relevant Table Selection\u003c/strong\u003e: Automatically identifying which tables to query based on the natural language input.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eCustomizing Prompts and Responses\u003c/strong\u003e: Fine-tuning the model's interaction to provide clear, concise, and relevant answers.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eAdding Memory to Chatbots\u003c/strong\u003e: Enabling the model to handle follow-up questions by remembering the context of the conversation.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003cp\u003eThrough each of these steps, we'll discuss the concepts, show you how to implement them , and illustrate the outcomes , ensuring you have the tools and knowledge needed to bring the power of NL2SQL to your databases.\u003c/p\u003e\\n\u003cp\u003eLet's embark on this exciting journey to unlock the full potential of your data, making database queries as simple as conversing with a friend.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-building-a-basic-nl2sql-model\\\"\u003eBuilding a Basic NL2SQL Model\u003c/h2\u003e\\n\u003cp\u003eThe first step in our journey to revolutionize database querying with natural language is constructing a basic NL2SQL model using LangChain. This foundational model serves as the cornerstone for more advanced functionalities we'll explore later. Here's how we begin:\u003c/p\u003e\\n\u003ch4 id=\\\"heading-understanding-the-basics\\\"\u003eUnderstanding the Basics\u003c/h4\u003e\\n\u003cp\u003eAt its core, an NL2SQL model aims to translate natural language queries into SQL commands. But how do we start building such a model with LangChain?\u003c/p\u003e\\n\u003ch4 id=\\\"heading-setting-up-langchain\\\"\u003eSetting Up LangChain\u003c/h4\u003e\\n\u003cp\u003eLangChain simplifies the process of creating NL2SQL models by providing a flexible framework that integrates seamlessly with existing databases and natural language processing (NLP) models. To get started, you'll need to:\u003c/p\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eInstall LangChain\u003c/strong\u003e: Ensure that LangChain is installed in your environment.\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-bash\\\"\u003e pip install langchain_openai langchain_community langchain pymysql chromadb -q\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eConnect to Your Database\u003c/strong\u003e: The next step involves establishing a connection to your database. LangChain supports various database systems, so you'll likely find your database among the supported ones. You'll use the database credentials to create a connection that LangChain can use to interact with your data\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e os\\n os.environ[\u003cspan class=\\\"hljs-string\\\"\u003e\\\"OPENAI_API_KEY\\\"\u003c/span\u003e] = \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\u003c/span\u003e\\n\\n db_user = \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\u003c/span\u003e\\n db_password = \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\u003c/span\u003e\\n db_host = \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\u003c/span\u003e\\n db_name = \u003cspan class=\\\"hljs-string\\\"\u003e\\\"classicmodels\\\"\u003c/span\u003e\\n \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_community.utilities.sql_database \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e SQLDatabase\\n \u003cspan class=\\\"hljs-comment\\\"\u003e# db = SQLDatabase.from_uri(f\\\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\\\",sample_rows_in_table_info=1,include_tables=['customers','orders'],custom_table_info={'customers':\\\"customer\\\"})\u003c/span\u003e\\n db = SQLDatabase.from_uri(\u003cspan class=\\\"hljs-string\\\"\u003ef\\\"mysql+pymysql://\u003cspan class=\\\"hljs-subst\\\"\u003e{db_user}\u003c/span\u003e:\u003cspan class=\\\"hljs-subst\\\"\u003e{db_password}\u003c/span\u003e@\u003cspan class=\\\"hljs-subst\\\"\u003e{db_host}\u003c/span\u003e/\u003cspan class=\\\"hljs-subst\\\"\u003e{db_name}\u003c/span\u003e\\\"\u003c/span\u003e)\\n print(db.dialect)\\n print(db.get_usable_table_names())\\n print(db.table_info)\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003ch4 id=\\\"heading-the-first-query\\\"\u003eThe First Query\u003c/h4\u003e\\n\u003cp\u003eOnce the setup is complete, the real magic begins. You can start by formulating a simple query in natural language, such as \\\"Show me all products priced above $100.\\\" LangChain takes this input and, through its integration with language models like ChatGPT and your database, generates an SQL query that precisely captures the intent of your request\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain.chains \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e create_sql_query_chain\\n\u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_openai \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e ChatOpenAI\\n\\nllm = ChatOpenAI(model=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"gpt-3.5-turbo\\\"\u003c/span\u003e, temperature=\u003cspan class=\\\"hljs-number\\\"\u003e0\u003c/span\u003e)\\ngenerate_query = create_sql_query_chain(llm, db)\\nquery = generate_query.invoke({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"question\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"what is price of `1968 Ford Mustang`\\\"\u003c/span\u003e})\\n\u003cspan class=\\\"hljs-comment\\\"\u003e# \\\"what is price of `1968 Ford Mustang`\\\"\u003c/span\u003e\\nprint(query)\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch4 id=\\\"heading-seeing-the-results\\\"\u003eSeeing the Results\u003c/h4\u003e\\n\u003cp\u003eExecuting the generated SQL query against your database retrieves the data you're looking for, which LangChain can then present in a user-friendly format.\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_community.tools.sql_database.tool \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e QuerySQLDataBaseTool\\nexecute_query = QuerySQLDataBaseTool(db=db)\\nexecute_query.invoke(query)\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch4 id=\\\"heading-moving-forward\\\"\u003eMoving Forward\u003c/h4\u003e\\n\u003cp\u003eWith the basic NL2SQL model set up, you've taken the first step towards transforming how we interact with databases. However, this is just the beginning. As we progress, we'll explore how to enhance the model's accuracy, handle more complex queries, and even maintain context over a conversation for follow-up questions.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-rephrasing-answers-for-enhanced-clarity\\\"\u003eRephrasing Answers for Enhanced Clarity\u003c/h2\u003e\\n\u003cp\u003eAfter your NL2SQL model successfully executes a SQL query, the next pivotal step is to present the data in a manner that's easily understandable by your users. This is where the art of rephrasing SQL results into clear, natural language answers comes into play. Here's how you can achieve this with LangChain:\u003c/p\u003e\\n\u003ch4 id=\\\"heading-implementing-rephrasing-with-langchain\\\"\u003eImplementing Rephrasing with LangChain\u003c/h4\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eUse Prompt Templates\u003c/strong\u003e: LangChain allows you to create prompt templates that can guide the model in how to rephrase SQL results. These templates can include placeholders for the original question, the SQL query, and the query result, setting the stage for generating a natural language response\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e operator \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e itemgetter\\n\\n \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_core.output_parsers \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e StrOutputParser\\n \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_core.prompts \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e PromptTemplate\\n \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_core.runnables \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e RunnablePassthrough\\n\\n answer_prompt = PromptTemplate.from_template(\\n     \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\\\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\\n\\n Question: {question}\\n SQL Query: {query}\\n SQL Result: {result}\\n Answer: \\\"\\\"\\\"\u003c/span\u003e\\n )\\n\\n rephrase_answer = answer_prompt | llm | StrOutputParser()\\n\\n chain = (\\n     RunnablePassthrough.assign(query=generate_query).assign(\\n         result=itemgetter(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"query\\\"\u003c/span\u003e) | execute_query\\n     )\\n     | rephrase_answer\\n )\\n\\n chain.invoke({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"question\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"How many customers have an order count greater than 5\\\"\u003c/span\u003e})\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003ch4 id=\\\"heading-example-transforming-sql-results-into-user-friendly-responses\\\"\u003eExample: Transforming SQL Results into User-Friendly Responses\u003c/h4\u003e\\n\u003cp\u003eLet's consider a user asks, \\\"How many customers have an order count greater than 5?\\\" and the SQL query returns a raw numerical result. The rephrasing process would convert this into a more readable answer, such as \\\"There are 2 customers with an order count of more than 5.\\\" This step is vital in closing the loop between user queries and database responses, ensuring that the information provided is both useful and easily digestible\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-plaintext\\\"\u003eThere are 2 customers with an order count of more than 5.\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eIn the next section, we'll dive into the exciting world of few-shot learning and how it can be used to improve the performance of your NL2SQL model with LangChain. Stay tuned to unlock the full potential of natural language database querying.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-enhancing-nl2sql-models-with-few-shot-examples\\\"\u003eEnhancing NL2SQL Models with Few-Shot Examples\u003c/h2\u003e\\n\u003cp\u003eThis technique involves providing the model with a small set of carefully selected examples that demonstrate how to convert natural language questions into SQL queries. Few-shot learning can significantly improve the model's ability to understand and generate precise SQL commands based on user queries, bridging the gap between human language and database querying.\u003c/p\u003e\\n\u003ch4 id=\\\"heading-incorporating-few-shot-examples-into-langchain\\\"\u003eIncorporating Few-Shot Examples into LangChain\u003c/h4\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eSelecting Relevant Examples\u003c/strong\u003e: The first step is to curate a set of examples that cover a broad range of query types and complexities. These examples should ideally reflect the most common or critical queries your users might perform\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-plaintext\\\"\u003e examples = [\\n     {\\n         \\\"input\\\": \\\"List all customers in France with a credit limit over 20,000.\\\",\\n         \\\"query\\\": \\\"SELECT * FROM customers WHERE country = 'France' AND creditLimit \u0026gt; 20000;\\\"\\n     },\\n     {\\n         \\\"input\\\": \\\"Get the highest payment amount made by any customer.\\\",\\n         \\\"query\\\": \\\"SELECT MAX(amount) FROM payments;\\\"\\n     },\\n    .....\\n ]\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eCreating a Few-Shot Learning Template\u003c/strong\u003e: With LangChain, you can design a prompt template that incorporates these examples into the model's workflow. The template instructs the model to consider the examples when generating SQL queries from new user questions\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_core.prompts \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e ChatPromptTemplate, MessagesPlaceholder,FewShotChatMessagePromptTemplate,PromptTemplate\\n\\n example_prompt = ChatPromptTemplate.from_messages(\\n     [\\n         (\u003cspan class=\\\"hljs-string\\\"\u003e\\\"human\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"{input}\\\\nSQLQuery:\\\"\u003c/span\u003e),\\n         (\u003cspan class=\\\"hljs-string\\\"\u003e\\\"ai\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"{query}\\\"\u003c/span\u003e),\\n     ]\\n )\\n few_shot_prompt = FewShotChatMessagePromptTemplate(\\n     example_prompt=example_prompt,\\n     examples=examples,\\n     \u003cspan class=\\\"hljs-comment\\\"\u003e# input_variables=[\\\"input\\\",\\\"top_k\\\"],\u003c/span\u003e\\n     input_variables=[\u003cspan class=\\\"hljs-string\\\"\u003e\\\"input\\\"\u003c/span\u003e],\\n )\\n print(few_shot_prompt.format(input1=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"How many products are there?\\\"\u003c/span\u003e))\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-plaintext\\\"\u003e Human: List all customers in France with a credit limit over 20,000.\\n SQLQuery:\\n AI: SELECT * FROM customers WHERE country = 'France' AND creditLimit \u0026gt; 20000;\\n Human: Get the highest payment amount made by any customer.\\n SQLQuery:\\n AI: SELECT MAX(amount) FROM payments;\\n ......\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003ch4 id=\\\"heading-the-impact-of-few-shot-learning\\\"\u003eThe Impact of Few-Shot Learning\u003c/h4\u003e\\n\u003cp\u003eBy integrating few-shot examples, your NL2SQL model becomes more adept at handling a wider variety of user queries. This not only improves the user experience by providing more accurate and relevant responses but also reduces the potential for errors in SQL query generation.\u003c/p\u003e\\n\u003cp\u003eIn the next section, we'll explore the integration of dynamic example selection to further enhance the model's accuracy and relevance, ensuring that your NL2SQL system remains adaptive and responsive to user queries.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-dynamic-few-shot-example-selection\\\"\u003eDynamic Few-Shot Example Selection:\u003c/h2\u003e\\n\u003cp\u003eThis advanced technique tailors the few-shot examples provided to the model based on the specific context of the user's query. It ensures that the guidance offered to the model is not just relevant but optimally aligned with the query's nuances, significantly boosting the model's ability to generate accurate SQL queries.\u003c/p\u003e\\n\u003ch4 id=\\\"heading-the-need-for-dynamism\\\"\u003eThe Need for Dynamism\u003c/h4\u003e\\n\u003cp\u003eStatic few-shot examples, though highly effective, have their limitations. Dynamic selection addresses this by intelligently choosing examples that closely match the intent and context of each new query, providing a customized learning experience for the model with every interaction.\u003c/p\u003e\\n\u003ch4 id=\\\"heading-implementing-dynamic-few-shot-selection\\\"\u003eImplementing Dynamic Few-Shot Selection\u003c/h4\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eExample Selector Configuration\u003c/strong\u003e: Begin by setting up an example selector that can analyze the semantics of the user's query and compare it with a repository of potential examples. Tools like semantic similarity algorithms and vector embeddings come into play here, identifying which examples are most relevant to the current query\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_community.vectorstores \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e Chroma\\n \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_core.example_selectors \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e SemanticSimilarityExampleSelector\\n \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_openai \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e OpenAIEmbeddings\\n\\n vectorstore = Chroma()\\n vectorstore.delete_collection()\\n example_selector = SemanticSimilarityExampleSelector.from_examples(\\n     examples,\\n     OpenAIEmbeddings(),\\n     vectorstore,\\n     k=\u003cspan class=\\\"hljs-number\\\"\u003e2\u003c/span\u003e,\\n     input_keys=[\u003cspan class=\\\"hljs-string\\\"\u003e\\\"input\\\"\u003c/span\u003e],\\n )\\n example_selector.select_examples({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"input\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"how many employees we have?\\\"\u003c/span\u003e})\\n few_shot_prompt = FewShotChatMessagePromptTemplate(\\n     example_prompt=example_prompt,\\n     example_selector=example_selector,\\n     input_variables=[\u003cspan class=\\\"hljs-string\\\"\u003e\\\"input\\\"\u003c/span\u003e,\u003cspan class=\\\"hljs-string\\\"\u003e\\\"top_k\\\"\u003c/span\u003e],\\n )\\n print(few_shot_prompt.format(input=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"How many products are there?\\\"\u003c/span\u003e))\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eIntegrating with LangChain\u003c/strong\u003e: Integrate the example selector with your LangChain workflow. When a new query is received, the selector determines the most relevant few-shot examples before the model generates the SQL query. This ensures that the guidance provided to the model is tailored to the specific requirements of the query\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e final_prompt = ChatPromptTemplate.from_messages(\\n     [\\n         (\u003cspan class=\\\"hljs-string\\\"\u003e\\\"system\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run. Unless otherwise specificed.\\\\n\\\\nHere is the relevant table info: {table_info}\\\\n\\\\nBelow are a number of examples of questions and their corresponding SQL queries.\\\"\u003c/span\u003e),\\n         few_shot_prompt,\\n         (\u003cspan class=\\\"hljs-string\\\"\u003e\\\"human\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"{input}\\\"\u003c/span\u003e),\\n     ]\\n )\\n print(final_prompt.format(input=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"How many products are there?\\\"\u003c/span\u003e,table_info=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"some table info\\\"\u003c/span\u003e))\\n generate_query = create_sql_query_chain(llm, db,final_prompt)\\n chain = (\\n RunnablePassthrough.assign(query=generate_query).assign(\\n     result=itemgetter(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"query\\\"\u003c/span\u003e) | execute_query\\n )\\n | rephrase_answer\\n )\\n chain.invoke({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"question\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"How many csutomers with credit limit more than 50000\\\"\u003c/span\u003e})\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-plaintext\\\"\u003e There are 85 customers with a credit limit greater than 50000.\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003cp\u003eBy ensuring that the examples used for guidance are always contextually relevant, the model can generate more precise SQL queries, reducing errors and improving user satisfaction. of NL2SQL technology, making data insights more accessible to everyone.\u003c/p\u003e\\n\u003cp\u003eIn the following section, we will explore the integration of dynamic relevant table selection, further advancing our NL2SQL model's capabilities to efficiently parse and respond to user queries.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-dynamic-relevant-table-selection\\\"\u003eDynamic Relevant Table Selection\u003c/h2\u003e\\n\u003cp\u003eIn the realm of NL2SQL models, especially when dealing with complex databases featuring 100+ tables. With databases growing in complexity and size, it's impractical and costly in terms of prompt token usage to include the schema of every table in the initial prompt for generating SQL queries. The sheer volume of information would overwhelm the model, leading to slower response times and increased computational costs. Dynamic relevant table selection emerges as a solution to this challenge, focusing the model's attention only on the tables pertinent to the user's query.\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e operator \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e itemgetter\\n\u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain.chains.openai_tools \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e create_extraction_chain_pydantic\\n\u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_core.pydantic_v1 \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e BaseModel, Field\\n\u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e typing \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e List\\n\u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e pandas \u003cspan class=\\\"hljs-keyword\\\"\u003eas\u003c/span\u003e pd\\n\\n\u003cspan class=\\\"hljs-function\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003eget_table_details\u003c/span\u003e():\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-comment\\\"\u003e# Read the CSV file into a DataFrame\u003c/span\u003e\\n    table_description = pd.read_csv(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"database_table_descriptions.csv\\\"\u003c/span\u003e)\\n    table_docs = []\\n\\n    \u003cspan class=\\\"hljs-comment\\\"\u003e# Iterate over the DataFrame rows to create Document objects\u003c/span\u003e\\n    table_details = \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003efor\u003c/span\u003e index, row \u003cspan class=\\\"hljs-keyword\\\"\u003ein\u003c/span\u003e table_description.iterrows():\\n        table_details = table_details + \u003cspan class=\\\"hljs-string\\\"\u003e\\\"Table Name:\\\"\u003c/span\u003e + row[\u003cspan class=\\\"hljs-string\\\"\u003e'Table'\u003c/span\u003e] + \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\\n\\\"\u003c/span\u003e + \u003cspan class=\\\"hljs-string\\\"\u003e\\\"Table Description:\\\"\u003c/span\u003e + row[\u003cspan class=\\\"hljs-string\\\"\u003e'Description'\u003c/span\u003e] + \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\\n\\\\n\\\"\u003c/span\u003e\\n\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e table_details\\n\\n\\n\u003cspan class=\\\"hljs-class\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003eclass\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003eTable\u003c/span\u003e(\u003cspan class=\\\"hljs-params\\\"\u003eBaseModel\u003c/span\u003e):\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\\\"Table in SQL database.\\\"\\\"\\\"\u003c/span\u003e\\n\\n    name: str = Field(description=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"Name of table in SQL database.\\\"\u003c/span\u003e)\\n\\n\u003cspan class=\\\"hljs-comment\\\"\u003e# table_names = \\\"\\\\n\\\".join(db.get_usable_table_names())\u003c/span\u003e\\ntable_details = get_table_details()\\nprint(table_details)\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-plaintext\\\"\u003eTable Name:productlines\\nTable Description:Stores information about the differ....\\n\\nTable Name:products\\nTable Description:Contains de....\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch4 id=\\\"heading-leveraging-smaller-focused-prompts-for-faster-execution\\\"\u003eLeveraging Smaller, Focused Prompts for Faster Execution\u003c/h4\u003e\\n\u003cp\u003eDynamic relevant table selection hinges on the principle that \\\"less is more.\\\" By reducing the scope of information the model needs to consider for each query:\u003c/p\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eImproved Model Performance\u003c/strong\u003e: Smaller prompts mean the model has fewer tokens to process, which translates to faster execution times. This is particularly crucial for interactive applications where response time is a key component of user satisfaction.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eEnhanced Accuracy\u003c/strong\u003e: Focusing on only the relevant tables minimizes the risk of generating incorrect SQL queries. This specificity ensures that the model's computational resources are dedicated to understanding and processing only the most pertinent data.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eCost-Efficiency\u003c/strong\u003e: Reducing the amount of prompt information also means fewer token usage costs. In the context of cloud-based NLP services, where processing costs can accumulate rapidly, this efficiency is not only a technical but also a financial advantage.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003etable_details_prompt = \u003cspan class=\\\"hljs-string\\\"\u003ef\\\"\\\"\\\"Return the names of ALL the SQL tables that MIGHT be relevant to the user question. \\\\\\nThe tables are:\\n\\n\u003cspan class=\\\"hljs-subst\\\"\u003e{table_details}\u003c/span\u003e\\n\\nRemember to include ALL POTENTIALLY RELEVANT tables, even if you're not sure that they're needed.\\\"\\\"\\\"\u003c/span\u003e\\n\\ntable_chain = create_extraction_chain_pydantic(Table, llm, system_message=table_details_prompt)\\ntables = table_chain.invoke({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"input\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"give me details of customer and their order count\\\"\u003c/span\u003e})\\ntables\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-plaintext\\\"\u003e[Table(name='customers'), Table(name='orders')]\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-function\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003eget_tables\u003c/span\u003e(\u003cspan class=\\\"hljs-params\\\"\u003etables: List[Table]\u003c/span\u003e) -\u0026gt; List[str]:\u003c/span\u003e\\n    tables  = [table.name \u003cspan class=\\\"hljs-keyword\\\"\u003efor\u003c/span\u003e table \u003cspan class=\\\"hljs-keyword\\\"\u003ein\u003c/span\u003e tables]\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e tables\\n\\nselect_table = {\u003cspan class=\\\"hljs-string\\\"\u003e\\\"input\\\"\u003c/span\u003e: itemgetter(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"question\\\"\u003c/span\u003e)} | create_extraction_chain_pydantic(Table, llm, system_message=table_details_prompt) | get_tables\\nselect_table.invoke({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"question\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"give me details of customer and their order count\\\"\u003c/span\u003e})\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-plaintext\\\"\u003e['customers', 'orders']\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003echain = (\\nRunnablePassthrough.assign(table_names_to_use=select_table) |\\nRunnablePassthrough.assign(query=generate_query).assign(\\n    result=itemgetter(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"query\\\"\u003c/span\u003e) | execute_query\\n)\\n| rephrase_answer\\n)\\nchain.invoke({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"question\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"How many cutomers with order count more than 5\\\"\u003c/span\u003e})\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch2 id=\\\"heading-enhancing-chatbots-with-memory-for-follow-up-database-queries\\\"\u003eEnhancing Chatbots with Memory for Follow-up Database Queries\u003c/h2\u003e\\n\u003cp\u003eOne of the most advanced steps in creating a user-friendly NL2SQL interface is endowing your chatbot with memory. This feature enables the chatbot to handle follow-up questions related to the database intelligently, providing users with a seamless conversational experience. Let's explore how adding memory to your chatbot can revolutionize interactions with your database.\u003c/p\u003e\\n\u003ch4 id=\\\"heading-the-significance-of-memory-in-chatbots\\\"\u003eThe Significance of Memory in Chatbots\u003c/h4\u003e\\n\u003cp\u003eIn real-world conversations, context matters. A question might relate to or build upon previous interactions. Similarly, when users interact with a database through a chatbot, their follow-up questions often depend on the context established by earlier queries and responses. A chatbot equipped with memory can retain this context, allowing it to generate more accurate and relevant SQL queries for follow-up questions.\u003c/p\u003e\\n\u003ch4 id=\\\"heading-implementing-memory-in-your-nl2sql-model\\\"\u003eImplementing Memory in Your NL2SQL Model\u003c/h4\u003e\\n\u003cp\u003eTo equip your NL2SQL model with memory, consider incorporating a chat message history that tracks the conversation's flow. This history should include both the questions posed by the user and the chatbot's responses, enabling the model to reference previous interactions when generating SQL queries for new questions.\u003c/p\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eSetting Up Message History\u003c/strong\u003e: Implement a mechanism to record each user query and the corresponding chatbot response. This can be achieved by defining a \u003ccode\u003eChatMessageHistory\u003c/code\u003e object that stores this information and can be accessed when needed\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain.memory \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e ChatMessageHistory\\n history = ChatMessageHistory()\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eLeveraging Previous Interactions\u003c/strong\u003e: Integrate this message history into your prompt generation process. Before generating a new SQL query, the model should consider the recorded history to understand the conversation's context\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e final_prompt = ChatPromptTemplate.from_messages(\\n     [\\n         (\u003cspan class=\\\"hljs-string\\\"\u003e\\\"system\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run. Unless otherwise specificed.\\\\n\\\\nHere is the relevant table info: {table_info}\\\\n\\\\nBelow are a number of examples of questions and their corresponding SQL queries. Those examples are just for referecne and hsould be considered while answering follow up questions\\\"\u003c/span\u003e),\\n         few_shot_prompt,\\n         MessagesPlaceholder(variable_name=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"messages\\\"\u003c/span\u003e),\\n         (\u003cspan class=\\\"hljs-string\\\"\u003e\\\"human\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"{input}\\\"\u003c/span\u003e),\\n     ]\\n )\\n print(final_prompt.format(input=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"How many products are there?\\\"\u003c/span\u003e,table_info=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"some table info\\\"\u003c/span\u003e,messages=[]))\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eDynamic Prompt Adaptation\u003c/strong\u003e: Use the chat message history to dynamically adapt the prompts sent to the model for generating SQL queries. This adaptation should include information from previous queries and responses, guiding the model in understanding the context of the follow-up question\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e generate_query = create_sql_query_chain(llm, db,final_prompt)\\n\\n chain = (\\n RunnablePassthrough.assign(table_names_to_use=select_table) |\\n RunnablePassthrough.assign(query=generate_query).assign(\\n     result=itemgetter(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"query\\\"\u003c/span\u003e) | execute_query\\n )\\n | rephrase_answer\\n )\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003ch4 id=\\\"heading-example-scenario-handling-follow-up-questions\\\"\u003eExample Scenario: Handling Follow-Up Questions\u003c/h4\u003e\\n\u003cp\u003eImagine a user first asks, \\\"How many customers have an order count more than 5?\\\" After receiving the answer, they follow up with, \\\"Can you list their names?\\\" With a memory feature, the chatbot can understand that the second question relates to the subset of customers identified in response to the first question, allowing it to generate an accurate follow-up query without needing the user to re-specify the context.\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003equestion = \u003cspan class=\\\"hljs-string\\\"\u003e\\\"How many cutomers with order count more than 5\\\"\u003c/span\u003e\\nresponse = chain.invoke({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"question\\\"\u003c/span\u003e: question,\u003cspan class=\\\"hljs-string\\\"\u003e\\\"messages\\\"\u003c/span\u003e:history.messages})\\nThere are \u003cspan class=\\\"hljs-number\\\"\u003e2\u003c/span\u003e customers \u003cspan class=\\\"hljs-keyword\\\"\u003ewith\u003c/span\u003e an order count of more than \u003cspan class=\\\"hljs-number\\\"\u003e5.\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003ehistory.add_user_message(question)\\nhistory.add_ai_message(response)\\nhistory.messages\\n[HumanMessage(content=\u003cspan class=\\\"hljs-string\\\"\u003e'How many cutomers with order count more than 5'\u003c/span\u003e),\\n AIMessage(content=\u003cspan class=\\\"hljs-string\\\"\u003e'There are 2 customers with an order count of more than 5.'\u003c/span\u003e)]\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003eresponse = chain.invoke({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"question\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"Can you list there names?\\\"\u003c/span\u003e,\u003cspan class=\\\"hljs-string\\\"\u003e\\\"messages\\\"\u003c/span\u003e:history.messages})\\nresponse\\nThe names of the customers \u003cspan class=\\\"hljs-keyword\\\"\u003ewith\u003c/span\u003e more than \u003cspan class=\\\"hljs-number\\\"\u003e5\u003c/span\u003e orders are Mini Gifts Distributors Ltd. \u003cspan class=\\\"hljs-keyword\\\"\u003eand\u003c/span\u003e Euro+ Shopping Channel.\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch2 id=\\\"heading-conclusion\\\"\u003e\u003cstrong\u003eConclusion:\u003c/strong\u003e\u003c/h2\u003e\\n\u003cp\u003eThrough this guide, we've journeyed through the process of enhancing NL2SQL models using LangChain, showcasing how to transform natural language queries into precise SQL commands. This exploration not only highlights the power of LangChain in making database queries more accessible but also underscores the broader impact of integrating advanced NLP techniques for intuitive data interaction.\u003c/p\u003e\\n\u003cp\u003eFor those interested in delving deeper, a \u003ca target=\\\"_blank\\\" href=\\\"https://youtu.be/fss6CrmQU2Y\\\"\u003evideo walkthrough\u003c/a\u003e and a comprehensive \u003ca target=\\\"_blank\\\" href=\\\"https://github.com/PradipNichite/Youtube-Tutorials/blob/main/Langchain_NL2SQL_2024.ipynb\\\"\u003eGitHub notebook\u003c/a\u003e and \u003ca target=\\\"_blank\\\" href=\\\"https://github.com/PradipNichite/Youtube-Tutorials/tree/main/Langchain%20NL2SQL%20Chatbot\\\"\u003eStreamlit Code\u003c/a\u003e are available to explore these concepts further. These resources offer visual demonstrations and hands-on examples to help bring these ideas to life in your own projects.\u003c/p\u003e\\n\u003cp\u003eThe journey toward more natural and efficient database interactions is ongoing, and with each step, we're making the world of data more accessible to all.\u003c/p\u003e\\n\u003cp\u003eIf you're curious about the latest in AI technology, I invite you to visit my project, AI Demos, at \u003ca target=\\\"_blank\\\" href=\\\"http://aidemos.com/\\\"\u003e\u003cstrong\u003eaidemos.com\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e. It's a rich resource offering a wide array of video demos showcasing the most advanced AI tools. My goal with AI Demos is to educate and illuminate the diverse possibilities of AI.\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eFor even more in-depth exploration, be sure to visit my YouTube channel at \u003ca target=\\\"_blank\\\" href=\\\"https://www.youtube.com/@aidemos.videos\\\"\u003ehttps://www.youtube.com/@aidemos.videos\u003c/a\u003e\u003cstrong\u003e. Here, you'll find a wealth of content that delves into the exciting future of AI and its various applications.\u003c/strong\u003e\u003c/p\u003e\\n\",\"markdown\":\"## Introduction\\n\\nWelcome to our deep dive into revolutionizing the way we interact with databases using Natural Language Processing (NLP) and LangChain. In today's data-driven world, the ability to query databases without needing to know complex SQL syntax opens up a myriad of possibilities across various industries, from healthcare to finance, making data more accessible to everyone.\\n\\nThis blog post aims to guide you through a comprehensive journey to master NL2SQL using LangChain. We will explore the steps necessary to build an intuitive, efficient, and intelligent NL2SQL model that can understand and process natural language queries, dynamically select relevant database tables, and maintain a conversational context to handle follow-up questions effectively.\\n\\nBy the end of this post, you'll have a solid understanding of:\\n\\n1. **Building a Basic NL2SQL Model**: The foundation of translating natural language queries into SQL commands.\\n    \\n2. **Incorporating Few-Shot Learning**: Enhancing model accuracy with examples.\\n    \\n3. **Dynamic Few-Shot Example Selection**: Tailoring examples to the query context for improved relevance.\\n    \\n4. **Dynamic Relevant Table Selection**: Automatically identifying which tables to query based on the natural language input.\\n    \\n5. **Customizing Prompts and Responses**: Fine-tuning the model's interaction to provide clear, concise, and relevant answers.\\n    \\n6. **Adding Memory to Chatbots**: Enabling the model to handle follow-up questions by remembering the context of the conversation.\\n    \\n\\nThrough each of these steps, we'll discuss the concepts, show you how to implement them , and illustrate the outcomes , ensuring you have the tools and knowledge needed to bring the power of NL2SQL to your databases.\\n\\nLet's embark on this exciting journey to unlock the full potential of your data, making database queries as simple as conversing with a friend.\\n\\n## Building a Basic NL2SQL Model\\n\\nThe first step in our journey to revolutionize database querying with natural language is constructing a basic NL2SQL model using LangChain. This foundational model serves as the cornerstone for more advanced functionalities we'll explore later. Here's how we begin:\\n\\n#### Understanding the Basics\\n\\nAt its core, an NL2SQL model aims to translate natural language queries into SQL commands. But how do we start building such a model with LangChain?\\n\\n#### Setting Up LangChain\\n\\nLangChain simplifies the process of creating NL2SQL models by providing a flexible framework that integrates seamlessly with existing databases and natural language processing (NLP) models. To get started, you'll need to:\\n\\n1. **Install LangChain**: Ensure that LangChain is installed in your environment.\\n    \\n    ```bash\\n    pip install langchain_openai langchain_community langchain pymysql chromadb -q\\n    ```\\n    \\n2. **Connect to Your Database**: The next step involves establishing a connection to your database. LangChain supports various database systems, so you'll likely find your database among the supported ones. You'll use the database credentials to create a connection that LangChain can use to interact with your data\\n    \\n    ```python\\n    import os\\n    os.environ[\\\"OPENAI_API_KEY\\\"] = \\\"\\\"\\n    \\n    db_user = \\\"\\\"\\n    db_password = \\\"\\\"\\n    db_host = \\\"\\\"\\n    db_name = \\\"classicmodels\\\"\\n    from langchain_community.utilities.sql_database import SQLDatabase\\n    # db = SQLDatabase.from_uri(f\\\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\\\",sample_rows_in_table_info=1,include_tables=['customers','orders'],custom_table_info={'customers':\\\"customer\\\"})\\n    db = SQLDatabase.from_uri(f\\\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\\\")\\n    print(db.dialect)\\n    print(db.get_usable_table_names())\\n    print(db.table_info)\\n    ```\\n    \\n\\n#### The First Query\\n\\nOnce the setup is complete, the real magic begins. You can start by formulating a simple query in natural language, such as \\\"Show me all products priced above $100.\\\" LangChain takes this input and, through its integration with language models like ChatGPT and your database, generates an SQL query that precisely captures the intent of your request\\n\\n```python\\nfrom langchain.chains import create_sql_query_chain\\nfrom langchain_openai import ChatOpenAI\\n\\nllm = ChatOpenAI(model=\\\"gpt-3.5-turbo\\\", temperature=0)\\ngenerate_query = create_sql_query_chain(llm, db)\\nquery = generate_query.invoke({\\\"question\\\": \\\"what is price of `1968 Ford Mustang`\\\"})\\n# \\\"what is price of `1968 Ford Mustang`\\\"\\nprint(query)\\n```\\n\\n#### Seeing the Results\\n\\nExecuting the generated SQL query against your database retrieves the data you're looking for, which LangChain can then present in a user-friendly format.\\n\\n```python\\nfrom langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\\nexecute_query = QuerySQLDataBaseTool(db=db)\\nexecute_query.invoke(query)\\n```\\n\\n#### Moving Forward\\n\\nWith the basic NL2SQL model set up, you've taken the first step towards transforming how we interact with databases. However, this is just the beginning. As we progress, we'll explore how to enhance the model's accuracy, handle more complex queries, and even maintain context over a conversation for follow-up questions.\\n\\n## Rephrasing Answers for Enhanced Clarity\\n\\nAfter your NL2SQL model successfully executes a SQL query, the next pivotal step is to present the data in a manner that's easily understandable by your users. This is where the art of rephrasing SQL results into clear, natural language answers comes into play. Here's how you can achieve this with LangChain:\\n\\n#### Implementing Rephrasing with LangChain\\n\\n1. **Use Prompt Templates**: LangChain allows you to create prompt templates that can guide the model in how to rephrase SQL results. These templates can include placeholders for the original question, the SQL query, and the query result, setting the stage for generating a natural language response\\n    \\n    ```python\\n    from operator import itemgetter\\n    \\n    from langchain_core.output_parsers import StrOutputParser\\n    from langchain_core.prompts import PromptTemplate\\n    from langchain_core.runnables import RunnablePassthrough\\n    \\n    answer_prompt = PromptTemplate.from_template(\\n        \\\"\\\"\\\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\\n    \\n    Question: {question}\\n    SQL Query: {query}\\n    SQL Result: {result}\\n    Answer: \\\"\\\"\\\"\\n    )\\n    \\n    rephrase_answer = answer_prompt | llm | StrOutputParser()\\n    \\n    chain = (\\n        RunnablePassthrough.assign(query=generate_query).assign(\\n            result=itemgetter(\\\"query\\\") | execute_query\\n        )\\n        | rephrase_answer\\n    )\\n    \\n    chain.invoke({\\\"question\\\": \\\"How many customers have an order count greater than 5\\\"})\\n    ```\\n    \\n\\n#### Example: Transforming SQL Results into User-Friendly Responses\\n\\nLet's consider a user asks, \\\"How many customers have an order count greater than 5?\\\" and the SQL query returns a raw numerical result. The rephrasing process would convert this into a more readable answer, such as \\\"There are 2 customers with an order count of more than 5.\\\" This step is vital in closing the loop between user queries and database responses, ensuring that the information provided is both useful and easily digestible\\n\\n```plaintext\\nThere are 2 customers with an order count of more than 5.\\n```\\n\\nIn the next section, we'll dive into the exciting world of few-shot learning and how it can be used to improve the performance of your NL2SQL model with LangChain. Stay tuned to unlock the full potential of natural language database querying.\\n\\n## Enhancing NL2SQL Models with Few-Shot Examples\\n\\nThis technique involves providing the model with a small set of carefully selected examples that demonstrate how to convert natural language questions into SQL queries. Few-shot learning can significantly improve the model's ability to understand and generate precise SQL commands based on user queries, bridging the gap between human language and database querying.\\n\\n#### Incorporating Few-Shot Examples into LangChain\\n\\n1. **Selecting Relevant Examples**: The first step is to curate a set of examples that cover a broad range of query types and complexities. These examples should ideally reflect the most common or critical queries your users might perform\\n    \\n    ```plaintext\\n    examples = [\\n        {\\n            \\\"input\\\": \\\"List all customers in France with a credit limit over 20,000.\\\",\\n            \\\"query\\\": \\\"SELECT * FROM customers WHERE country = 'France' AND creditLimit \u003e 20000;\\\"\\n        },\\n        {\\n            \\\"input\\\": \\\"Get the highest payment amount made by any customer.\\\",\\n            \\\"query\\\": \\\"SELECT MAX(amount) FROM payments;\\\"\\n        },\\n       .....\\n    ]\\n    ```\\n    \\n2. **Creating a Few-Shot Learning Template**: With LangChain, you can design a prompt template that incorporates these examples into the model's workflow. The template instructs the model to consider the examples when generating SQL queries from new user questions\\n    \\n    ```python\\n    from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder,FewShotChatMessagePromptTemplate,PromptTemplate\\n    \\n    example_prompt = ChatPromptTemplate.from_messages(\\n        [\\n            (\\\"human\\\", \\\"{input}\\\\nSQLQuery:\\\"),\\n            (\\\"ai\\\", \\\"{query}\\\"),\\n        ]\\n    )\\n    few_shot_prompt = FewShotChatMessagePromptTemplate(\\n        example_prompt=example_prompt,\\n        examples=examples,\\n        # input_variables=[\\\"input\\\",\\\"top_k\\\"],\\n        input_variables=[\\\"input\\\"],\\n    )\\n    print(few_shot_prompt.format(input1=\\\"How many products are there?\\\"))\\n    ```\\n    \\n    ```plaintext\\n    Human: List all customers in France with a credit limit over 20,000.\\n    SQLQuery:\\n    AI: SELECT * FROM customers WHERE country = 'France' AND creditLimit \u003e 20000;\\n    Human: Get the highest payment amount made by any customer.\\n    SQLQuery:\\n    AI: SELECT MAX(amount) FROM payments;\\n    ......\\n    ```\\n    \\n\\n#### The Impact of Few-Shot Learning\\n\\nBy integrating few-shot examples, your NL2SQL model becomes more adept at handling a wider variety of user queries. This not only improves the user experience by providing more accurate and relevant responses but also reduces the potential for errors in SQL query generation.\\n\\nIn the next section, we'll explore the integration of dynamic example selection to further enhance the model's accuracy and relevance, ensuring that your NL2SQL system remains adaptive and responsive to user queries.\\n\\n## Dynamic Few-Shot Example Selection:\\n\\nThis advanced technique tailors the few-shot examples provided to the model based on the specific context of the user's query. It ensures that the guidance offered to the model is not just relevant but optimally aligned with the query's nuances, significantly boosting the model's ability to generate accurate SQL queries.\\n\\n#### The Need for Dynamism\\n\\nStatic few-shot examples, though highly effective, have their limitations. Dynamic selection addresses this by intelligently choosing examples that closely match the intent and context of each new query, providing a customized learning experience for the model with every interaction.\\n\\n#### Implementing Dynamic Few-Shot Selection\\n\\n1. **Example Selector Configuration**: Begin by setting up an example selector that can analyze the semantics of the user's query and compare it with a repository of potential examples. Tools like semantic similarity algorithms and vector embeddings come into play here, identifying which examples are most relevant to the current query\\n    \\n    ```python\\n    from langchain_community.vectorstores import Chroma\\n    from langchain_core.example_selectors import SemanticSimilarityExampleSelector\\n    from langchain_openai import OpenAIEmbeddings\\n    \\n    vectorstore = Chroma()\\n    vectorstore.delete_collection()\\n    example_selector = SemanticSimilarityExampleSelector.from_examples(\\n        examples,\\n        OpenAIEmbeddings(),\\n        vectorstore,\\n        k=2,\\n        input_keys=[\\\"input\\\"],\\n    )\\n    example_selector.select_examples({\\\"input\\\": \\\"how many employees we have?\\\"})\\n    few_shot_prompt = FewShotChatMessagePromptTemplate(\\n        example_prompt=example_prompt,\\n        example_selector=example_selector,\\n        input_variables=[\\\"input\\\",\\\"top_k\\\"],\\n    )\\n    print(few_shot_prompt.format(input=\\\"How many products are there?\\\"))\\n    ```\\n    \\n2. **Integrating with LangChain**: Integrate the example selector with your LangChain workflow. When a new query is received, the selector determines the most relevant few-shot examples before the model generates the SQL query. This ensures that the guidance provided to the model is tailored to the specific requirements of the query\\n    \\n    ```python\\n    final_prompt = ChatPromptTemplate.from_messages(\\n        [\\n            (\\\"system\\\", \\\"You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run. Unless otherwise specificed.\\\\n\\\\nHere is the relevant table info: {table_info}\\\\n\\\\nBelow are a number of examples of questions and their corresponding SQL queries.\\\"),\\n            few_shot_prompt,\\n            (\\\"human\\\", \\\"{input}\\\"),\\n        ]\\n    )\\n    print(final_prompt.format(input=\\\"How many products are there?\\\",table_info=\\\"some table info\\\"))\\n    generate_query = create_sql_query_chain(llm, db,final_prompt)\\n    chain = (\\n    RunnablePassthrough.assign(query=generate_query).assign(\\n        result=itemgetter(\\\"query\\\") | execute_query\\n    )\\n    | rephrase_answer\\n    )\\n    chain.invoke({\\\"question\\\": \\\"How many csutomers with credit limit more than 50000\\\"})\\n    ```\\n    \\n    ```plaintext\\n    There are 85 customers with a credit limit greater than 50000.\\n    ```\\n    \\n\\nBy ensuring that the examples used for guidance are always contextually relevant, the model can generate more precise SQL queries, reducing errors and improving user satisfaction. of NL2SQL technology, making data insights more accessible to everyone.\\n\\nIn the following section, we will explore the integration of dynamic relevant table selection, further advancing our NL2SQL model's capabilities to efficiently parse and respond to user queries.\\n\\n## Dynamic Relevant Table Selection\\n\\nIn the realm of NL2SQL models, especially when dealing with complex databases featuring 100+ tables. With databases growing in complexity and size, it's impractical and costly in terms of prompt token usage to include the schema of every table in the initial prompt for generating SQL queries. The sheer volume of information would overwhelm the model, leading to slower response times and increased computational costs. Dynamic relevant table selection emerges as a solution to this challenge, focusing the model's attention only on the tables pertinent to the user's query.\\n\\n```python\\nfrom operator import itemgetter\\nfrom langchain.chains.openai_tools import create_extraction_chain_pydantic\\nfrom langchain_core.pydantic_v1 import BaseModel, Field\\nfrom typing import List\\nimport pandas as pd\\n\\ndef get_table_details():\\n    # Read the CSV file into a DataFrame\\n    table_description = pd.read_csv(\\\"database_table_descriptions.csv\\\")\\n    table_docs = []\\n\\n    # Iterate over the DataFrame rows to create Document objects\\n    table_details = \\\"\\\"\\n    for index, row in table_description.iterrows():\\n        table_details = table_details + \\\"Table Name:\\\" + row['Table'] + \\\"\\\\n\\\" + \\\"Table Description:\\\" + row['Description'] + \\\"\\\\n\\\\n\\\"\\n\\n    return table_details\\n\\n\\nclass Table(BaseModel):\\n    \\\"\\\"\\\"Table in SQL database.\\\"\\\"\\\"\\n\\n    name: str = Field(description=\\\"Name of table in SQL database.\\\")\\n\\n# table_names = \\\"\\\\n\\\".join(db.get_usable_table_names())\\ntable_details = get_table_details()\\nprint(table_details)\\n```\\n\\n```plaintext\\nTable Name:productlines\\nTable Description:Stores information about the differ....\\n\\nTable Name:products\\nTable Description:Contains de....\\n```\\n\\n#### Leveraging Smaller, Focused Prompts for Faster Execution\\n\\nDynamic relevant table selection hinges on the principle that \\\"less is more.\\\" By reducing the scope of information the model needs to consider for each query:\\n\\n1. **Improved Model Performance**: Smaller prompts mean the model has fewer tokens to process, which translates to faster execution times. This is particularly crucial for interactive applications where response time is a key component of user satisfaction.\\n    \\n2. **Enhanced Accuracy**: Focusing on only the relevant tables minimizes the risk of generating incorrect SQL queries. This specificity ensures that the model's computational resources are dedicated to understanding and processing only the most pertinent data.\\n    \\n3. **Cost-Efficiency**: Reducing the amount of prompt information also means fewer token usage costs. In the context of cloud-based NLP services, where processing costs can accumulate rapidly, this efficiency is not only a technical but also a financial advantage.\\n    \\n\\n```python\\ntable_details_prompt = f\\\"\\\"\\\"Return the names of ALL the SQL tables that MIGHT be relevant to the user question. \\\\\\nThe tables are:\\n\\n{table_details}\\n\\nRemember to include ALL POTENTIALLY RELEVANT tables, even if you're not sure that they're needed.\\\"\\\"\\\"\\n\\ntable_chain = create_extraction_chain_pydantic(Table, llm, system_message=table_details_prompt)\\ntables = table_chain.invoke({\\\"input\\\": \\\"give me details of customer and their order count\\\"})\\ntables\\n```\\n\\n```plaintext\\n[Table(name='customers'), Table(name='orders')]\\n```\\n\\n```python\\ndef get_tables(tables: List[Table]) -\u003e List[str]:\\n    tables  = [table.name for table in tables]\\n    return tables\\n\\nselect_table = {\\\"input\\\": itemgetter(\\\"question\\\")} | create_extraction_chain_pydantic(Table, llm, system_message=table_details_prompt) | get_tables\\nselect_table.invoke({\\\"question\\\": \\\"give me details of customer and their order count\\\"})\\n```\\n\\n```plaintext\\n['customers', 'orders']\\n```\\n\\n```python\\nchain = (\\nRunnablePassthrough.assign(table_names_to_use=select_table) |\\nRunnablePassthrough.assign(query=generate_query).assign(\\n    result=itemgetter(\\\"query\\\") | execute_query\\n)\\n| rephrase_answer\\n)\\nchain.invoke({\\\"question\\\": \\\"How many cutomers with order count more than 5\\\"})\\n```\\n\\n## Enhancing Chatbots with Memory for Follow-up Database Queries\\n\\nOne of the most advanced steps in creating a user-friendly NL2SQL interface is endowing your chatbot with memory. This feature enables the chatbot to handle follow-up questions related to the database intelligently, providing users with a seamless conversational experience. Let's explore how adding memory to your chatbot can revolutionize interactions with your database.\\n\\n#### The Significance of Memory in Chatbots\\n\\nIn real-world conversations, context matters. A question might relate to or build upon previous interactions. Similarly, when users interact with a database through a chatbot, their follow-up questions often depend on the context established by earlier queries and responses. A chatbot equipped with memory can retain this context, allowing it to generate more accurate and relevant SQL queries for follow-up questions.\\n\\n#### Implementing Memory in Your NL2SQL Model\\n\\nTo equip your NL2SQL model with memory, consider incorporating a chat message history that tracks the conversation's flow. This history should include both the questions posed by the user and the chatbot's responses, enabling the model to reference previous interactions when generating SQL queries for new questions.\\n\\n1. **Setting Up Message History**: Implement a mechanism to record each user query and the corresponding chatbot response. This can be achieved by defining a `ChatMessageHistory` object that stores this information and can be accessed when needed\\n    \\n    ```python\\n    from langchain.memory import ChatMessageHistory\\n    history = ChatMessageHistory()\\n    ```\\n    \\n2. **Leveraging Previous Interactions**: Integrate this message history into your prompt generation process. Before generating a new SQL query, the model should consider the recorded history to understand the conversation's context\\n    \\n    ```python\\n    final_prompt = ChatPromptTemplate.from_messages(\\n        [\\n            (\\\"system\\\", \\\"You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run. Unless otherwise specificed.\\\\n\\\\nHere is the relevant table info: {table_info}\\\\n\\\\nBelow are a number of examples of questions and their corresponding SQL queries. Those examples are just for referecne and hsould be considered while answering follow up questions\\\"),\\n            few_shot_prompt,\\n            MessagesPlaceholder(variable_name=\\\"messages\\\"),\\n            (\\\"human\\\", \\\"{input}\\\"),\\n        ]\\n    )\\n    print(final_prompt.format(input=\\\"How many products are there?\\\",table_info=\\\"some table info\\\",messages=[]))\\n    ```\\n    \\n3. **Dynamic Prompt Adaptation**: Use the chat message history to dynamically adapt the prompts sent to the model for generating SQL queries. This adaptation should include information from previous queries and responses, guiding the model in understanding the context of the follow-up question\\n    \\n    ```python\\n    generate_query = create_sql_query_chain(llm, db,final_prompt)\\n    \\n    chain = (\\n    RunnablePassthrough.assign(table_names_to_use=select_table) |\\n    RunnablePassthrough.assign(query=generate_query).assign(\\n        result=itemgetter(\\\"query\\\") | execute_query\\n    )\\n    | rephrase_answer\\n    )\\n    ```\\n    \\n\\n#### Example Scenario: Handling Follow-Up Questions\\n\\nImagine a user first asks, \\\"How many customers have an order count more than 5?\\\" After receiving the answer, they follow up with, \\\"Can you list their names?\\\" With a memory feature, the chatbot can understand that the second question relates to the subset of customers identified in response to the first question, allowing it to generate an accurate follow-up query without needing the user to re-specify the context.\\n\\n```python\\nquestion = \\\"How many cutomers with order count more than 5\\\"\\nresponse = chain.invoke({\\\"question\\\": question,\\\"messages\\\":history.messages})\\nThere are 2 customers with an order count of more than 5.\\n```\\n\\n```python\\nhistory.add_user_message(question)\\nhistory.add_ai_message(response)\\nhistory.messages\\n[HumanMessage(content='How many cutomers with order count more than 5'),\\n AIMessage(content='There are 2 customers with an order count of more than 5.')]\\n```\\n\\n```python\\nresponse = chain.invoke({\\\"question\\\": \\\"Can you list there names?\\\",\\\"messages\\\":history.messages})\\nresponse\\nThe names of the customers with more than 5 orders are Mini Gifts Distributors Ltd. and Euro+ Shopping Channel.\\n```\\n\\n## **Conclusion:**\\n\\nThrough this guide, we've journeyed through the process of enhancing NL2SQL models using LangChain, showcasing how to transform natural language queries into precise SQL commands. This exploration not only highlights the power of LangChain in making database queries more accessible but also underscores the broader impact of integrating advanced NLP techniques for intuitive data interaction.\\n\\nFor those interested in delving deeper, a [video walkthrough](https://youtu.be/fss6CrmQU2Y) and a comprehensive [GitHub notebook](https://github.com/PradipNichite/Youtube-Tutorials/blob/main/Langchain_NL2SQL_2024.ipynb) and [Streamlit Code](https://github.com/PradipNichite/Youtube-Tutorials/tree/main/Langchain%20NL2SQL%20Chatbot) are available to explore these concepts further. These resources offer visual demonstrations and hands-on examples to help bring these ideas to life in your own projects.\\n\\nThe journey toward more natural and efficient database interactions is ongoing, and with each step, we're making the world of data more accessible to all.\\n\\nIf you're curious about the latest in AI technology, I invite you to visit my project, AI Demos, at [**aidemos.com**](http://aidemos.com/)**. It's a rich resource offering a wide array of video demos showcasing the most advanced AI tools. My goal with AI Demos is to educate and illuminate the diverse possibilities of AI.**\\n\\nFor even more in-depth exploration, be sure to visit my YouTube channel at [https://www.youtube.com/@aidemos.videos](https://www.youtube.com/@aidemos.videos)**. Here, you'll find a wealth of content that delves into the exciting future of AI and its various applications.**\"},\"views\":39122,\"preferences\":{\"pinnedToBlog\":false,\"disableComments\":false,\"stickCoverToBottom\":false,\"isDelisted\":false},\"readTimeInMinutes\":14,\"series\":null,\"tags\":[{\"id\":\"63f859c05e428f179a5cf8f3\",\"slug\":\"langchain\",\"name\":\"langchain\"},{\"id\":\"63fef3fddc65a8ca9c1e0b0d\",\"slug\":\"nl2sql\",\"name\":\"NL2SQL\"},{\"id\":\"635ad52efe8087002dee4707\",\"slug\":\"llm\",\"name\":\"llm\"},{\"id\":\"642f259f311bf43ae82a8390\",\"slug\":\"text-to-sql\",\"name\":\"text to sql\"},{\"id\":\"5f1a7b4309e95d4d18c3b2ee\",\"slug\":\"openai\",\"name\":\"openai\"},{\"id\":\"638891761e50d717cbfd7b5b\",\"slug\":\"chatgpt\",\"name\":\"chatgpt\"}],\"ogMetaData\":{\"image\":null},\"canonicalUrl\":null,\"hasLatexInPost\":false,\"audioUrls\":null,\"isFollowed\":null,\"bookmarked\":false,\"features\":{\"tableOfContents\":{\"isEnabled\":true,\"items\":[{\"__typename\":\"TableOfContentsItem\",\"id\":\"6a4b64cc-4dc7-498c-babd-f79152ec0916\",\"level\":2,\"slug\":\"introduction\",\"title\":\"Introduction\",\"parentId\":null},{\"__typename\":\"TableOfContentsItem\",\"id\":\"89f6377b-515f-410a-b612-3b1926dd7e4a\",\"level\":2,\"slug\":\"building-a-basic-nl2sql-model\",\"title\":\"Building a Basic NL2SQL Model\",\"parentId\":null},{\"__typename\":\"TableOfContentsItem\",\"id\":\"bb4ff478-b5bb-4962-9895-16c826212a1b\",\"level\":4,\"slug\":\"understanding-the-basics\",\"title\":\"Understanding the Basics\",\"parentId\":\"89f6377b-515f-410a-b612-3b1926dd7e4a\"},{\"__typename\":\"TableOfContentsItem\",\"id\":\"ea22420b-75d2-492c-9394-425d5309cb14\",\"level\":4,\"slug\":\"setting-up-langchain\",\"title\":\"Setting Up LangChain\",\"parentId\":\"89f6377b-515f-410a-b612-3b1926dd7e4a\"},{\"__typename\":\"TableOfContentsItem\",\"id\":\"622473cc-a30e-490d-a5a6-055c1bb8156f\",\"level\":4,\"slug\":\"the-first-query\",\"title\":\"The First Query\",\"parentId\":\"89f6377b-515f-410a-b612-3b1926dd7e4a\"},{\"__typename\":\"TableOfContentsItem\",\"id\":\"6163595a-a60a-492a-acc2-8301e380bb3a\",\"level\":4,\"slug\":\"seeing-the-results\",\"title\":\"Seeing the Results\",\"parentId\":\"89f6377b-515f-410a-b612-3b1926dd7e4a\"},{\"__typename\":\"TableOfContentsItem\",\"id\":\"3ab1b020-4a7e-49e8-b8b9-8327280d5c38\",\"level\":4,\"slug\":\"moving-forward\",\"title\":\"Moving Forward\",\"parentId\":\"89f6377b-515f-410a-b612-3b1926dd7e4a\"},{\"__typename\":\"TableOfContentsItem\",\"id\":\"23abf3fc-5dce-4913-bd2e-6f4deefc4c80\",\"level\":2,\"slug\":\"rephrasing-answers-for-enhanced-clarity\",\"title\":\"Rephrasing Answers for Enhanced Clarity\",\"parentId\":null},{\"__typename\":\"TableOfContentsItem\",\"id\":\"2723367f-11b2-4b0b-8f80-ac78795c0455\",\"level\":4,\"slug\":\"implementing-rephrasing-with-langchain\",\"title\":\"Implementing Rephrasing with LangChain\",\"parentId\":\"23abf3fc-5dce-4913-bd2e-6f4deefc4c80\"},{\"__typename\":\"TableOfContentsItem\",\"id\":\"723b6b1a-9890-423f-9e23-39705a3d3a0b\",\"level\":4,\"slug\":\"example-transforming-sql-results-into-user-friendly-responses\",\"title\":\"Example: Transforming SQL Results into User-Friendly Responses\",\"parentId\":\"23abf3fc-5dce-4913-bd2e-6f4deefc4c80\"},{\"__typename\":\"TableOfContentsItem\",\"id\":\"6c7b4aff-61de-4eef-92f6-0d3509afb5f7\",\"level\":2,\"slug\":\"enhancing-nl2sql-models-with-few-shot-examples\",\"title\":\"Enhancing NL2SQL Models with Few-Shot Examples\",\"parentId\":null},{\"__typename\":\"TableOfContentsItem\",\"id\":\"29b8ba8c-a202-42aa-bc3a-079048290ff2\",\"level\":4,\"slug\":\"incorporating-few-shot-examples-into-langchain\",\"title\":\"Incorporating Few-Shot Examples into LangChain\",\"parentId\":\"6c7b4aff-61de-4eef-92f6-0d3509afb5f7\"},{\"__typename\":\"TableOfContentsItem\",\"id\":\"48bfcd04-66ab-4ee5-b177-1a75ad1c7e4d\",\"level\":4,\"slug\":\"the-impact-of-few-shot-learning\",\"title\":\"The Impact of Few-Shot Learning\",\"parentId\":\"6c7b4aff-61de-4eef-92f6-0d3509afb5f7\"},{\"__typename\":\"TableOfContentsItem\",\"id\":\"145d30b6-096f-405f-a44c-c86b4279f723\",\"level\":2,\"slug\":\"dynamic-few-shot-example-selection\",\"title\":\"Dynamic Few-Shot Example Selection:\",\"parentId\":null},{\"__typename\":\"TableOfContentsItem\",\"id\":\"29c4be64-f1b4-4156-abc1-41e406f9bc47\",\"level\":4,\"slug\":\"the-need-for-dynamism\",\"title\":\"The Need for Dynamism\",\"parentId\":\"145d30b6-096f-405f-a44c-c86b4279f723\"},{\"__typename\":\"TableOfContentsItem\",\"id\":\"7f2d3a9d-cdba-4667-8813-116b0f92f119\",\"level\":4,\"slug\":\"implementing-dynamic-few-shot-selection\",\"title\":\"Implementing Dynamic Few-Shot Selection\",\"parentId\":\"145d30b6-096f-405f-a44c-c86b4279f723\"},{\"__typename\":\"TableOfContentsItem\",\"id\":\"8d8fc6ef-2108-4a4f-af9f-80f72789047a\",\"level\":2,\"slug\":\"dynamic-relevant-table-selection\",\"title\":\"Dynamic Relevant Table Selection\",\"parentId\":null},{\"__typename\":\"TableOfContentsItem\",\"id\":\"6b7f41f4-1020-416a-b891-50a1373b6a91\",\"level\":4,\"slug\":\"leveraging-smaller-focused-prompts-for-faster-execution\",\"title\":\"Leveraging Smaller, Focused Prompts for Faster Execution\",\"parentId\":\"8d8fc6ef-2108-4a4f-af9f-80f72789047a\"},{\"__typename\":\"TableOfContentsItem\",\"id\":\"0039f550-0787-4861-9971-1cd12bc7f576\",\"level\":2,\"slug\":\"enhancing-chatbots-with-memory-for-follow-up-database-queries\",\"title\":\"Enhancing Chatbots with Memory for Follow-up Database Queries\",\"parentId\":null},{\"__typename\":\"TableOfContentsItem\",\"id\":\"633b8ee7-b47b-4fa2-b05b-e3ab6e26626a\",\"level\":4,\"slug\":\"the-significance-of-memory-in-chatbots\",\"title\":\"The Significance of Memory in Chatbots\",\"parentId\":\"0039f550-0787-4861-9971-1cd12bc7f576\"},{\"__typename\":\"TableOfContentsItem\",\"id\":\"c24d59b1-7af7-4601-8f48-0c67f3210e3b\",\"level\":4,\"slug\":\"implementing-memory-in-your-nl2sql-model\",\"title\":\"Implementing Memory in Your NL2SQL Model\",\"parentId\":\"0039f550-0787-4861-9971-1cd12bc7f576\"},{\"__typename\":\"TableOfContentsItem\",\"id\":\"4323aad8-b5b2-4ade-9d71-61fdcdc71b2f\",\"level\":4,\"slug\":\"example-scenario-handling-follow-up-questions\",\"title\":\"Example Scenario: Handling Follow-Up Questions\",\"parentId\":\"0039f550-0787-4861-9971-1cd12bc7f576\"},{\"__typename\":\"TableOfContentsItem\",\"id\":\"b7148ae5-6032-4ffd-bd89-102a74b799a5\",\"level\":2,\"slug\":\"conclusion\",\"title\":\"Conclusion:\",\"parentId\":null}]},\"badges\":{\"isEnabled\":true,\"items\":[]}},\"isAutoPublishedFromRSS\":false,\"authenticatedUserLikes\":{\"edges\":[]},\"totalUserLikes\":{\"totalDocuments\":17},\"isShadowBanned\":false,\"isAskMeAnything\":false},\"redirectedPost\":null,\"staticPage\":null}","totalUsersWhoLikedArticle":17,"integrations":{"fbPixelID":null,"fathomSiteID":null,"fathomCustomDomainEnabled":null,"fathomCustomDomain":null,"hotjarSiteID":null,"matomoSiteID":null,"matomoURL":null,"gaTrackingID":"G-X68KZGCNTQ","gTagManagerID":null,"plausibleAnalyticsEnabled":null,"koalaPublicKey":null,"msClarityID":null,"domainURL":"blog.futuresmart.ai"},"rootLayout":{"legacyPublicationJSON":"{\"_id\":\"6294f745136694dfeee8e80c\",\"author\":{\"_id\":\"610e6befb79d6a11366814e1\",\"name\":\"Pradip Nichite\",\"photo\":\"https://cdn.hashnode.com/res/hashnode/image/upload/v1629011734354/sgLB_1lXJ.jpeg\",\"username\":\"pnichite\"},\"badgePageEnabled\":true,\"description\":\"Learn how to build custom Natural Language Processing (NLP) solutions using state-of-the-art models. Use Pytorch, Amazon Lex, FastAPI, and Hugging Face Transformers to create powerful applications.\",\"domain\":\"blog.futuresmart.ai\",\"domainStatus\":{\"ready\":true,\"certIssued\":true},\"wwwPrefixedDomainStatus\":{},\"customCSSEnabled\":false,\"customCSSPublished\":{\"homeMin\":\"\",\"postMin\":\"\",\"staticMin\":\"\"},\"customRules\":[],\"darkModeLogo\":\"\",\"disableFooterBranding\":false,\"isSubscriptionModalDisabled\":false,\"publicMembersCount\":16,\"displayTitle\":\"Building Custom NLP Solutions using state of the art NLP models | FutureSmart AI\",\"fathomCustomDomain\":\"\",\"fathomSiteID\":\"\",\"favicon\":\"\",\"fbPixelID\":\"\",\"gaTrackingID\":\"G-X68KZGCNTQ\",\"gTagManagerID\":\"\",\"hasBadges\":true,\"headerColor\":\"#2962FF\",\"hideMembersPage\":false,\"hotjarSiteID\":\"\",\"isTeam\":true,\"layout\":\"stacked\",\"matomoURL\":\"\",\"membersPageEnabled\":true,\"menu\":[{\"_id\":\"6294fc0d1ef08fdfc9f632ba\",\"label\":\"website\",\"type\":\"link\",\"url\":\"https://www.futuresmart.ai/\"},{\"_id\":\"6358d50ff001c905d3bc60be\",\"label\":\"Youtube\",\"type\":\"link\",\"url\":\"https://www.youtube.com/c/PradipNichiteAI\"},{\"_id\":\"6358d543c1d1be05714fa376\",\"label\":\"LinkedIN\",\"type\":\"link\",\"url\":\"https://www.linkedin.com/in/pradipnichite/\"},{\"_id\":\"63ca4e7d587fc59d3cd72863\",\"label\":\"AI Demos\",\"type\":\"link\",\"url\":\"https://www.aidemos.com/\"}],\"metaHTML\":\"\u003cp\u003eFutureSmart AI provides custom Natural Language Processing (NLP) solutions.\u003c/p\u003e\\n\",\"metaHTMLSanitized\":\"FutureSmart AI provides custom Natural Language Processing (NLP) solutions.\\n\",\"newsletterEnabled\":false,\"proTeamEnabled\":false,\"newsletterPageEnabled\":true,\"ogImage\":\"\",\"logo\":\"\",\"textSelectionSharerEnabled\":true,\"title\":\"FutureSmart AI Blog\",\"urlPattern\":\"simple\",\"username\":\"pnichite-1653929794900\",\"viewCountVisible\":false,\"wmPaymentPointer\":\"\",\"readTimeHidden\":false,\"links\":{\"twitter\":\"\",\"instagram\":\"https://www.instagram.com/futuresmart.ai\",\"github\":\"\",\"website\":\"https://www.futuresmart.ai/\",\"hashnode\":\"\",\"youtube\":\"https://www.youtube.com/c/PradipNichiteAI\",\"dailydev\":\"\",\"linkedin\":\"\",\"mastodon\":\"\",\"facebook\":\"\"},\"numPosts\":105,\"sponsorship\":{\"content\":\"\",\"contentMarkdown\":\"\"},\"allowContributorEdits\":true,\"allowCrawlingByGPT\":false}","legacyPostJSON":"{\"_id\":\"65eedf3f2e25d54cd93c3d52\",\"partOfPublication\":true,\"author\":{\"_id\":\"610e6befb79d6a11366814e1\",\"name\":\"Pradip Nichite\",\"photo\":\"https://cdn.hashnode.com/res/hashnode/image/upload/v1629011734354/sgLB_1lXJ.jpeg\",\"username\":\"pnichite\",\"bio\":\"\u003cp\u003e🚀 I'm a Top Rated Plus NLP freelancer on Upwork with over $300K in earnings and a 100% Job Success rate. This journey began in 2022 after years of enriching experience in the field of Data Science.\\n📚 Starting my career in 2013 as a Software Developer focusing on backend and API development, I soon pursued my interest in Data Science by earning my M.Tech in IT from IIIT Bangalore, specializing in Data Science (2016 - 2018).\\n💼 Upon graduation, I carved out a path in the industry as a Data Scientist at MiQ (2018 - 2020) and later ascended to the role of Lead Data Scientist at Oracle (2020 - 2022).\\n🌐 Inspired by my freelancing success, I founded FutureSmart AI in September 2022. We provide custom AI solutions for clients using the latest models and techniques in NLP.\\n🎥 In addition, I run AI Demos, a platform aimed at educating people about the latest AI tools through engaging video demonstrations.\\n🧰 My technical toolbox encompasses:\\n🔧 Languages: Python, JavaScript, SQL.\\n🧪 ML Libraries: PyTorch, Transformers, LangChain.\\n🔍 Specialties: Semantic Search, Sentence Transformers, Vector Databases.\\n🖥️ Web Frameworks: FastAPI, Streamlit, Anvil.\\n☁️ Other: AWS, AWS RDS, MySQL.\\n🚀 In the fast-evolving landscape of AI, FutureSmart AI and I stand at the forefront, delivering cutting-edge, custom NLP solutions to clients across various industries.\u003c/p\u003e\\n\",\"socialMedia\":{\"website\":\"https://www.futuresmart.ai/\",\"github\":\"\",\"twitter\":\"\",\"facebook\":\"\",\"stackoverflow\":\"\",\"linkedin\":\"https://www.linkedin.com/in/pradipnichite/\"},\"isDeactivated\":false},\"bookmarkedIn\":[],\"publication\":{\"_id\":\"6294f745136694dfeee8e80c\",\"author\":{\"_id\":\"610e6befb79d6a11366814e1\",\"name\":\"Pradip Nichite\",\"photo\":\"https://cdn.hashnode.com/res/hashnode/image/upload/v1629011734354/sgLB_1lXJ.jpeg\",\"username\":\"pnichite\"},\"badgePageEnabled\":true,\"description\":\"Learn how to build custom Natural Language Processing (NLP) solutions using state-of-the-art models. Use Pytorch, Amazon Lex, FastAPI, and Hugging Face Transformers to create powerful applications.\",\"domain\":\"blog.futuresmart.ai\",\"domainStatus\":{\"ready\":true,\"certIssued\":true},\"wwwPrefixedDomainStatus\":{},\"customCSSEnabled\":false,\"customCSSPublished\":{\"homeMin\":\"\",\"postMin\":\"\",\"staticMin\":\"\"},\"customRules\":[],\"darkModeLogo\":\"\",\"disableFooterBranding\":false,\"isSubscriptionModalDisabled\":false,\"publicMembersCount\":16,\"displayTitle\":\"Building Custom NLP Solutions using state of the art NLP models | FutureSmart AI\",\"fathomCustomDomain\":\"\",\"fathomSiteID\":\"\",\"favicon\":\"\",\"fbPixelID\":\"\",\"gaTrackingID\":\"G-X68KZGCNTQ\",\"gTagManagerID\":\"\",\"hasBadges\":true,\"headerColor\":\"#2962FF\",\"hideMembersPage\":false,\"hotjarSiteID\":\"\",\"isTeam\":true,\"layout\":\"stacked\",\"matomoURL\":\"\",\"membersPageEnabled\":true,\"menu\":[{\"_id\":\"6294fc0d1ef08fdfc9f632ba\",\"label\":\"website\",\"type\":\"link\",\"url\":\"https://www.futuresmart.ai/\"},{\"_id\":\"6358d50ff001c905d3bc60be\",\"label\":\"Youtube\",\"type\":\"link\",\"url\":\"https://www.youtube.com/c/PradipNichiteAI\"},{\"_id\":\"6358d543c1d1be05714fa376\",\"label\":\"LinkedIN\",\"type\":\"link\",\"url\":\"https://www.linkedin.com/in/pradipnichite/\"},{\"_id\":\"63ca4e7d587fc59d3cd72863\",\"label\":\"AI Demos\",\"type\":\"link\",\"url\":\"https://www.aidemos.com/\"}],\"metaHTML\":\"\u003cp\u003eFutureSmart AI provides custom Natural Language Processing (NLP) solutions.\u003c/p\u003e\\n\",\"metaHTMLSanitized\":\"FutureSmart AI provides custom Natural Language Processing (NLP) solutions.\\n\",\"newsletterEnabled\":false,\"proTeamEnabled\":false,\"newsletterPageEnabled\":true,\"ogImage\":\"\",\"logo\":\"\",\"textSelectionSharerEnabled\":true,\"title\":\"FutureSmart AI Blog\",\"urlPattern\":\"simple\",\"username\":\"pnichite-1653929794900\",\"viewCountVisible\":false,\"wmPaymentPointer\":\"\",\"readTimeHidden\":false,\"links\":{\"twitter\":\"\",\"instagram\":\"https://www.instagram.com/futuresmart.ai\",\"github\":\"\",\"website\":\"https://www.futuresmart.ai/\",\"hashnode\":\"\",\"youtube\":\"https://www.youtube.com/c/PradipNichiteAI\",\"dailydev\":\"\",\"linkedin\":\"\",\"mastodon\":\"\",\"facebook\":\"\"},\"numPosts\":105,\"sponsorship\":{\"content\":\"\",\"contentMarkdown\":\"\"},\"allowContributorEdits\":true,\"allowCrawlingByGPT\":false},\"tags\":[{\"_id\":\"63f859c05e428f179a5cf8f3\",\"slug\":\"langchain\",\"name\":\"langchain\",\"isActive\":true,\"isApproved\":true},{\"_id\":\"63fef3fddc65a8ca9c1e0b0d\",\"slug\":\"nl2sql\",\"name\":\"NL2SQL\",\"isActive\":true,\"isApproved\":true},{\"_id\":\"635ad52efe8087002dee4707\",\"slug\":\"llm\",\"name\":\"llm\",\"isActive\":true,\"isApproved\":true},{\"_id\":\"642f259f311bf43ae82a8390\",\"slug\":\"text-to-sql\",\"name\":\"text to sql\",\"isActive\":true,\"isApproved\":true},{\"_id\":\"5f1a7b4309e95d4d18c3b2ee\",\"slug\":\"openai\",\"name\":\"openai\",\"isActive\":true,\"isApproved\":true},{\"_id\":\"638891761e50d717cbfd7b5b\",\"slug\":\"chatgpt\",\"name\":\"chatgpt\",\"isActive\":true,\"isApproved\":true}],\"coAuthors\":[],\"responseCount\":5,\"replyCount\":0,\"contentMarkdown\":\"## Introduction\\n\\nWelcome to our deep dive into revolutionizing the way we interact with databases using Natural Language Processing (NLP) and LangChain. In today's data-driven world, the ability to query databases without needing to know complex SQL syntax opens up a myriad of possibilities across various industries, from healthcare to finance, making data more accessible to everyone.\\n\\nThis blog post aims to guide you through a comprehensive journey to master NL2SQL using LangChain. We will explore the steps necessary to build an intuitive, efficient, and intelligent NL2SQL model that can understand and process natural language queries, dynamically select relevant database tables, and maintain a conversational context to handle follow-up questions effectively.\\n\\nBy the end of this post, you'll have a solid understanding of:\\n\\n1. **Building a Basic NL2SQL Model**: The foundation of translating natural language queries into SQL commands.\\n    \\n2. **Incorporating Few-Shot Learning**: Enhancing model accuracy with examples.\\n    \\n3. **Dynamic Few-Shot Example Selection**: Tailoring examples to the query context for improved relevance.\\n    \\n4. **Dynamic Relevant Table Selection**: Automatically identifying which tables to query based on the natural language input.\\n    \\n5. **Customizing Prompts and Responses**: Fine-tuning the model's interaction to provide clear, concise, and relevant answers.\\n    \\n6. **Adding Memory to Chatbots**: Enabling the model to handle follow-up questions by remembering the context of the conversation.\\n    \\n\\nThrough each of these steps, we'll discuss the concepts, show you how to implement them , and illustrate the outcomes , ensuring you have the tools and knowledge needed to bring the power of NL2SQL to your databases.\\n\\nLet's embark on this exciting journey to unlock the full potential of your data, making database queries as simple as conversing with a friend.\\n\\n## Building a Basic NL2SQL Model\\n\\nThe first step in our journey to revolutionize database querying with natural language is constructing a basic NL2SQL model using LangChain. This foundational model serves as the cornerstone for more advanced functionalities we'll explore later. Here's how we begin:\\n\\n#### Understanding the Basics\\n\\nAt its core, an NL2SQL model aims to translate natural language queries into SQL commands. But how do we start building such a model with LangChain?\\n\\n#### Setting Up LangChain\\n\\nLangChain simplifies the process of creating NL2SQL models by providing a flexible framework that integrates seamlessly with existing databases and natural language processing (NLP) models. To get started, you'll need to:\\n\\n1. **Install LangChain**: Ensure that LangChain is installed in your environment.\\n    \\n    ```bash\\n    pip install langchain_openai langchain_community langchain pymysql chromadb -q\\n    ```\\n    \\n2. **Connect to Your Database**: The next step involves establishing a connection to your database. LangChain supports various database systems, so you'll likely find your database among the supported ones. You'll use the database credentials to create a connection that LangChain can use to interact with your data\\n    \\n    ```python\\n    import os\\n    os.environ[\\\"OPENAI_API_KEY\\\"] = \\\"\\\"\\n    \\n    db_user = \\\"\\\"\\n    db_password = \\\"\\\"\\n    db_host = \\\"\\\"\\n    db_name = \\\"classicmodels\\\"\\n    from langchain_community.utilities.sql_database import SQLDatabase\\n    # db = SQLDatabase.from_uri(f\\\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\\\",sample_rows_in_table_info=1,include_tables=['customers','orders'],custom_table_info={'customers':\\\"customer\\\"})\\n    db = SQLDatabase.from_uri(f\\\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\\\")\\n    print(db.dialect)\\n    print(db.get_usable_table_names())\\n    print(db.table_info)\\n    ```\\n    \\n\\n#### The First Query\\n\\nOnce the setup is complete, the real magic begins. You can start by formulating a simple query in natural language, such as \\\"Show me all products priced above $100.\\\" LangChain takes this input and, through its integration with language models like ChatGPT and your database, generates an SQL query that precisely captures the intent of your request\\n\\n```python\\nfrom langchain.chains import create_sql_query_chain\\nfrom langchain_openai import ChatOpenAI\\n\\nllm = ChatOpenAI(model=\\\"gpt-3.5-turbo\\\", temperature=0)\\ngenerate_query = create_sql_query_chain(llm, db)\\nquery = generate_query.invoke({\\\"question\\\": \\\"what is price of `1968 Ford Mustang`\\\"})\\n# \\\"what is price of `1968 Ford Mustang`\\\"\\nprint(query)\\n```\\n\\n#### Seeing the Results\\n\\nExecuting the generated SQL query against your database retrieves the data you're looking for, which LangChain can then present in a user-friendly format.\\n\\n```python\\nfrom langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\\nexecute_query = QuerySQLDataBaseTool(db=db)\\nexecute_query.invoke(query)\\n```\\n\\n#### Moving Forward\\n\\nWith the basic NL2SQL model set up, you've taken the first step towards transforming how we interact with databases. However, this is just the beginning. As we progress, we'll explore how to enhance the model's accuracy, handle more complex queries, and even maintain context over a conversation for follow-up questions.\\n\\n## Rephrasing Answers for Enhanced Clarity\\n\\nAfter your NL2SQL model successfully executes a SQL query, the next pivotal step is to present the data in a manner that's easily understandable by your users. This is where the art of rephrasing SQL results into clear, natural language answers comes into play. Here's how you can achieve this with LangChain:\\n\\n#### Implementing Rephrasing with LangChain\\n\\n1. **Use Prompt Templates**: LangChain allows you to create prompt templates that can guide the model in how to rephrase SQL results. These templates can include placeholders for the original question, the SQL query, and the query result, setting the stage for generating a natural language response\\n    \\n    ```python\\n    from operator import itemgetter\\n    \\n    from langchain_core.output_parsers import StrOutputParser\\n    from langchain_core.prompts import PromptTemplate\\n    from langchain_core.runnables import RunnablePassthrough\\n    \\n    answer_prompt = PromptTemplate.from_template(\\n        \\\"\\\"\\\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\\n    \\n    Question: {question}\\n    SQL Query: {query}\\n    SQL Result: {result}\\n    Answer: \\\"\\\"\\\"\\n    )\\n    \\n    rephrase_answer = answer_prompt | llm | StrOutputParser()\\n    \\n    chain = (\\n        RunnablePassthrough.assign(query=generate_query).assign(\\n            result=itemgetter(\\\"query\\\") | execute_query\\n        )\\n        | rephrase_answer\\n    )\\n    \\n    chain.invoke({\\\"question\\\": \\\"How many customers have an order count greater than 5\\\"})\\n    ```\\n    \\n\\n#### Example: Transforming SQL Results into User-Friendly Responses\\n\\nLet's consider a user asks, \\\"How many customers have an order count greater than 5?\\\" and the SQL query returns a raw numerical result. The rephrasing process would convert this into a more readable answer, such as \\\"There are 2 customers with an order count of more than 5.\\\" This step is vital in closing the loop between user queries and database responses, ensuring that the information provided is both useful and easily digestible\\n\\n```plaintext\\nThere are 2 customers with an order count of more than 5.\\n```\\n\\nIn the next section, we'll dive into the exciting world of few-shot learning and how it can be used to improve the performance of your NL2SQL model with LangChain. Stay tuned to unlock the full potential of natural language database querying.\\n\\n## Enhancing NL2SQL Models with Few-Shot Examples\\n\\nThis technique involves providing the model with a small set of carefully selected examples that demonstrate how to convert natural language questions into SQL queries. Few-shot learning can significantly improve the model's ability to understand and generate precise SQL commands based on user queries, bridging the gap between human language and database querying.\\n\\n#### Incorporating Few-Shot Examples into LangChain\\n\\n1. **Selecting Relevant Examples**: The first step is to curate a set of examples that cover a broad range of query types and complexities. These examples should ideally reflect the most common or critical queries your users might perform\\n    \\n    ```plaintext\\n    examples = [\\n        {\\n            \\\"input\\\": \\\"List all customers in France with a credit limit over 20,000.\\\",\\n            \\\"query\\\": \\\"SELECT * FROM customers WHERE country = 'France' AND creditLimit \u003e 20000;\\\"\\n        },\\n        {\\n            \\\"input\\\": \\\"Get the highest payment amount made by any customer.\\\",\\n            \\\"query\\\": \\\"SELECT MAX(amount) FROM payments;\\\"\\n        },\\n       .....\\n    ]\\n    ```\\n    \\n2. **Creating a Few-Shot Learning Template**: With LangChain, you can design a prompt template that incorporates these examples into the model's workflow. The template instructs the model to consider the examples when generating SQL queries from new user questions\\n    \\n    ```python\\n    from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder,FewShotChatMessagePromptTemplate,PromptTemplate\\n    \\n    example_prompt = ChatPromptTemplate.from_messages(\\n        [\\n            (\\\"human\\\", \\\"{input}\\\\nSQLQuery:\\\"),\\n            (\\\"ai\\\", \\\"{query}\\\"),\\n        ]\\n    )\\n    few_shot_prompt = FewShotChatMessagePromptTemplate(\\n        example_prompt=example_prompt,\\n        examples=examples,\\n        # input_variables=[\\\"input\\\",\\\"top_k\\\"],\\n        input_variables=[\\\"input\\\"],\\n    )\\n    print(few_shot_prompt.format(input1=\\\"How many products are there?\\\"))\\n    ```\\n    \\n    ```plaintext\\n    Human: List all customers in France with a credit limit over 20,000.\\n    SQLQuery:\\n    AI: SELECT * FROM customers WHERE country = 'France' AND creditLimit \u003e 20000;\\n    Human: Get the highest payment amount made by any customer.\\n    SQLQuery:\\n    AI: SELECT MAX(amount) FROM payments;\\n    ......\\n    ```\\n    \\n\\n#### The Impact of Few-Shot Learning\\n\\nBy integrating few-shot examples, your NL2SQL model becomes more adept at handling a wider variety of user queries. This not only improves the user experience by providing more accurate and relevant responses but also reduces the potential for errors in SQL query generation.\\n\\nIn the next section, we'll explore the integration of dynamic example selection to further enhance the model's accuracy and relevance, ensuring that your NL2SQL system remains adaptive and responsive to user queries.\\n\\n## Dynamic Few-Shot Example Selection:\\n\\nThis advanced technique tailors the few-shot examples provided to the model based on the specific context of the user's query. It ensures that the guidance offered to the model is not just relevant but optimally aligned with the query's nuances, significantly boosting the model's ability to generate accurate SQL queries.\\n\\n#### The Need for Dynamism\\n\\nStatic few-shot examples, though highly effective, have their limitations. Dynamic selection addresses this by intelligently choosing examples that closely match the intent and context of each new query, providing a customized learning experience for the model with every interaction.\\n\\n#### Implementing Dynamic Few-Shot Selection\\n\\n1. **Example Selector Configuration**: Begin by setting up an example selector that can analyze the semantics of the user's query and compare it with a repository of potential examples. Tools like semantic similarity algorithms and vector embeddings come into play here, identifying which examples are most relevant to the current query\\n    \\n    ```python\\n    from langchain_community.vectorstores import Chroma\\n    from langchain_core.example_selectors import SemanticSimilarityExampleSelector\\n    from langchain_openai import OpenAIEmbeddings\\n    \\n    vectorstore = Chroma()\\n    vectorstore.delete_collection()\\n    example_selector = SemanticSimilarityExampleSelector.from_examples(\\n        examples,\\n        OpenAIEmbeddings(),\\n        vectorstore,\\n        k=2,\\n        input_keys=[\\\"input\\\"],\\n    )\\n    example_selector.select_examples({\\\"input\\\": \\\"how many employees we have?\\\"})\\n    few_shot_prompt = FewShotChatMessagePromptTemplate(\\n        example_prompt=example_prompt,\\n        example_selector=example_selector,\\n        input_variables=[\\\"input\\\",\\\"top_k\\\"],\\n    )\\n    print(few_shot_prompt.format(input=\\\"How many products are there?\\\"))\\n    ```\\n    \\n2. **Integrating with LangChain**: Integrate the example selector with your LangChain workflow. When a new query is received, the selector determines the most relevant few-shot examples before the model generates the SQL query. This ensures that the guidance provided to the model is tailored to the specific requirements of the query\\n    \\n    ```python\\n    final_prompt = ChatPromptTemplate.from_messages(\\n        [\\n            (\\\"system\\\", \\\"You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run. Unless otherwise specificed.\\\\n\\\\nHere is the relevant table info: {table_info}\\\\n\\\\nBelow are a number of examples of questions and their corresponding SQL queries.\\\"),\\n            few_shot_prompt,\\n            (\\\"human\\\", \\\"{input}\\\"),\\n        ]\\n    )\\n    print(final_prompt.format(input=\\\"How many products are there?\\\",table_info=\\\"some table info\\\"))\\n    generate_query = create_sql_query_chain(llm, db,final_prompt)\\n    chain = (\\n    RunnablePassthrough.assign(query=generate_query).assign(\\n        result=itemgetter(\\\"query\\\") | execute_query\\n    )\\n    | rephrase_answer\\n    )\\n    chain.invoke({\\\"question\\\": \\\"How many csutomers with credit limit more than 50000\\\"})\\n    ```\\n    \\n    ```plaintext\\n    There are 85 customers with a credit limit greater than 50000.\\n    ```\\n    \\n\\nBy ensuring that the examples used for guidance are always contextually relevant, the model can generate more precise SQL queries, reducing errors and improving user satisfaction. of NL2SQL technology, making data insights more accessible to everyone.\\n\\nIn the following section, we will explore the integration of dynamic relevant table selection, further advancing our NL2SQL model's capabilities to efficiently parse and respond to user queries.\\n\\n## Dynamic Relevant Table Selection\\n\\nIn the realm of NL2SQL models, especially when dealing with complex databases featuring 100+ tables. With databases growing in complexity and size, it's impractical and costly in terms of prompt token usage to include the schema of every table in the initial prompt for generating SQL queries. The sheer volume of information would overwhelm the model, leading to slower response times and increased computational costs. Dynamic relevant table selection emerges as a solution to this challenge, focusing the model's attention only on the tables pertinent to the user's query.\\n\\n```python\\nfrom operator import itemgetter\\nfrom langchain.chains.openai_tools import create_extraction_chain_pydantic\\nfrom langchain_core.pydantic_v1 import BaseModel, Field\\nfrom typing import List\\nimport pandas as pd\\n\\ndef get_table_details():\\n    # Read the CSV file into a DataFrame\\n    table_description = pd.read_csv(\\\"database_table_descriptions.csv\\\")\\n    table_docs = []\\n\\n    # Iterate over the DataFrame rows to create Document objects\\n    table_details = \\\"\\\"\\n    for index, row in table_description.iterrows():\\n        table_details = table_details + \\\"Table Name:\\\" + row['Table'] + \\\"\\\\n\\\" + \\\"Table Description:\\\" + row['Description'] + \\\"\\\\n\\\\n\\\"\\n\\n    return table_details\\n\\n\\nclass Table(BaseModel):\\n    \\\"\\\"\\\"Table in SQL database.\\\"\\\"\\\"\\n\\n    name: str = Field(description=\\\"Name of table in SQL database.\\\")\\n\\n# table_names = \\\"\\\\n\\\".join(db.get_usable_table_names())\\ntable_details = get_table_details()\\nprint(table_details)\\n```\\n\\n```plaintext\\nTable Name:productlines\\nTable Description:Stores information about the differ....\\n\\nTable Name:products\\nTable Description:Contains de....\\n```\\n\\n#### Leveraging Smaller, Focused Prompts for Faster Execution\\n\\nDynamic relevant table selection hinges on the principle that \\\"less is more.\\\" By reducing the scope of information the model needs to consider for each query:\\n\\n1. **Improved Model Performance**: Smaller prompts mean the model has fewer tokens to process, which translates to faster execution times. This is particularly crucial for interactive applications where response time is a key component of user satisfaction.\\n    \\n2. **Enhanced Accuracy**: Focusing on only the relevant tables minimizes the risk of generating incorrect SQL queries. This specificity ensures that the model's computational resources are dedicated to understanding and processing only the most pertinent data.\\n    \\n3. **Cost-Efficiency**: Reducing the amount of prompt information also means fewer token usage costs. In the context of cloud-based NLP services, where processing costs can accumulate rapidly, this efficiency is not only a technical but also a financial advantage.\\n    \\n\\n```python\\ntable_details_prompt = f\\\"\\\"\\\"Return the names of ALL the SQL tables that MIGHT be relevant to the user question. \\\\\\nThe tables are:\\n\\n{table_details}\\n\\nRemember to include ALL POTENTIALLY RELEVANT tables, even if you're not sure that they're needed.\\\"\\\"\\\"\\n\\ntable_chain = create_extraction_chain_pydantic(Table, llm, system_message=table_details_prompt)\\ntables = table_chain.invoke({\\\"input\\\": \\\"give me details of customer and their order count\\\"})\\ntables\\n```\\n\\n```plaintext\\n[Table(name='customers'), Table(name='orders')]\\n```\\n\\n```python\\ndef get_tables(tables: List[Table]) -\u003e List[str]:\\n    tables  = [table.name for table in tables]\\n    return tables\\n\\nselect_table = {\\\"input\\\": itemgetter(\\\"question\\\")} | create_extraction_chain_pydantic(Table, llm, system_message=table_details_prompt) | get_tables\\nselect_table.invoke({\\\"question\\\": \\\"give me details of customer and their order count\\\"})\\n```\\n\\n```plaintext\\n['customers', 'orders']\\n```\\n\\n```python\\nchain = (\\nRunnablePassthrough.assign(table_names_to_use=select_table) |\\nRunnablePassthrough.assign(query=generate_query).assign(\\n    result=itemgetter(\\\"query\\\") | execute_query\\n)\\n| rephrase_answer\\n)\\nchain.invoke({\\\"question\\\": \\\"How many cutomers with order count more than 5\\\"})\\n```\\n\\n## Enhancing Chatbots with Memory for Follow-up Database Queries\\n\\nOne of the most advanced steps in creating a user-friendly NL2SQL interface is endowing your chatbot with memory. This feature enables the chatbot to handle follow-up questions related to the database intelligently, providing users with a seamless conversational experience. Let's explore how adding memory to your chatbot can revolutionize interactions with your database.\\n\\n#### The Significance of Memory in Chatbots\\n\\nIn real-world conversations, context matters. A question might relate to or build upon previous interactions. Similarly, when users interact with a database through a chatbot, their follow-up questions often depend on the context established by earlier queries and responses. A chatbot equipped with memory can retain this context, allowing it to generate more accurate and relevant SQL queries for follow-up questions.\\n\\n#### Implementing Memory in Your NL2SQL Model\\n\\nTo equip your NL2SQL model with memory, consider incorporating a chat message history that tracks the conversation's flow. This history should include both the questions posed by the user and the chatbot's responses, enabling the model to reference previous interactions when generating SQL queries for new questions.\\n\\n1. **Setting Up Message History**: Implement a mechanism to record each user query and the corresponding chatbot response. This can be achieved by defining a `ChatMessageHistory` object that stores this information and can be accessed when needed\\n    \\n    ```python\\n    from langchain.memory import ChatMessageHistory\\n    history = ChatMessageHistory()\\n    ```\\n    \\n2. **Leveraging Previous Interactions**: Integrate this message history into your prompt generation process. Before generating a new SQL query, the model should consider the recorded history to understand the conversation's context\\n    \\n    ```python\\n    final_prompt = ChatPromptTemplate.from_messages(\\n        [\\n            (\\\"system\\\", \\\"You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run. Unless otherwise specificed.\\\\n\\\\nHere is the relevant table info: {table_info}\\\\n\\\\nBelow are a number of examples of questions and their corresponding SQL queries. Those examples are just for referecne and hsould be considered while answering follow up questions\\\"),\\n            few_shot_prompt,\\n            MessagesPlaceholder(variable_name=\\\"messages\\\"),\\n            (\\\"human\\\", \\\"{input}\\\"),\\n        ]\\n    )\\n    print(final_prompt.format(input=\\\"How many products are there?\\\",table_info=\\\"some table info\\\",messages=[]))\\n    ```\\n    \\n3. **Dynamic Prompt Adaptation**: Use the chat message history to dynamically adapt the prompts sent to the model for generating SQL queries. This adaptation should include information from previous queries and responses, guiding the model in understanding the context of the follow-up question\\n    \\n    ```python\\n    generate_query = create_sql_query_chain(llm, db,final_prompt)\\n    \\n    chain = (\\n    RunnablePassthrough.assign(table_names_to_use=select_table) |\\n    RunnablePassthrough.assign(query=generate_query).assign(\\n        result=itemgetter(\\\"query\\\") | execute_query\\n    )\\n    | rephrase_answer\\n    )\\n    ```\\n    \\n\\n#### Example Scenario: Handling Follow-Up Questions\\n\\nImagine a user first asks, \\\"How many customers have an order count more than 5?\\\" After receiving the answer, they follow up with, \\\"Can you list their names?\\\" With a memory feature, the chatbot can understand that the second question relates to the subset of customers identified in response to the first question, allowing it to generate an accurate follow-up query without needing the user to re-specify the context.\\n\\n```python\\nquestion = \\\"How many cutomers with order count more than 5\\\"\\nresponse = chain.invoke({\\\"question\\\": question,\\\"messages\\\":history.messages})\\nThere are 2 customers with an order count of more than 5.\\n```\\n\\n```python\\nhistory.add_user_message(question)\\nhistory.add_ai_message(response)\\nhistory.messages\\n[HumanMessage(content='How many cutomers with order count more than 5'),\\n AIMessage(content='There are 2 customers with an order count of more than 5.')]\\n```\\n\\n```python\\nresponse = chain.invoke({\\\"question\\\": \\\"Can you list there names?\\\",\\\"messages\\\":history.messages})\\nresponse\\nThe names of the customers with more than 5 orders are Mini Gifts Distributors Ltd. and Euro+ Shopping Channel.\\n```\\n\\n## **Conclusion:**\\n\\nThrough this guide, we've journeyed through the process of enhancing NL2SQL models using LangChain, showcasing how to transform natural language queries into precise SQL commands. This exploration not only highlights the power of LangChain in making database queries more accessible but also underscores the broader impact of integrating advanced NLP techniques for intuitive data interaction.\\n\\nFor those interested in delving deeper, a [video walkthrough](https://youtu.be/fss6CrmQU2Y) and a comprehensive [GitHub notebook](https://github.com/PradipNichite/Youtube-Tutorials/blob/main/Langchain_NL2SQL_2024.ipynb) and [Streamlit Code](https://github.com/PradipNichite/Youtube-Tutorials/tree/main/Langchain%20NL2SQL%20Chatbot) are available to explore these concepts further. These resources offer visual demonstrations and hands-on examples to help bring these ideas to life in your own projects.\\n\\nThe journey toward more natural and efficient database interactions is ongoing, and with each step, we're making the world of data more accessible to all.\\n\\nIf you're curious about the latest in AI technology, I invite you to visit my project, AI Demos, at [**aidemos.com**](http://aidemos.com/)**. It's a rich resource offering a wide array of video demos showcasing the most advanced AI tools. My goal with AI Demos is to educate and illuminate the diverse possibilities of AI.**\\n\\nFor even more in-depth exploration, be sure to visit my YouTube channel at [https://www.youtube.com/@aidemos.videos](https://www.youtube.com/@aidemos.videos)**. Here, you'll find a wealth of content that delves into the exciting future of AI and its various applications.**\",\"content\":\"\u003ch2 id=\\\"heading-introduction\\\"\u003eIntroduction\u003c/h2\u003e\\n\u003cp\u003eWelcome to our deep dive into revolutionizing the way we interact with databases using Natural Language Processing (NLP) and LangChain. In today's data-driven world, the ability to query databases without needing to know complex SQL syntax opens up a myriad of possibilities across various industries, from healthcare to finance, making data more accessible to everyone.\u003c/p\u003e\\n\u003cp\u003eThis blog post aims to guide you through a comprehensive journey to master NL2SQL using LangChain. We will explore the steps necessary to build an intuitive, efficient, and intelligent NL2SQL model that can understand and process natural language queries, dynamically select relevant database tables, and maintain a conversational context to handle follow-up questions effectively.\u003c/p\u003e\\n\u003cp\u003eBy the end of this post, you'll have a solid understanding of:\u003c/p\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eBuilding a Basic NL2SQL Model\u003c/strong\u003e: The foundation of translating natural language queries into SQL commands.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eIncorporating Few-Shot Learning\u003c/strong\u003e: Enhancing model accuracy with examples.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eDynamic Few-Shot Example Selection\u003c/strong\u003e: Tailoring examples to the query context for improved relevance.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eDynamic Relevant Table Selection\u003c/strong\u003e: Automatically identifying which tables to query based on the natural language input.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eCustomizing Prompts and Responses\u003c/strong\u003e: Fine-tuning the model's interaction to provide clear, concise, and relevant answers.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eAdding Memory to Chatbots\u003c/strong\u003e: Enabling the model to handle follow-up questions by remembering the context of the conversation.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003cp\u003eThrough each of these steps, we'll discuss the concepts, show you how to implement them , and illustrate the outcomes , ensuring you have the tools and knowledge needed to bring the power of NL2SQL to your databases.\u003c/p\u003e\\n\u003cp\u003eLet's embark on this exciting journey to unlock the full potential of your data, making database queries as simple as conversing with a friend.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-building-a-basic-nl2sql-model\\\"\u003eBuilding a Basic NL2SQL Model\u003c/h2\u003e\\n\u003cp\u003eThe first step in our journey to revolutionize database querying with natural language is constructing a basic NL2SQL model using LangChain. This foundational model serves as the cornerstone for more advanced functionalities we'll explore later. Here's how we begin:\u003c/p\u003e\\n\u003ch4 id=\\\"heading-understanding-the-basics\\\"\u003eUnderstanding the Basics\u003c/h4\u003e\\n\u003cp\u003eAt its core, an NL2SQL model aims to translate natural language queries into SQL commands. But how do we start building such a model with LangChain?\u003c/p\u003e\\n\u003ch4 id=\\\"heading-setting-up-langchain\\\"\u003eSetting Up LangChain\u003c/h4\u003e\\n\u003cp\u003eLangChain simplifies the process of creating NL2SQL models by providing a flexible framework that integrates seamlessly with existing databases and natural language processing (NLP) models. To get started, you'll need to:\u003c/p\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eInstall LangChain\u003c/strong\u003e: Ensure that LangChain is installed in your environment.\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-bash\\\"\u003e pip install langchain_openai langchain_community langchain pymysql chromadb -q\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eConnect to Your Database\u003c/strong\u003e: The next step involves establishing a connection to your database. LangChain supports various database systems, so you'll likely find your database among the supported ones. You'll use the database credentials to create a connection that LangChain can use to interact with your data\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e os\\n os.environ[\u003cspan class=\\\"hljs-string\\\"\u003e\\\"OPENAI_API_KEY\\\"\u003c/span\u003e] = \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\u003c/span\u003e\\n\\n db_user = \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\u003c/span\u003e\\n db_password = \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\u003c/span\u003e\\n db_host = \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\u003c/span\u003e\\n db_name = \u003cspan class=\\\"hljs-string\\\"\u003e\\\"classicmodels\\\"\u003c/span\u003e\\n \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_community.utilities.sql_database \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e SQLDatabase\\n \u003cspan class=\\\"hljs-comment\\\"\u003e# db = SQLDatabase.from_uri(f\\\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\\\",sample_rows_in_table_info=1,include_tables=['customers','orders'],custom_table_info={'customers':\\\"customer\\\"})\u003c/span\u003e\\n db = SQLDatabase.from_uri(\u003cspan class=\\\"hljs-string\\\"\u003ef\\\"mysql+pymysql://\u003cspan class=\\\"hljs-subst\\\"\u003e{db_user}\u003c/span\u003e:\u003cspan class=\\\"hljs-subst\\\"\u003e{db_password}\u003c/span\u003e@\u003cspan class=\\\"hljs-subst\\\"\u003e{db_host}\u003c/span\u003e/\u003cspan class=\\\"hljs-subst\\\"\u003e{db_name}\u003c/span\u003e\\\"\u003c/span\u003e)\\n print(db.dialect)\\n print(db.get_usable_table_names())\\n print(db.table_info)\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003ch4 id=\\\"heading-the-first-query\\\"\u003eThe First Query\u003c/h4\u003e\\n\u003cp\u003eOnce the setup is complete, the real magic begins. You can start by formulating a simple query in natural language, such as \\\"Show me all products priced above $100.\\\" LangChain takes this input and, through its integration with language models like ChatGPT and your database, generates an SQL query that precisely captures the intent of your request\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain.chains \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e create_sql_query_chain\\n\u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_openai \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e ChatOpenAI\\n\\nllm = ChatOpenAI(model=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"gpt-3.5-turbo\\\"\u003c/span\u003e, temperature=\u003cspan class=\\\"hljs-number\\\"\u003e0\u003c/span\u003e)\\ngenerate_query = create_sql_query_chain(llm, db)\\nquery = generate_query.invoke({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"question\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"what is price of `1968 Ford Mustang`\\\"\u003c/span\u003e})\\n\u003cspan class=\\\"hljs-comment\\\"\u003e# \\\"what is price of `1968 Ford Mustang`\\\"\u003c/span\u003e\\nprint(query)\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch4 id=\\\"heading-seeing-the-results\\\"\u003eSeeing the Results\u003c/h4\u003e\\n\u003cp\u003eExecuting the generated SQL query against your database retrieves the data you're looking for, which LangChain can then present in a user-friendly format.\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_community.tools.sql_database.tool \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e QuerySQLDataBaseTool\\nexecute_query = QuerySQLDataBaseTool(db=db)\\nexecute_query.invoke(query)\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch4 id=\\\"heading-moving-forward\\\"\u003eMoving Forward\u003c/h4\u003e\\n\u003cp\u003eWith the basic NL2SQL model set up, you've taken the first step towards transforming how we interact with databases. However, this is just the beginning. As we progress, we'll explore how to enhance the model's accuracy, handle more complex queries, and even maintain context over a conversation for follow-up questions.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-rephrasing-answers-for-enhanced-clarity\\\"\u003eRephrasing Answers for Enhanced Clarity\u003c/h2\u003e\\n\u003cp\u003eAfter your NL2SQL model successfully executes a SQL query, the next pivotal step is to present the data in a manner that's easily understandable by your users. This is where the art of rephrasing SQL results into clear, natural language answers comes into play. Here's how you can achieve this with LangChain:\u003c/p\u003e\\n\u003ch4 id=\\\"heading-implementing-rephrasing-with-langchain\\\"\u003eImplementing Rephrasing with LangChain\u003c/h4\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eUse Prompt Templates\u003c/strong\u003e: LangChain allows you to create prompt templates that can guide the model in how to rephrase SQL results. These templates can include placeholders for the original question, the SQL query, and the query result, setting the stage for generating a natural language response\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e operator \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e itemgetter\\n\\n \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_core.output_parsers \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e StrOutputParser\\n \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_core.prompts \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e PromptTemplate\\n \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_core.runnables \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e RunnablePassthrough\\n\\n answer_prompt = PromptTemplate.from_template(\\n     \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\\\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\\n\\n Question: {question}\\n SQL Query: {query}\\n SQL Result: {result}\\n Answer: \\\"\\\"\\\"\u003c/span\u003e\\n )\\n\\n rephrase_answer = answer_prompt | llm | StrOutputParser()\\n\\n chain = (\\n     RunnablePassthrough.assign(query=generate_query).assign(\\n         result=itemgetter(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"query\\\"\u003c/span\u003e) | execute_query\\n     )\\n     | rephrase_answer\\n )\\n\\n chain.invoke({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"question\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"How many customers have an order count greater than 5\\\"\u003c/span\u003e})\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003ch4 id=\\\"heading-example-transforming-sql-results-into-user-friendly-responses\\\"\u003eExample: Transforming SQL Results into User-Friendly Responses\u003c/h4\u003e\\n\u003cp\u003eLet's consider a user asks, \\\"How many customers have an order count greater than 5?\\\" and the SQL query returns a raw numerical result. The rephrasing process would convert this into a more readable answer, such as \\\"There are 2 customers with an order count of more than 5.\\\" This step is vital in closing the loop between user queries and database responses, ensuring that the information provided is both useful and easily digestible\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-plaintext\\\"\u003eThere are 2 customers with an order count of more than 5.\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cp\u003eIn the next section, we'll dive into the exciting world of few-shot learning and how it can be used to improve the performance of your NL2SQL model with LangChain. Stay tuned to unlock the full potential of natural language database querying.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-enhancing-nl2sql-models-with-few-shot-examples\\\"\u003eEnhancing NL2SQL Models with Few-Shot Examples\u003c/h2\u003e\\n\u003cp\u003eThis technique involves providing the model with a small set of carefully selected examples that demonstrate how to convert natural language questions into SQL queries. Few-shot learning can significantly improve the model's ability to understand and generate precise SQL commands based on user queries, bridging the gap between human language and database querying.\u003c/p\u003e\\n\u003ch4 id=\\\"heading-incorporating-few-shot-examples-into-langchain\\\"\u003eIncorporating Few-Shot Examples into LangChain\u003c/h4\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eSelecting Relevant Examples\u003c/strong\u003e: The first step is to curate a set of examples that cover a broad range of query types and complexities. These examples should ideally reflect the most common or critical queries your users might perform\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-plaintext\\\"\u003e examples = [\\n     {\\n         \\\"input\\\": \\\"List all customers in France with a credit limit over 20,000.\\\",\\n         \\\"query\\\": \\\"SELECT * FROM customers WHERE country = 'France' AND creditLimit \u0026gt; 20000;\\\"\\n     },\\n     {\\n         \\\"input\\\": \\\"Get the highest payment amount made by any customer.\\\",\\n         \\\"query\\\": \\\"SELECT MAX(amount) FROM payments;\\\"\\n     },\\n    .....\\n ]\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eCreating a Few-Shot Learning Template\u003c/strong\u003e: With LangChain, you can design a prompt template that incorporates these examples into the model's workflow. The template instructs the model to consider the examples when generating SQL queries from new user questions\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_core.prompts \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e ChatPromptTemplate, MessagesPlaceholder,FewShotChatMessagePromptTemplate,PromptTemplate\\n\\n example_prompt = ChatPromptTemplate.from_messages(\\n     [\\n         (\u003cspan class=\\\"hljs-string\\\"\u003e\\\"human\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"{input}\\\\nSQLQuery:\\\"\u003c/span\u003e),\\n         (\u003cspan class=\\\"hljs-string\\\"\u003e\\\"ai\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"{query}\\\"\u003c/span\u003e),\\n     ]\\n )\\n few_shot_prompt = FewShotChatMessagePromptTemplate(\\n     example_prompt=example_prompt,\\n     examples=examples,\\n     \u003cspan class=\\\"hljs-comment\\\"\u003e# input_variables=[\\\"input\\\",\\\"top_k\\\"],\u003c/span\u003e\\n     input_variables=[\u003cspan class=\\\"hljs-string\\\"\u003e\\\"input\\\"\u003c/span\u003e],\\n )\\n print(few_shot_prompt.format(input1=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"How many products are there?\\\"\u003c/span\u003e))\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-plaintext\\\"\u003e Human: List all customers in France with a credit limit over 20,000.\\n SQLQuery:\\n AI: SELECT * FROM customers WHERE country = 'France' AND creditLimit \u0026gt; 20000;\\n Human: Get the highest payment amount made by any customer.\\n SQLQuery:\\n AI: SELECT MAX(amount) FROM payments;\\n ......\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003ch4 id=\\\"heading-the-impact-of-few-shot-learning\\\"\u003eThe Impact of Few-Shot Learning\u003c/h4\u003e\\n\u003cp\u003eBy integrating few-shot examples, your NL2SQL model becomes more adept at handling a wider variety of user queries. This not only improves the user experience by providing more accurate and relevant responses but also reduces the potential for errors in SQL query generation.\u003c/p\u003e\\n\u003cp\u003eIn the next section, we'll explore the integration of dynamic example selection to further enhance the model's accuracy and relevance, ensuring that your NL2SQL system remains adaptive and responsive to user queries.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-dynamic-few-shot-example-selection\\\"\u003eDynamic Few-Shot Example Selection:\u003c/h2\u003e\\n\u003cp\u003eThis advanced technique tailors the few-shot examples provided to the model based on the specific context of the user's query. It ensures that the guidance offered to the model is not just relevant but optimally aligned with the query's nuances, significantly boosting the model's ability to generate accurate SQL queries.\u003c/p\u003e\\n\u003ch4 id=\\\"heading-the-need-for-dynamism\\\"\u003eThe Need for Dynamism\u003c/h4\u003e\\n\u003cp\u003eStatic few-shot examples, though highly effective, have their limitations. Dynamic selection addresses this by intelligently choosing examples that closely match the intent and context of each new query, providing a customized learning experience for the model with every interaction.\u003c/p\u003e\\n\u003ch4 id=\\\"heading-implementing-dynamic-few-shot-selection\\\"\u003eImplementing Dynamic Few-Shot Selection\u003c/h4\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eExample Selector Configuration\u003c/strong\u003e: Begin by setting up an example selector that can analyze the semantics of the user's query and compare it with a repository of potential examples. Tools like semantic similarity algorithms and vector embeddings come into play here, identifying which examples are most relevant to the current query\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_community.vectorstores \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e Chroma\\n \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_core.example_selectors \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e SemanticSimilarityExampleSelector\\n \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_openai \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e OpenAIEmbeddings\\n\\n vectorstore = Chroma()\\n vectorstore.delete_collection()\\n example_selector = SemanticSimilarityExampleSelector.from_examples(\\n     examples,\\n     OpenAIEmbeddings(),\\n     vectorstore,\\n     k=\u003cspan class=\\\"hljs-number\\\"\u003e2\u003c/span\u003e,\\n     input_keys=[\u003cspan class=\\\"hljs-string\\\"\u003e\\\"input\\\"\u003c/span\u003e],\\n )\\n example_selector.select_examples({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"input\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"how many employees we have?\\\"\u003c/span\u003e})\\n few_shot_prompt = FewShotChatMessagePromptTemplate(\\n     example_prompt=example_prompt,\\n     example_selector=example_selector,\\n     input_variables=[\u003cspan class=\\\"hljs-string\\\"\u003e\\\"input\\\"\u003c/span\u003e,\u003cspan class=\\\"hljs-string\\\"\u003e\\\"top_k\\\"\u003c/span\u003e],\\n )\\n print(few_shot_prompt.format(input=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"How many products are there?\\\"\u003c/span\u003e))\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eIntegrating with LangChain\u003c/strong\u003e: Integrate the example selector with your LangChain workflow. When a new query is received, the selector determines the most relevant few-shot examples before the model generates the SQL query. This ensures that the guidance provided to the model is tailored to the specific requirements of the query\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e final_prompt = ChatPromptTemplate.from_messages(\\n     [\\n         (\u003cspan class=\\\"hljs-string\\\"\u003e\\\"system\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run. Unless otherwise specificed.\\\\n\\\\nHere is the relevant table info: {table_info}\\\\n\\\\nBelow are a number of examples of questions and their corresponding SQL queries.\\\"\u003c/span\u003e),\\n         few_shot_prompt,\\n         (\u003cspan class=\\\"hljs-string\\\"\u003e\\\"human\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"{input}\\\"\u003c/span\u003e),\\n     ]\\n )\\n print(final_prompt.format(input=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"How many products are there?\\\"\u003c/span\u003e,table_info=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"some table info\\\"\u003c/span\u003e))\\n generate_query = create_sql_query_chain(llm, db,final_prompt)\\n chain = (\\n RunnablePassthrough.assign(query=generate_query).assign(\\n     result=itemgetter(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"query\\\"\u003c/span\u003e) | execute_query\\n )\\n | rephrase_answer\\n )\\n chain.invoke({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"question\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"How many csutomers with credit limit more than 50000\\\"\u003c/span\u003e})\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-plaintext\\\"\u003e There are 85 customers with a credit limit greater than 50000.\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003cp\u003eBy ensuring that the examples used for guidance are always contextually relevant, the model can generate more precise SQL queries, reducing errors and improving user satisfaction. of NL2SQL technology, making data insights more accessible to everyone.\u003c/p\u003e\\n\u003cp\u003eIn the following section, we will explore the integration of dynamic relevant table selection, further advancing our NL2SQL model's capabilities to efficiently parse and respond to user queries.\u003c/p\u003e\\n\u003ch2 id=\\\"heading-dynamic-relevant-table-selection\\\"\u003eDynamic Relevant Table Selection\u003c/h2\u003e\\n\u003cp\u003eIn the realm of NL2SQL models, especially when dealing with complex databases featuring 100+ tables. With databases growing in complexity and size, it's impractical and costly in terms of prompt token usage to include the schema of every table in the initial prompt for generating SQL queries. The sheer volume of information would overwhelm the model, leading to slower response times and increased computational costs. Dynamic relevant table selection emerges as a solution to this challenge, focusing the model's attention only on the tables pertinent to the user's query.\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e operator \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e itemgetter\\n\u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain.chains.openai_tools \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e create_extraction_chain_pydantic\\n\u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain_core.pydantic_v1 \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e BaseModel, Field\\n\u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e typing \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e List\\n\u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e pandas \u003cspan class=\\\"hljs-keyword\\\"\u003eas\u003c/span\u003e pd\\n\\n\u003cspan class=\\\"hljs-function\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003eget_table_details\u003c/span\u003e():\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-comment\\\"\u003e# Read the CSV file into a DataFrame\u003c/span\u003e\\n    table_description = pd.read_csv(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"database_table_descriptions.csv\\\"\u003c/span\u003e)\\n    table_docs = []\\n\\n    \u003cspan class=\\\"hljs-comment\\\"\u003e# Iterate over the DataFrame rows to create Document objects\u003c/span\u003e\\n    table_details = \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003efor\u003c/span\u003e index, row \u003cspan class=\\\"hljs-keyword\\\"\u003ein\u003c/span\u003e table_description.iterrows():\\n        table_details = table_details + \u003cspan class=\\\"hljs-string\\\"\u003e\\\"Table Name:\\\"\u003c/span\u003e + row[\u003cspan class=\\\"hljs-string\\\"\u003e'Table'\u003c/span\u003e] + \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\\n\\\"\u003c/span\u003e + \u003cspan class=\\\"hljs-string\\\"\u003e\\\"Table Description:\\\"\u003c/span\u003e + row[\u003cspan class=\\\"hljs-string\\\"\u003e'Description'\u003c/span\u003e] + \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\\n\\\\n\\\"\u003c/span\u003e\\n\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e table_details\\n\\n\\n\u003cspan class=\\\"hljs-class\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003eclass\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003eTable\u003c/span\u003e(\u003cspan class=\\\"hljs-params\\\"\u003eBaseModel\u003c/span\u003e):\u003c/span\u003e\\n    \u003cspan class=\\\"hljs-string\\\"\u003e\\\"\\\"\\\"Table in SQL database.\\\"\\\"\\\"\u003c/span\u003e\\n\\n    name: str = Field(description=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"Name of table in SQL database.\\\"\u003c/span\u003e)\\n\\n\u003cspan class=\\\"hljs-comment\\\"\u003e# table_names = \\\"\\\\n\\\".join(db.get_usable_table_names())\u003c/span\u003e\\ntable_details = get_table_details()\\nprint(table_details)\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-plaintext\\\"\u003eTable Name:productlines\\nTable Description:Stores information about the differ....\\n\\nTable Name:products\\nTable Description:Contains de....\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch4 id=\\\"heading-leveraging-smaller-focused-prompts-for-faster-execution\\\"\u003eLeveraging Smaller, Focused Prompts for Faster Execution\u003c/h4\u003e\\n\u003cp\u003eDynamic relevant table selection hinges on the principle that \\\"less is more.\\\" By reducing the scope of information the model needs to consider for each query:\u003c/p\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eImproved Model Performance\u003c/strong\u003e: Smaller prompts mean the model has fewer tokens to process, which translates to faster execution times. This is particularly crucial for interactive applications where response time is a key component of user satisfaction.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eEnhanced Accuracy\u003c/strong\u003e: Focusing on only the relevant tables minimizes the risk of generating incorrect SQL queries. This specificity ensures that the model's computational resources are dedicated to understanding and processing only the most pertinent data.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eCost-Efficiency\u003c/strong\u003e: Reducing the amount of prompt information also means fewer token usage costs. In the context of cloud-based NLP services, where processing costs can accumulate rapidly, this efficiency is not only a technical but also a financial advantage.\u003c/p\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003etable_details_prompt = \u003cspan class=\\\"hljs-string\\\"\u003ef\\\"\\\"\\\"Return the names of ALL the SQL tables that MIGHT be relevant to the user question. \\\\\\nThe tables are:\\n\\n\u003cspan class=\\\"hljs-subst\\\"\u003e{table_details}\u003c/span\u003e\\n\\nRemember to include ALL POTENTIALLY RELEVANT tables, even if you're not sure that they're needed.\\\"\\\"\\\"\u003c/span\u003e\\n\\ntable_chain = create_extraction_chain_pydantic(Table, llm, system_message=table_details_prompt)\\ntables = table_chain.invoke({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"input\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"give me details of customer and their order count\\\"\u003c/span\u003e})\\ntables\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-plaintext\\\"\u003e[Table(name='customers'), Table(name='orders')]\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e\u003cspan class=\\\"hljs-function\\\"\u003e\u003cspan class=\\\"hljs-keyword\\\"\u003edef\u003c/span\u003e \u003cspan class=\\\"hljs-title\\\"\u003eget_tables\u003c/span\u003e(\u003cspan class=\\\"hljs-params\\\"\u003etables: List[Table]\u003c/span\u003e) -\u0026gt; List[str]:\u003c/span\u003e\\n    tables  = [table.name \u003cspan class=\\\"hljs-keyword\\\"\u003efor\u003c/span\u003e table \u003cspan class=\\\"hljs-keyword\\\"\u003ein\u003c/span\u003e tables]\\n    \u003cspan class=\\\"hljs-keyword\\\"\u003ereturn\u003c/span\u003e tables\\n\\nselect_table = {\u003cspan class=\\\"hljs-string\\\"\u003e\\\"input\\\"\u003c/span\u003e: itemgetter(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"question\\\"\u003c/span\u003e)} | create_extraction_chain_pydantic(Table, llm, system_message=table_details_prompt) | get_tables\\nselect_table.invoke({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"question\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"give me details of customer and their order count\\\"\u003c/span\u003e})\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-plaintext\\\"\u003e['customers', 'orders']\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003echain = (\\nRunnablePassthrough.assign(table_names_to_use=select_table) |\\nRunnablePassthrough.assign(query=generate_query).assign(\\n    result=itemgetter(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"query\\\"\u003c/span\u003e) | execute_query\\n)\\n| rephrase_answer\\n)\\nchain.invoke({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"question\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"How many cutomers with order count more than 5\\\"\u003c/span\u003e})\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch2 id=\\\"heading-enhancing-chatbots-with-memory-for-follow-up-database-queries\\\"\u003eEnhancing Chatbots with Memory for Follow-up Database Queries\u003c/h2\u003e\\n\u003cp\u003eOne of the most advanced steps in creating a user-friendly NL2SQL interface is endowing your chatbot with memory. This feature enables the chatbot to handle follow-up questions related to the database intelligently, providing users with a seamless conversational experience. Let's explore how adding memory to your chatbot can revolutionize interactions with your database.\u003c/p\u003e\\n\u003ch4 id=\\\"heading-the-significance-of-memory-in-chatbots\\\"\u003eThe Significance of Memory in Chatbots\u003c/h4\u003e\\n\u003cp\u003eIn real-world conversations, context matters. A question might relate to or build upon previous interactions. Similarly, when users interact with a database through a chatbot, their follow-up questions often depend on the context established by earlier queries and responses. A chatbot equipped with memory can retain this context, allowing it to generate more accurate and relevant SQL queries for follow-up questions.\u003c/p\u003e\\n\u003ch4 id=\\\"heading-implementing-memory-in-your-nl2sql-model\\\"\u003eImplementing Memory in Your NL2SQL Model\u003c/h4\u003e\\n\u003cp\u003eTo equip your NL2SQL model with memory, consider incorporating a chat message history that tracks the conversation's flow. This history should include both the questions posed by the user and the chatbot's responses, enabling the model to reference previous interactions when generating SQL queries for new questions.\u003c/p\u003e\\n\u003col\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eSetting Up Message History\u003c/strong\u003e: Implement a mechanism to record each user query and the corresponding chatbot response. This can be achieved by defining a \u003ccode\u003eChatMessageHistory\u003c/code\u003e object that stores this information and can be accessed when needed\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e \u003cspan class=\\\"hljs-keyword\\\"\u003efrom\u003c/span\u003e langchain.memory \u003cspan class=\\\"hljs-keyword\\\"\u003eimport\u003c/span\u003e ChatMessageHistory\\n history = ChatMessageHistory()\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eLeveraging Previous Interactions\u003c/strong\u003e: Integrate this message history into your prompt generation process. Before generating a new SQL query, the model should consider the recorded history to understand the conversation's context\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e final_prompt = ChatPromptTemplate.from_messages(\\n     [\\n         (\u003cspan class=\\\"hljs-string\\\"\u003e\\\"system\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run. Unless otherwise specificed.\\\\n\\\\nHere is the relevant table info: {table_info}\\\\n\\\\nBelow are a number of examples of questions and their corresponding SQL queries. Those examples are just for referecne and hsould be considered while answering follow up questions\\\"\u003c/span\u003e),\\n         few_shot_prompt,\\n         MessagesPlaceholder(variable_name=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"messages\\\"\u003c/span\u003e),\\n         (\u003cspan class=\\\"hljs-string\\\"\u003e\\\"human\\\"\u003c/span\u003e, \u003cspan class=\\\"hljs-string\\\"\u003e\\\"{input}\\\"\u003c/span\u003e),\\n     ]\\n )\\n print(final_prompt.format(input=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"How many products are there?\\\"\u003c/span\u003e,table_info=\u003cspan class=\\\"hljs-string\\\"\u003e\\\"some table info\\\"\u003c/span\u003e,messages=[]))\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eDynamic Prompt Adaptation\u003c/strong\u003e: Use the chat message history to dynamically adapt the prompts sent to the model for generating SQL queries. This adaptation should include information from previous queries and responses, guiding the model in understanding the context of the follow-up question\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003e generate_query = create_sql_query_chain(llm, db,final_prompt)\\n\\n chain = (\\n RunnablePassthrough.assign(table_names_to_use=select_table) |\\n RunnablePassthrough.assign(query=generate_query).assign(\\n     result=itemgetter(\u003cspan class=\\\"hljs-string\\\"\u003e\\\"query\\\"\u003c/span\u003e) | execute_query\\n )\\n | rephrase_answer\\n )\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003c/li\u003e\\n\u003c/ol\u003e\\n\u003ch4 id=\\\"heading-example-scenario-handling-follow-up-questions\\\"\u003eExample Scenario: Handling Follow-Up Questions\u003c/h4\u003e\\n\u003cp\u003eImagine a user first asks, \\\"How many customers have an order count more than 5?\\\" After receiving the answer, they follow up with, \\\"Can you list their names?\\\" With a memory feature, the chatbot can understand that the second question relates to the subset of customers identified in response to the first question, allowing it to generate an accurate follow-up query without needing the user to re-specify the context.\u003c/p\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003equestion = \u003cspan class=\\\"hljs-string\\\"\u003e\\\"How many cutomers with order count more than 5\\\"\u003c/span\u003e\\nresponse = chain.invoke({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"question\\\"\u003c/span\u003e: question,\u003cspan class=\\\"hljs-string\\\"\u003e\\\"messages\\\"\u003c/span\u003e:history.messages})\\nThere are \u003cspan class=\\\"hljs-number\\\"\u003e2\u003c/span\u003e customers \u003cspan class=\\\"hljs-keyword\\\"\u003ewith\u003c/span\u003e an order count of more than \u003cspan class=\\\"hljs-number\\\"\u003e5.\u003c/span\u003e\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003ehistory.add_user_message(question)\\nhistory.add_ai_message(response)\\nhistory.messages\\n[HumanMessage(content=\u003cspan class=\\\"hljs-string\\\"\u003e'How many cutomers with order count more than 5'\u003c/span\u003e),\\n AIMessage(content=\u003cspan class=\\\"hljs-string\\\"\u003e'There are 2 customers with an order count of more than 5.'\u003c/span\u003e)]\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003cpre\u003e\u003ccode class=\\\"lang-python\\\"\u003eresponse = chain.invoke({\u003cspan class=\\\"hljs-string\\\"\u003e\\\"question\\\"\u003c/span\u003e: \u003cspan class=\\\"hljs-string\\\"\u003e\\\"Can you list there names?\\\"\u003c/span\u003e,\u003cspan class=\\\"hljs-string\\\"\u003e\\\"messages\\\"\u003c/span\u003e:history.messages})\\nresponse\\nThe names of the customers \u003cspan class=\\\"hljs-keyword\\\"\u003ewith\u003c/span\u003e more than \u003cspan class=\\\"hljs-number\\\"\u003e5\u003c/span\u003e orders are Mini Gifts Distributors Ltd. \u003cspan class=\\\"hljs-keyword\\\"\u003eand\u003c/span\u003e Euro+ Shopping Channel.\\n\u003c/code\u003e\u003c/pre\u003e\\n\u003ch2 id=\\\"heading-conclusion\\\"\u003e\u003cstrong\u003eConclusion:\u003c/strong\u003e\u003c/h2\u003e\\n\u003cp\u003eThrough this guide, we've journeyed through the process of enhancing NL2SQL models using LangChain, showcasing how to transform natural language queries into precise SQL commands. This exploration not only highlights the power of LangChain in making database queries more accessible but also underscores the broader impact of integrating advanced NLP techniques for intuitive data interaction.\u003c/p\u003e\\n\u003cp\u003eFor those interested in delving deeper, a \u003ca target=\\\"_blank\\\" href=\\\"https://youtu.be/fss6CrmQU2Y\\\"\u003evideo walkthrough\u003c/a\u003e and a comprehensive \u003ca target=\\\"_blank\\\" href=\\\"https://github.com/PradipNichite/Youtube-Tutorials/blob/main/Langchain_NL2SQL_2024.ipynb\\\"\u003eGitHub notebook\u003c/a\u003e and \u003ca target=\\\"_blank\\\" href=\\\"https://github.com/PradipNichite/Youtube-Tutorials/tree/main/Langchain%20NL2SQL%20Chatbot\\\"\u003eStreamlit Code\u003c/a\u003e are available to explore these concepts further. These resources offer visual demonstrations and hands-on examples to help bring these ideas to life in your own projects.\u003c/p\u003e\\n\u003cp\u003eThe journey toward more natural and efficient database interactions is ongoing, and with each step, we're making the world of data more accessible to all.\u003c/p\u003e\\n\u003cp\u003eIf you're curious about the latest in AI technology, I invite you to visit my project, AI Demos, at \u003ca target=\\\"_blank\\\" href=\\\"http://aidemos.com/\\\"\u003e\u003cstrong\u003e\u003ca href=\\\"http://aidemos.com\\\" class=\\\"autolinkedURL autolinkedURL-url\\\" target=\\\"_blank\\\"\u003eaidemos.com\u003c/a\u003e\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e. It's a rich resource offering a wide array of video demos showcasing the most advanced AI tools. My goal with AI Demos is to educate and illuminate the diverse possibilities of AI.\u003c/strong\u003e\u003c/p\u003e\\n\u003cp\u003eFor even more in-depth exploration, be sure to visit my YouTube channel at \u003ca target=\\\"_blank\\\" href=\\\"https://www.youtube.com/@aidemos.videos\\\"\u003ehttps://www.youtube.com/@aidemos.videos\u003c/a\u003e\u003cstrong\u003e. Here, you'll find a wealth of content that delves into the exciting future of AI and its various applications.\u003c/strong\u003e\u003c/p\u003e\\n\",\"cuid\":\"cltmt9d8u000308jy744l8n74\",\"views\":39122,\"title\":\"Mastering Natural Language to SQL with LangChain | NL2SQL\",\"slug\":\"mastering-natural-language-to-sql-with-langchain-nl2sql\",\"dateAdded\":\"2024-03-11T10:38:55.566Z\",\"dateUpdated\":\"2024-03-11T10:40:28.637Z\",\"type\":\"story\",\"coverImage\":\"https://cdn.hashnode.com/res/hashnode/image/upload/v1710152478787/e57074e2-3303-46ec-8491-11f60aa0bd2d.png\",\"isCoverImagePortrait\":false,\"isCoverAttributionHidden\":false,\"brief\":\"Introduction\\nWelcome to our deep dive into revolutionizing the way we interact with databases using Natural Language Processing (NLP) and LangChain. In today's data-driven world, the ability to query databases without needing to know complex SQL synt...\",\"isFollowing\":false,\"totalReactions\":21,\"totalReactionsByCurrentUser\":0,\"series\":null,\"isPinnedToBlog\":false,\"readTime\":14,\"sB\":false,\"isAMA\":false,\"subtitle\":\"\",\"isPartOfSeries\":false,\"hasTags\":true,\"ogImage\":\"\",\"metaTitle\":\"\",\"metaDescription\":\"Unlock the full potential of database interactions with our guide on Natural Language to SQL using LangChain and LLM.\",\"isRepublished\":false,\"autoPublishedFromRSS\":false,\"responses\":[],\"isFeatured\":false,\"hasLatex\":false,\"stickCoverToBottom\":false,\"hideBadges\":false,\"badges\":[],\"isDelisted\":false,\"audioUrls\":{},\"disableComments\":false,\"enableToc\":true,\"toc\":[[{\"id\":\"6a4b64cc-4dc7-498c-babd-f79152ec0916\",\"level\":2,\"slug\":\"introduction\",\"title\":\"Introduction\",\"parentId\":null}],[{\"id\":\"89f6377b-515f-410a-b612-3b1926dd7e4a\",\"level\":2,\"slug\":\"building-a-basic-nl2sql-model\",\"title\":\"Building a Basic NL2SQL Model\",\"parentId\":null}],[{\"id\":\"bb4ff478-b5bb-4962-9895-16c826212a1b\",\"level\":4,\"slug\":\"understanding-the-basics\",\"title\":\"Understanding the Basics\",\"parentId\":\"89f6377b-515f-410a-b612-3b1926dd7e4a\"}],[{\"id\":\"ea22420b-75d2-492c-9394-425d5309cb14\",\"level\":4,\"slug\":\"setting-up-langchain\",\"title\":\"Setting Up LangChain\",\"parentId\":\"89f6377b-515f-410a-b612-3b1926dd7e4a\"}],[{\"id\":\"622473cc-a30e-490d-a5a6-055c1bb8156f\",\"level\":4,\"slug\":\"the-first-query\",\"title\":\"The First Query\",\"parentId\":\"89f6377b-515f-410a-b612-3b1926dd7e4a\"}],[{\"id\":\"6163595a-a60a-492a-acc2-8301e380bb3a\",\"level\":4,\"slug\":\"seeing-the-results\",\"title\":\"Seeing the Results\",\"parentId\":\"89f6377b-515f-410a-b612-3b1926dd7e4a\"}],[{\"id\":\"3ab1b020-4a7e-49e8-b8b9-8327280d5c38\",\"level\":4,\"slug\":\"moving-forward\",\"title\":\"Moving Forward\",\"parentId\":\"89f6377b-515f-410a-b612-3b1926dd7e4a\"}],[{\"id\":\"23abf3fc-5dce-4913-bd2e-6f4deefc4c80\",\"level\":2,\"slug\":\"rephrasing-answers-for-enhanced-clarity\",\"title\":\"Rephrasing Answers for Enhanced Clarity\",\"parentId\":null}],[{\"id\":\"2723367f-11b2-4b0b-8f80-ac78795c0455\",\"level\":4,\"slug\":\"implementing-rephrasing-with-langchain\",\"title\":\"Implementing Rephrasing with LangChain\",\"parentId\":\"23abf3fc-5dce-4913-bd2e-6f4deefc4c80\"}],[{\"id\":\"723b6b1a-9890-423f-9e23-39705a3d3a0b\",\"level\":4,\"slug\":\"example-transforming-sql-results-into-user-friendly-responses\",\"title\":\"Example: Transforming SQL Results into User-Friendly Responses\",\"parentId\":\"23abf3fc-5dce-4913-bd2e-6f4deefc4c80\"}],[{\"id\":\"6c7b4aff-61de-4eef-92f6-0d3509afb5f7\",\"level\":2,\"slug\":\"enhancing-nl2sql-models-with-few-shot-examples\",\"title\":\"Enhancing NL2SQL Models with Few-Shot Examples\",\"parentId\":null}],[{\"id\":\"29b8ba8c-a202-42aa-bc3a-079048290ff2\",\"level\":4,\"slug\":\"incorporating-few-shot-examples-into-langchain\",\"title\":\"Incorporating Few-Shot Examples into LangChain\",\"parentId\":\"6c7b4aff-61de-4eef-92f6-0d3509afb5f7\"}],[{\"id\":\"48bfcd04-66ab-4ee5-b177-1a75ad1c7e4d\",\"level\":4,\"slug\":\"the-impact-of-few-shot-learning\",\"title\":\"The Impact of Few-Shot Learning\",\"parentId\":\"6c7b4aff-61de-4eef-92f6-0d3509afb5f7\"}],[{\"id\":\"145d30b6-096f-405f-a44c-c86b4279f723\",\"level\":2,\"slug\":\"dynamic-few-shot-example-selection\",\"title\":\"Dynamic Few-Shot Example Selection:\",\"parentId\":null}],[{\"id\":\"29c4be64-f1b4-4156-abc1-41e406f9bc47\",\"level\":4,\"slug\":\"the-need-for-dynamism\",\"title\":\"The Need for Dynamism\",\"parentId\":\"145d30b6-096f-405f-a44c-c86b4279f723\"}],[{\"id\":\"7f2d3a9d-cdba-4667-8813-116b0f92f119\",\"level\":4,\"slug\":\"implementing-dynamic-few-shot-selection\",\"title\":\"Implementing Dynamic Few-Shot Selection\",\"parentId\":\"145d30b6-096f-405f-a44c-c86b4279f723\"}],[{\"id\":\"8d8fc6ef-2108-4a4f-af9f-80f72789047a\",\"level\":2,\"slug\":\"dynamic-relevant-table-selection\",\"title\":\"Dynamic Relevant Table Selection\",\"parentId\":null}],[{\"id\":\"6b7f41f4-1020-416a-b891-50a1373b6a91\",\"level\":4,\"slug\":\"leveraging-smaller-focused-prompts-for-faster-execution\",\"title\":\"Leveraging Smaller, Focused Prompts for Faster Execution\",\"parentId\":\"8d8fc6ef-2108-4a4f-af9f-80f72789047a\"}],[{\"id\":\"0039f550-0787-4861-9971-1cd12bc7f576\",\"level\":2,\"slug\":\"enhancing-chatbots-with-memory-for-follow-up-database-queries\",\"title\":\"Enhancing Chatbots with Memory for Follow-up Database Queries\",\"parentId\":null}],[{\"id\":\"633b8ee7-b47b-4fa2-b05b-e3ab6e26626a\",\"level\":4,\"slug\":\"the-significance-of-memory-in-chatbots\",\"title\":\"The Significance of Memory in Chatbots\",\"parentId\":\"0039f550-0787-4861-9971-1cd12bc7f576\"}],[{\"id\":\"c24d59b1-7af7-4601-8f48-0c67f3210e3b\",\"level\":4,\"slug\":\"implementing-memory-in-your-nl2sql-model\",\"title\":\"Implementing Memory in Your NL2SQL Model\",\"parentId\":\"0039f550-0787-4861-9971-1cd12bc7f576\"}],[{\"id\":\"4323aad8-b5b2-4ade-9d71-61fdcdc71b2f\",\"level\":4,\"slug\":\"example-scenario-handling-follow-up-questions\",\"title\":\"Example Scenario: Handling Follow-Up Questions\",\"parentId\":\"0039f550-0787-4861-9971-1cd12bc7f576\"}],[{\"id\":\"b7148ae5-6032-4ffd-bd89-102a74b799a5\",\"level\":2,\"slug\":\"conclusion\",\"title\":\"Conclusion:\",\"parentId\":null}]],\"noIndex\":false}","legacySeriesJSON":null,"headProps":{"title":"Mastering Natural Language to SQL with LangChain | NL2SQL","description":"Unlock the full potential of database interactions with our guide on Natural Language to SQL using LangChain and LLM.","author":{"name":"Pradip Nichite","username":"pnichite"},"links":[{"rel":"canonical","href":"https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql"}],"pageType":"article","bannerType":"large","ogSiteName":"FutureSmart AI Blog","url":"https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql","ogImage":"https://hashnode.com/utility/r?url=https%3A%2F%2Fcdn.hashnode.com%2Fres%2Fhashnode%2Fimage%2Fupload%2Fv1710152478787%2Fe57074e2-3303-46ec-8491-11f60aa0bd2d.png%3Fw%3D1200%26h%3D630%26fit%3Dcrop%26crop%3Dentropy%26auto%3Dcompress%2Cformat%26format%3Dwebp%26fm%3Dpng","twitterImage":"https://hashnode.com/utility/r?url=https%3A%2F%2Fcdn.hashnode.com%2Fres%2Fhashnode%2Fimage%2Fupload%2Fv1710152478787%2Fe57074e2-3303-46ec-8491-11f60aa0bd2d.png%3Fw%3D1200%26h%3D630%26fit%3Dcrop%26crop%3Dentropy%26auto%3Dcompress%2Cformat%26format%3Dwebp%26fm%3Dpng","twitterHandle":"","monetization":"","style":{},"customHeadItems":{"customFavicon":null,"customTheme":"#2962FF","customMeta":"\u003cmeta name=\"google-site-verification\" content=\"hjDPYL5JIhkWAQpDvFOQHPr81ODcsYielMtN-_oZQSg\" /\u003e"},"hljs":true},"isDarkTheme":false,"headerColor":"#2962FF","isBadge":null,"isRecommendations":null,"isHome":null,"currentMenuId":null,"hnmcMode":false,"postCUID":"cltmt9d8u000308jy744l8n74","seoSchema":{"@context":"https://schema.org","@type":"NewsArticle","url":"https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql","mainEntityOfPage":"https://blog.futuresmart.ai/mastering-natural-language-to-sql-with-langchain-nl2sql","headline":"Mastering Natural Language to SQL with LangChain | NL2SQL","description":"Unlock the full potential of database interactions with our guide on Natural Language to SQL using LangChain and LLM.","datePublished":"2024-03-11T10:38:55.566Z","dateModified":"2024-03-11T10:40:28.637Z","isAccessibleForFree":true,"author":{"@type":"Person","name":"Pradip Nichite","url":"https://hashnode.com/@pnichite"},"publisher":{"@type":"Organization","name":"FutureSmart AI Blog","url":"https://blog.futuresmart.ai","logo":"https://hashnode.com/utility/r?url=https%3A%2F%2Fcdn.hashnode.com%2Fres%2Fhashnode%2Fimage%2Fupload%2Fv1559814205701%2Fek9fO-yT0.jpeg%3Fw%3D800%26bm%3Dnormal%26balph%3D100%26txt64%3DRnV0dXJlU21hcnQgQUkgQmxvZw%26txtsize%3D42%26txtfit%3Dmax%26txtalign%3Dmiddle%2Ccenter%26txtfont%3DHelvetica%20Neue%2CBold%26txtclr%3Dffffff%26blend%3D2962FF"},"image":{"@type":"ImageObject","url":"https://cdn.hashnode.com/res/hashnode/image/upload/v1710152478787/e57074e2-3303-46ec-8491-11f60aa0bd2d.png"}},"publication":{"__typename":"Publication","id":"6294f745136694dfeee8e80c","url":"https://blog.futuresmart.ai","canonicalURL":"https://blog.futuresmart.ai","urlPattern":"SIMPLE","title":"FutureSmart AI Blog","displayTitle":"Building Custom NLP Solutions using state of the art NLP models | FutureSmart AI","hasBadges":true,"descriptionSEO":"Learn how to build custom Natural Language Processing (NLP) solutions using state-of-the-art models. Use Pytorch, Amazon Lex, FastAPI, and Hugging Face Transformers to create powerful applications.","publicMembers":{"totalDocuments":16},"about":{"html":"\u003cp\u003eFutureSmart AI provides custom Natural Language Processing (NLP) solutions.\u003c/p\u003e\n","text":"FutureSmart AI provides custom Natural Language Processing (NLP) solutions.\n"},"features":{"proTeam":{"isEnabled":false},"newsletter":{"isEnabled":false},"viewCount":{"isEnabled":false},"readTime":{"isEnabled":true},"textSelectionSharer":{"isEnabled":true},"customCSS":{"isEnabled":false,"published":null,"draft":null},"gptBotCrawling":{"__typename":"GPTBotCrawlingFeature","isEnabled":false}},"metaTags":"\u003cmeta name=\"google-site-verification\" content=\"hjDPYL5JIhkWAQpDvFOQHPr81ODcsYielMtN-_oZQSg\" /\u003e","ogMetaData":{"image":null},"author":{"__typename":"User","id":"610e6befb79d6a11366814e1","name":"Pradip Nichite","username":"pnichite","profilePicture":"https://cdn.hashnode.com/res/hashnode/image/upload/v1629011734354/sgLB_1lXJ.jpeg"},"preferences":{"__typename":"Preferences","logo":null,"darkMode":{"__typename":"DarkModePreferences","logo":null,"enabled":null},"navbarItems":[{"__typename":"PublicationNavbarItem","id":"6294fc0d1ef08fdfc9f632ba","label":"website","url":"https://www.futuresmart.ai/","type":"link","series":null,"page":null},{"__typename":"PublicationNavbarItem","id":"6358d50ff001c905d3bc60be","label":"Youtube","url":"https://www.youtube.com/c/PradipNichiteAI","type":"link","series":null,"page":null},{"__typename":"PublicationNavbarItem","id":"6358d543c1d1be05714fa376","label":"LinkedIN","url":"https://www.linkedin.com/in/pradipnichite/","type":"link","series":null,"page":null},{"__typename":"PublicationNavbarItem","id":"63ca4e7d587fc59d3cd72863","label":"AI Demos","url":"https://www.aidemos.com/","type":"link","series":null,"page":null}],"enabledPages":{"__typename":"PagesPreferences","badges":false,"newsletter":false,"members":true},"layout":"stacked","disableFooterBranding":false,"isSubscriptionModalDisabled":false},"favicon":null,"headerColor":"#2962FF","integrations":{"fbPixelID":null,"fathomSiteID":null,"fathomCustomDomainEnabled":null,"fathomCustomDomain":null,"hotjarSiteID":null,"matomoSiteID":null,"matomoURL":null,"gaTrackingID":"G-X68KZGCNTQ","gTagManagerID":null,"plausibleAnalyticsEnabled":null,"koalaPublicKey":null,"msClarityID":null},"imprintV2":null,"postsCount":{"totalDocuments":105},"isTeam":true,"links":{"twitter":"","instagram":"https://www.instagram.com/futuresmart.ai","github":"","website":"https://www.futuresmart.ai/","hashnode":"","youtube":"https://www.youtube.com/c/PradipNichiteAI","dailydev":"","linkedin":"","mastodon":null,"facebook":null,"bluesky":null},"domainInfo":{"__typename":"DomainInfo","hashnodeSubdomain":"pnichite-1653929794900","domain":{"__typename":"DomainStatus","host":"blog.futuresmart.ai","ready":true},"wwwPrefixedDomain":null},"redirectionRules":[],"totalRecommendedPublications":0,"sponsorship":{"content":null,"stripe":null},"allowContributorEdits":true,"rssImport":null,"post":{"id":"65eedf3f2e25d54cd93c3d52","cuid":"cltmt9d8u000308jy744l8n74","title":"Mastering Natural Language to SQL with LangChain | NL2SQL","subtitle":null,"slug":"mastering-natural-language-to-sql-with-langchain-nl2sql","brief":"Introduction\nWelcome to our deep dive into revolutionizing the way we interact with databases using Natural Language Processing (NLP) and LangChain. In today's data-driven world, the ability to query databases without needing to know complex SQL synt...","featured":false,"publishedAt":"2024-03-11T10:38:55.566Z","updatedAt":"2024-03-11T10:40:28.637Z","author":{"__typename":"User","id":"610e6befb79d6a11366814e1","name":"Pradip Nichite","username":"pnichite","deactivated":false,"profilePicture":"https://cdn.hashnode.com/res/hashnode/image/upload/v1629011734354/sgLB_1lXJ.jpeg","bio":{"html":"\u003cp\u003e🚀 I'm a Top Rated Plus NLP freelancer on Upwork with over $300K in earnings and a 100% Job Success rate. This journey began in 2022 after years of enriching experience in the field of Data Science.\n📚 Starting my career in 2013 as a Software Developer focusing on backend and API development, I soon pursued my interest in Data Science by earning my M.Tech in IT from IIIT Bangalore, specializing in Data Science (2016 - 2018).\n💼 Upon graduation, I carved out a path in the industry as a Data Scientist at MiQ (2018 - 2020) and later ascended to the role of Lead Data Scientist at Oracle (2020 - 2022).\n🌐 Inspired by my freelancing success, I founded FutureSmart AI in September 2022. We provide custom AI solutions for clients using the latest models and techniques in NLP.\n🎥 In addition, I run AI Demos, a platform aimed at educating people about the latest AI tools through engaging video demonstrations.\n🧰 My technical toolbox encompasses:\n🔧 Languages: Python, JavaScript, SQL.\n🧪 ML Libraries: PyTorch, Transformers, LangChain.\n🔍 Specialties: Semantic Search, Sentence Transformers, Vector Databases.\n🖥️ Web Frameworks: FastAPI, Streamlit, Anvil.\n☁️ Other: AWS, AWS RDS, MySQL.\n🚀 In the fast-evolving landscape of AI, FutureSmart AI and I stand at the forefront, delivering cutting-edge, custom NLP solutions to clients across various industries.\u003c/p\u003e\n"},"socialMediaLinks":{"website":"https://www.futuresmart.ai/","github":"","twitter":"","facebook":"","stackoverflow":"","linkedin":"https://www.linkedin.com/in/pradipnichite/"}},"coAuthors":[],"seo":{"title":null,"description":"Unlock the full potential of database interactions with our guide on Natural Language to SQL using LangChain and LLM.","shouldNotIndex":false},"coverImage":{"url":"https://cdn.hashnode.com/res/hashnode/image/upload/v1710152478787/e57074e2-3303-46ec-8491-11f60aa0bd2d.png","isPortrait":false,"attribution":null,"isAttributionHidden":false,"photographer":null},"responseCount":5,"reactionCount":21,"replyCount":0,"content":{"html":"\u003ch2 id=\"heading-introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eWelcome to our deep dive into revolutionizing the way we interact with databases using Natural Language Processing (NLP) and LangChain. In today's data-driven world, the ability to query databases without needing to know complex SQL syntax opens up a myriad of possibilities across various industries, from healthcare to finance, making data more accessible to everyone.\u003c/p\u003e\n\u003cp\u003eThis blog post aims to guide you through a comprehensive journey to master NL2SQL using LangChain. We will explore the steps necessary to build an intuitive, efficient, and intelligent NL2SQL model that can understand and process natural language queries, dynamically select relevant database tables, and maintain a conversational context to handle follow-up questions effectively.\u003c/p\u003e\n\u003cp\u003eBy the end of this post, you'll have a solid understanding of:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eBuilding a Basic NL2SQL Model\u003c/strong\u003e: The foundation of translating natural language queries into SQL commands.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eIncorporating Few-Shot Learning\u003c/strong\u003e: Enhancing model accuracy with examples.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eDynamic Few-Shot Example Selection\u003c/strong\u003e: Tailoring examples to the query context for improved relevance.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eDynamic Relevant Table Selection\u003c/strong\u003e: Automatically identifying which tables to query based on the natural language input.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eCustomizing Prompts and Responses\u003c/strong\u003e: Fine-tuning the model's interaction to provide clear, concise, and relevant answers.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eAdding Memory to Chatbots\u003c/strong\u003e: Enabling the model to handle follow-up questions by remembering the context of the conversation.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eThrough each of these steps, we'll discuss the concepts, show you how to implement them , and illustrate the outcomes , ensuring you have the tools and knowledge needed to bring the power of NL2SQL to your databases.\u003c/p\u003e\n\u003cp\u003eLet's embark on this exciting journey to unlock the full potential of your data, making database queries as simple as conversing with a friend.\u003c/p\u003e\n\u003ch2 id=\"heading-building-a-basic-nl2sql-model\"\u003eBuilding a Basic NL2SQL Model\u003c/h2\u003e\n\u003cp\u003eThe first step in our journey to revolutionize database querying with natural language is constructing a basic NL2SQL model using LangChain. This foundational model serves as the cornerstone for more advanced functionalities we'll explore later. Here's how we begin:\u003c/p\u003e\n\u003ch4 id=\"heading-understanding-the-basics\"\u003eUnderstanding the Basics\u003c/h4\u003e\n\u003cp\u003eAt its core, an NL2SQL model aims to translate natural language queries into SQL commands. But how do we start building such a model with LangChain?\u003c/p\u003e\n\u003ch4 id=\"heading-setting-up-langchain\"\u003eSetting Up LangChain\u003c/h4\u003e\n\u003cp\u003eLangChain simplifies the process of creating NL2SQL models by providing a flexible framework that integrates seamlessly with existing databases and natural language processing (NLP) models. To get started, you'll need to:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eInstall LangChain\u003c/strong\u003e: Ensure that LangChain is installed in your environment.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-bash\"\u003e pip install langchain_openai langchain_community langchain pymysql chromadb -q\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eConnect to Your Database\u003c/strong\u003e: The next step involves establishing a connection to your database. LangChain supports various database systems, so you'll likely find your database among the supported ones. You'll use the database credentials to create a connection that LangChain can use to interact with your data\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e os\n os.environ[\u003cspan class=\"hljs-string\"\u003e\"OPENAI_API_KEY\"\u003c/span\u003e] = \u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e\n\n db_user = \u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e\n db_password = \u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e\n db_host = \u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e\n db_name = \u003cspan class=\"hljs-string\"\u003e\"classicmodels\"\u003c/span\u003e\n \u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e langchain_community.utilities.sql_database \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e SQLDatabase\n \u003cspan class=\"hljs-comment\"\u003e# db = SQLDatabase.from_uri(f\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\",sample_rows_in_table_info=1,include_tables=['customers','orders'],custom_table_info={'customers':\"customer\"})\u003c/span\u003e\n db = SQLDatabase.from_uri(\u003cspan class=\"hljs-string\"\u003ef\"mysql+pymysql://\u003cspan class=\"hljs-subst\"\u003e{db_user}\u003c/span\u003e:\u003cspan class=\"hljs-subst\"\u003e{db_password}\u003c/span\u003e@\u003cspan class=\"hljs-subst\"\u003e{db_host}\u003c/span\u003e/\u003cspan class=\"hljs-subst\"\u003e{db_name}\u003c/span\u003e\"\u003c/span\u003e)\n print(db.dialect)\n print(db.get_usable_table_names())\n print(db.table_info)\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch4 id=\"heading-the-first-query\"\u003eThe First Query\u003c/h4\u003e\n\u003cp\u003eOnce the setup is complete, the real magic begins. You can start by formulating a simple query in natural language, such as \"Show me all products priced above $100.\" LangChain takes this input and, through its integration with language models like ChatGPT and your database, generates an SQL query that precisely captures the intent of your request\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e langchain.chains \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e create_sql_query_chain\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e langchain_openai \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e ChatOpenAI\n\nllm = ChatOpenAI(model=\u003cspan class=\"hljs-string\"\u003e\"gpt-3.5-turbo\"\u003c/span\u003e, temperature=\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e)\ngenerate_query = create_sql_query_chain(llm, db)\nquery = generate_query.invoke({\u003cspan class=\"hljs-string\"\u003e\"question\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"what is price of `1968 Ford Mustang`\"\u003c/span\u003e})\n\u003cspan class=\"hljs-comment\"\u003e# \"what is price of `1968 Ford Mustang`\"\u003c/span\u003e\nprint(query)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4 id=\"heading-seeing-the-results\"\u003eSeeing the Results\u003c/h4\u003e\n\u003cp\u003eExecuting the generated SQL query against your database retrieves the data you're looking for, which LangChain can then present in a user-friendly format.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e langchain_community.tools.sql_database.tool \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e QuerySQLDataBaseTool\nexecute_query = QuerySQLDataBaseTool(db=db)\nexecute_query.invoke(query)\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4 id=\"heading-moving-forward\"\u003eMoving Forward\u003c/h4\u003e\n\u003cp\u003eWith the basic NL2SQL model set up, you've taken the first step towards transforming how we interact with databases. However, this is just the beginning. As we progress, we'll explore how to enhance the model's accuracy, handle more complex queries, and even maintain context over a conversation for follow-up questions.\u003c/p\u003e\n\u003ch2 id=\"heading-rephrasing-answers-for-enhanced-clarity\"\u003eRephrasing Answers for Enhanced Clarity\u003c/h2\u003e\n\u003cp\u003eAfter your NL2SQL model successfully executes a SQL query, the next pivotal step is to present the data in a manner that's easily understandable by your users. This is where the art of rephrasing SQL results into clear, natural language answers comes into play. Here's how you can achieve this with LangChain:\u003c/p\u003e\n\u003ch4 id=\"heading-implementing-rephrasing-with-langchain\"\u003eImplementing Rephrasing with LangChain\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eUse Prompt Templates\u003c/strong\u003e: LangChain allows you to create prompt templates that can guide the model in how to rephrase SQL results. These templates can include placeholders for the original question, the SQL query, and the query result, setting the stage for generating a natural language response\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e \u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e operator \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e itemgetter\n\n \u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e langchain_core.output_parsers \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e StrOutputParser\n \u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e langchain_core.prompts \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e PromptTemplate\n \u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e langchain_core.runnables \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e RunnablePassthrough\n\n answer_prompt = PromptTemplate.from_template(\n     \u003cspan class=\"hljs-string\"\u003e\"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n\n Question: {question}\n SQL Query: {query}\n SQL Result: {result}\n Answer: \"\"\"\u003c/span\u003e\n )\n\n rephrase_answer = answer_prompt | llm | StrOutputParser()\n\n chain = (\n     RunnablePassthrough.assign(query=generate_query).assign(\n         result=itemgetter(\u003cspan class=\"hljs-string\"\u003e\"query\"\u003c/span\u003e) | execute_query\n     )\n     | rephrase_answer\n )\n\n chain.invoke({\u003cspan class=\"hljs-string\"\u003e\"question\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"How many customers have an order count greater than 5\"\u003c/span\u003e})\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch4 id=\"heading-example-transforming-sql-results-into-user-friendly-responses\"\u003eExample: Transforming SQL Results into User-Friendly Responses\u003c/h4\u003e\n\u003cp\u003eLet's consider a user asks, \"How many customers have an order count greater than 5?\" and the SQL query returns a raw numerical result. The rephrasing process would convert this into a more readable answer, such as \"There are 2 customers with an order count of more than 5.\" This step is vital in closing the loop between user queries and database responses, ensuring that the information provided is both useful and easily digestible\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-plaintext\"\u003eThere are 2 customers with an order count of more than 5.\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eIn the next section, we'll dive into the exciting world of few-shot learning and how it can be used to improve the performance of your NL2SQL model with LangChain. Stay tuned to unlock the full potential of natural language database querying.\u003c/p\u003e\n\u003ch2 id=\"heading-enhancing-nl2sql-models-with-few-shot-examples\"\u003eEnhancing NL2SQL Models with Few-Shot Examples\u003c/h2\u003e\n\u003cp\u003eThis technique involves providing the model with a small set of carefully selected examples that demonstrate how to convert natural language questions into SQL queries. Few-shot learning can significantly improve the model's ability to understand and generate precise SQL commands based on user queries, bridging the gap between human language and database querying.\u003c/p\u003e\n\u003ch4 id=\"heading-incorporating-few-shot-examples-into-langchain\"\u003eIncorporating Few-Shot Examples into LangChain\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eSelecting Relevant Examples\u003c/strong\u003e: The first step is to curate a set of examples that cover a broad range of query types and complexities. These examples should ideally reflect the most common or critical queries your users might perform\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-plaintext\"\u003e examples = [\n     {\n         \"input\": \"List all customers in France with a credit limit over 20,000.\",\n         \"query\": \"SELECT * FROM customers WHERE country = 'France' AND creditLimit \u0026gt; 20000;\"\n     },\n     {\n         \"input\": \"Get the highest payment amount made by any customer.\",\n         \"query\": \"SELECT MAX(amount) FROM payments;\"\n     },\n    .....\n ]\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eCreating a Few-Shot Learning Template\u003c/strong\u003e: With LangChain, you can design a prompt template that incorporates these examples into the model's workflow. The template instructs the model to consider the examples when generating SQL queries from new user questions\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e \u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e langchain_core.prompts \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e ChatPromptTemplate, MessagesPlaceholder,FewShotChatMessagePromptTemplate,PromptTemplate\n\n example_prompt = ChatPromptTemplate.from_messages(\n     [\n         (\u003cspan class=\"hljs-string\"\u003e\"human\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"{input}\\nSQLQuery:\"\u003c/span\u003e),\n         (\u003cspan class=\"hljs-string\"\u003e\"ai\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"{query}\"\u003c/span\u003e),\n     ]\n )\n few_shot_prompt = FewShotChatMessagePromptTemplate(\n     example_prompt=example_prompt,\n     examples=examples,\n     \u003cspan class=\"hljs-comment\"\u003e# input_variables=[\"input\",\"top_k\"],\u003c/span\u003e\n     input_variables=[\u003cspan class=\"hljs-string\"\u003e\"input\"\u003c/span\u003e],\n )\n print(few_shot_prompt.format(input1=\u003cspan class=\"hljs-string\"\u003e\"How many products are there?\"\u003c/span\u003e))\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"lang-plaintext\"\u003e Human: List all customers in France with a credit limit over 20,000.\n SQLQuery:\n AI: SELECT * FROM customers WHERE country = 'France' AND creditLimit \u0026gt; 20000;\n Human: Get the highest payment amount made by any customer.\n SQLQuery:\n AI: SELECT MAX(amount) FROM payments;\n ......\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch4 id=\"heading-the-impact-of-few-shot-learning\"\u003eThe Impact of Few-Shot Learning\u003c/h4\u003e\n\u003cp\u003eBy integrating few-shot examples, your NL2SQL model becomes more adept at handling a wider variety of user queries. This not only improves the user experience by providing more accurate and relevant responses but also reduces the potential for errors in SQL query generation.\u003c/p\u003e\n\u003cp\u003eIn the next section, we'll explore the integration of dynamic example selection to further enhance the model's accuracy and relevance, ensuring that your NL2SQL system remains adaptive and responsive to user queries.\u003c/p\u003e\n\u003ch2 id=\"heading-dynamic-few-shot-example-selection\"\u003eDynamic Few-Shot Example Selection:\u003c/h2\u003e\n\u003cp\u003eThis advanced technique tailors the few-shot examples provided to the model based on the specific context of the user's query. It ensures that the guidance offered to the model is not just relevant but optimally aligned with the query's nuances, significantly boosting the model's ability to generate accurate SQL queries.\u003c/p\u003e\n\u003ch4 id=\"heading-the-need-for-dynamism\"\u003eThe Need for Dynamism\u003c/h4\u003e\n\u003cp\u003eStatic few-shot examples, though highly effective, have their limitations. Dynamic selection addresses this by intelligently choosing examples that closely match the intent and context of each new query, providing a customized learning experience for the model with every interaction.\u003c/p\u003e\n\u003ch4 id=\"heading-implementing-dynamic-few-shot-selection\"\u003eImplementing Dynamic Few-Shot Selection\u003c/h4\u003e\n\u003col\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eExample Selector Configuration\u003c/strong\u003e: Begin by setting up an example selector that can analyze the semantics of the user's query and compare it with a repository of potential examples. Tools like semantic similarity algorithms and vector embeddings come into play here, identifying which examples are most relevant to the current query\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e \u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e langchain_community.vectorstores \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e Chroma\n \u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e langchain_core.example_selectors \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e SemanticSimilarityExampleSelector\n \u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e langchain_openai \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e OpenAIEmbeddings\n\n vectorstore = Chroma()\n vectorstore.delete_collection()\n example_selector = SemanticSimilarityExampleSelector.from_examples(\n     examples,\n     OpenAIEmbeddings(),\n     vectorstore,\n     k=\u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e,\n     input_keys=[\u003cspan class=\"hljs-string\"\u003e\"input\"\u003c/span\u003e],\n )\n example_selector.select_examples({\u003cspan class=\"hljs-string\"\u003e\"input\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"how many employees we have?\"\u003c/span\u003e})\n few_shot_prompt = FewShotChatMessagePromptTemplate(\n     example_prompt=example_prompt,\n     example_selector=example_selector,\n     input_variables=[\u003cspan class=\"hljs-string\"\u003e\"input\"\u003c/span\u003e,\u003cspan class=\"hljs-string\"\u003e\"top_k\"\u003c/span\u003e],\n )\n print(few_shot_prompt.format(input=\u003cspan class=\"hljs-string\"\u003e\"How many products are there?\"\u003c/span\u003e))\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eIntegrating with LangChain\u003c/strong\u003e: Integrate the example selector with your LangChain workflow. When a new query is received, the selector determines the most relevant few-shot examples before the model generates the SQL query. This ensures that the guidance provided to the model is tailored to the specific requirements of the query\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e final_prompt = ChatPromptTemplate.from_messages(\n     [\n         (\u003cspan class=\"hljs-string\"\u003e\"system\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run. Unless otherwise specificed.\\n\\nHere is the relevant table info: {table_info}\\n\\nBelow are a number of examples of questions and their corresponding SQL queries.\"\u003c/span\u003e),\n         few_shot_prompt,\n         (\u003cspan class=\"hljs-string\"\u003e\"human\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"{input}\"\u003c/span\u003e),\n     ]\n )\n print(final_prompt.format(input=\u003cspan class=\"hljs-string\"\u003e\"How many products are there?\"\u003c/span\u003e,table_info=\u003cspan class=\"hljs-string\"\u003e\"some table info\"\u003c/span\u003e))\n generate_query = create_sql_query_chain(llm, db,final_prompt)\n chain = (\n RunnablePassthrough.assign(query=generate_query).assign(\n     result=itemgetter(\u003cspan class=\"hljs-string\"\u003e\"query\"\u003c/span\u003e) | execute_query\n )\n | rephrase_answer\n )\n chain.invoke({\u003cspan class=\"hljs-string\"\u003e\"question\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"How many csutomers with credit limit more than 50000\"\u003c/span\u003e})\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"lang-plaintext\"\u003e There are 85 customers with a credit limit greater than 50000.\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eBy ensuring that the examples used for guidance are always contextually relevant, the model can generate more precise SQL queries, reducing errors and improving user satisfaction. of NL2SQL technology, making data insights more accessible to everyone.\u003c/p\u003e\n\u003cp\u003eIn the following section, we will explore the integration of dynamic relevant table selection, further advancing our NL2SQL model's capabilities to efficiently parse and respond to user queries.\u003c/p\u003e\n\u003ch2 id=\"heading-dynamic-relevant-table-selection\"\u003eDynamic Relevant Table Selection\u003c/h2\u003e\n\u003cp\u003eIn the realm of NL2SQL models, especially when dealing with complex databases featuring 100+ tables. With databases growing in complexity and size, it's impractical and costly in terms of prompt token usage to include the schema of every table in the initial prompt for generating SQL queries. The sheer volume of information would overwhelm the model, leading to slower response times and increased computational costs. Dynamic relevant table selection emerges as a solution to this challenge, focusing the model's attention only on the tables pertinent to the user's query.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e operator \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e itemgetter\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e langchain.chains.openai_tools \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e create_extraction_chain_pydantic\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e langchain_core.pydantic_v1 \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e BaseModel, Field\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e typing \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e List\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e pandas \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e pd\n\n\u003cspan class=\"hljs-function\"\u003e\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title\"\u003eget_table_details\u003c/span\u003e():\u003c/span\u003e\n    \u003cspan class=\"hljs-comment\"\u003e# Read the CSV file into a DataFrame\u003c/span\u003e\n    table_description = pd.read_csv(\u003cspan class=\"hljs-string\"\u003e\"database_table_descriptions.csv\"\u003c/span\u003e)\n    table_docs = []\n\n    \u003cspan class=\"hljs-comment\"\u003e# Iterate over the DataFrame rows to create Document objects\u003c/span\u003e\n    table_details = \u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e index, row \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e table_description.iterrows():\n        table_details = table_details + \u003cspan class=\"hljs-string\"\u003e\"Table Name:\"\u003c/span\u003e + row[\u003cspan class=\"hljs-string\"\u003e'Table'\u003c/span\u003e] + \u003cspan class=\"hljs-string\"\u003e\"\\n\"\u003c/span\u003e + \u003cspan class=\"hljs-string\"\u003e\"Table Description:\"\u003c/span\u003e + row[\u003cspan class=\"hljs-string\"\u003e'Description'\u003c/span\u003e] + \u003cspan class=\"hljs-string\"\u003e\"\\n\\n\"\u003c/span\u003e\n\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e table_details\n\n\n\u003cspan class=\"hljs-class\"\u003e\u003cspan class=\"hljs-keyword\"\u003eclass\u003c/span\u003e \u003cspan class=\"hljs-title\"\u003eTable\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003eBaseModel\u003c/span\u003e):\u003c/span\u003e\n    \u003cspan class=\"hljs-string\"\u003e\"\"\"Table in SQL database.\"\"\"\u003c/span\u003e\n\n    name: str = Field(description=\u003cspan class=\"hljs-string\"\u003e\"Name of table in SQL database.\"\u003c/span\u003e)\n\n\u003cspan class=\"hljs-comment\"\u003e# table_names = \"\\n\".join(db.get_usable_table_names())\u003c/span\u003e\ntable_details = get_table_details()\nprint(table_details)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"lang-plaintext\"\u003eTable Name:productlines\nTable Description:Stores information about the differ....\n\nTable Name:products\nTable Description:Contains de....\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch4 id=\"heading-leveraging-smaller-focused-prompts-for-faster-execution\"\u003eLeveraging Smaller, Focused Prompts for Faster Execution\u003c/h4\u003e\n\u003cp\u003eDynamic relevant table selection hinges on the principle that \"less is more.\" By reducing the scope of information the model needs to consider for each query:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eImproved Model Performance\u003c/strong\u003e: Smaller prompts mean the model has fewer tokens to process, which translates to faster execution times. This is particularly crucial for interactive applications where response time is a key component of user satisfaction.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eEnhanced Accuracy\u003c/strong\u003e: Focusing on only the relevant tables minimizes the risk of generating incorrect SQL queries. This specificity ensures that the model's computational resources are dedicated to understanding and processing only the most pertinent data.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eCost-Efficiency\u003c/strong\u003e: Reducing the amount of prompt information also means fewer token usage costs. In the context of cloud-based NLP services, where processing costs can accumulate rapidly, this efficiency is not only a technical but also a financial advantage.\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003etable_details_prompt = \u003cspan class=\"hljs-string\"\u003ef\"\"\"Return the names of ALL the SQL tables that MIGHT be relevant to the user question. \\\nThe tables are:\n\n\u003cspan class=\"hljs-subst\"\u003e{table_details}\u003c/span\u003e\n\nRemember to include ALL POTENTIALLY RELEVANT tables, even if you're not sure that they're needed.\"\"\"\u003c/span\u003e\n\ntable_chain = create_extraction_chain_pydantic(Table, llm, system_message=table_details_prompt)\ntables = table_chain.invoke({\u003cspan class=\"hljs-string\"\u003e\"input\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"give me details of customer and their order count\"\u003c/span\u003e})\ntables\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"lang-plaintext\"\u003e[Table(name='customers'), Table(name='orders')]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e\u003cspan class=\"hljs-function\"\u003e\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title\"\u003eget_tables\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003etables: List[Table]\u003c/span\u003e) -\u0026gt; List[str]:\u003c/span\u003e\n    tables  = [table.name \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e table \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e tables]\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e tables\n\nselect_table = {\u003cspan class=\"hljs-string\"\u003e\"input\"\u003c/span\u003e: itemgetter(\u003cspan class=\"hljs-string\"\u003e\"question\"\u003c/span\u003e)} | create_extraction_chain_pydantic(Table, llm, system_message=table_details_prompt) | get_tables\nselect_table.invoke({\u003cspan class=\"hljs-string\"\u003e\"question\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"give me details of customer and their order count\"\u003c/span\u003e})\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"lang-plaintext\"\u003e['customers', 'orders']\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003echain = (\nRunnablePassthrough.assign(table_names_to_use=select_table) |\nRunnablePassthrough.assign(query=generate_query).assign(\n    result=itemgetter(\u003cspan class=\"hljs-string\"\u003e\"query\"\u003c/span\u003e) | execute_query\n)\n| rephrase_answer\n)\nchain.invoke({\u003cspan class=\"hljs-string\"\u003e\"question\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"How many cutomers with order count more than 5\"\u003c/span\u003e})\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"heading-enhancing-chatbots-with-memory-for-follow-up-database-queries\"\u003eEnhancing Chatbots with Memory for Follow-up Database Queries\u003c/h2\u003e\n\u003cp\u003eOne of the most advanced steps in creating a user-friendly NL2SQL interface is endowing your chatbot with memory. This feature enables the chatbot to handle follow-up questions related to the database intelligently, providing users with a seamless conversational experience. Let's explore how adding memory to your chatbot can revolutionize interactions with your database.\u003c/p\u003e\n\u003ch4 id=\"heading-the-significance-of-memory-in-chatbots\"\u003eThe Significance of Memory in Chatbots\u003c/h4\u003e\n\u003cp\u003eIn real-world conversations, context matters. A question might relate to or build upon previous interactions. Similarly, when users interact with a database through a chatbot, their follow-up questions often depend on the context established by earlier queries and responses. A chatbot equipped with memory can retain this context, allowing it to generate more accurate and relevant SQL queries for follow-up questions.\u003c/p\u003e\n\u003ch4 id=\"heading-implementing-memory-in-your-nl2sql-model\"\u003eImplementing Memory in Your NL2SQL Model\u003c/h4\u003e\n\u003cp\u003eTo equip your NL2SQL model with memory, consider incorporating a chat message history that tracks the conversation's flow. This history should include both the questions posed by the user and the chatbot's responses, enabling the model to reference previous interactions when generating SQL queries for new questions.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eSetting Up Message History\u003c/strong\u003e: Implement a mechanism to record each user query and the corresponding chatbot response. This can be achieved by defining a \u003ccode\u003eChatMessageHistory\u003c/code\u003e object that stores this information and can be accessed when needed\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e \u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e langchain.memory \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e ChatMessageHistory\n history = ChatMessageHistory()\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eLeveraging Previous Interactions\u003c/strong\u003e: Integrate this message history into your prompt generation process. Before generating a new SQL query, the model should consider the recorded history to understand the conversation's context\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e final_prompt = ChatPromptTemplate.from_messages(\n     [\n         (\u003cspan class=\"hljs-string\"\u003e\"system\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run. Unless otherwise specificed.\\n\\nHere is the relevant table info: {table_info}\\n\\nBelow are a number of examples of questions and their corresponding SQL queries. Those examples are just for referecne and hsould be considered while answering follow up questions\"\u003c/span\u003e),\n         few_shot_prompt,\n         MessagesPlaceholder(variable_name=\u003cspan class=\"hljs-string\"\u003e\"messages\"\u003c/span\u003e),\n         (\u003cspan class=\"hljs-string\"\u003e\"human\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"{input}\"\u003c/span\u003e),\n     ]\n )\n print(final_prompt.format(input=\u003cspan class=\"hljs-string\"\u003e\"How many products are there?\"\u003c/span\u003e,table_info=\u003cspan class=\"hljs-string\"\u003e\"some table info\"\u003c/span\u003e,messages=[]))\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003cstrong\u003eDynamic Prompt Adaptation\u003c/strong\u003e: Use the chat message history to dynamically adapt the prompts sent to the model for generating SQL queries. This adaptation should include information from previous queries and responses, guiding the model in understanding the context of the follow-up question\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e generate_query = create_sql_query_chain(llm, db,final_prompt)\n\n chain = (\n RunnablePassthrough.assign(table_names_to_use=select_table) |\n RunnablePassthrough.assign(query=generate_query).assign(\n     result=itemgetter(\u003cspan class=\"hljs-string\"\u003e\"query\"\u003c/span\u003e) | execute_query\n )\n | rephrase_answer\n )\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch4 id=\"heading-example-scenario-handling-follow-up-questions\"\u003eExample Scenario: Handling Follow-Up Questions\u003c/h4\u003e\n\u003cp\u003eImagine a user first asks, \"How many customers have an order count more than 5?\" After receiving the answer, they follow up with, \"Can you list their names?\" With a memory feature, the chatbot can understand that the second question relates to the subset of customers identified in response to the first question, allowing it to generate an accurate follow-up query without needing the user to re-specify the context.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003equestion = \u003cspan class=\"hljs-string\"\u003e\"How many cutomers with order count more than 5\"\u003c/span\u003e\nresponse = chain.invoke({\u003cspan class=\"hljs-string\"\u003e\"question\"\u003c/span\u003e: question,\u003cspan class=\"hljs-string\"\u003e\"messages\"\u003c/span\u003e:history.messages})\nThere are \u003cspan class=\"hljs-number\"\u003e2\u003c/span\u003e customers \u003cspan class=\"hljs-keyword\"\u003ewith\u003c/span\u003e an order count of more than \u003cspan class=\"hljs-number\"\u003e5.\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003ehistory.add_user_message(question)\nhistory.add_ai_message(response)\nhistory.messages\n[HumanMessage(content=\u003cspan class=\"hljs-string\"\u003e'How many cutomers with order count more than 5'\u003c/span\u003e),\n AIMessage(content=\u003cspan class=\"hljs-string\"\u003e'There are 2 customers with an order count of more than 5.'\u003c/span\u003e)]\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eresponse = chain.invoke({\u003cspan class=\"hljs-string\"\u003e\"question\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"Can you list there names?\"\u003c/span\u003e,\u003cspan class=\"hljs-string\"\u003e\"messages\"\u003c/span\u003e:history.messages})\nresponse\nThe names of the customers \u003cspan class=\"hljs-keyword\"\u003ewith\u003c/span\u003e more than \u003cspan class=\"hljs-number\"\u003e5\u003c/span\u003e orders are Mini Gifts Distributors Ltd. \u003cspan class=\"hljs-keyword\"\u003eand\u003c/span\u003e Euro+ Shopping Channel.\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"heading-conclusion\"\u003e\u003cstrong\u003eConclusion:\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eThrough this guide, we've journeyed through the process of enhancing NL2SQL models using LangChain, showcasing how to transform natural language queries into precise SQL commands. This exploration not only highlights the power of LangChain in making database queries more accessible but also underscores the broader impact of integrating advanced NLP techniques for intuitive data interaction.\u003c/p\u003e\n\u003cp\u003eFor those interested in delving deeper, a \u003ca target=\"_blank\" href=\"https://youtu.be/fss6CrmQU2Y\"\u003evideo walkthrough\u003c/a\u003e and a comprehensive \u003ca target=\"_blank\" href=\"https://github.com/PradipNichite/Youtube-Tutorials/blob/main/Langchain_NL2SQL_2024.ipynb\"\u003eGitHub notebook\u003c/a\u003e and \u003ca target=\"_blank\" href=\"https://github.com/PradipNichite/Youtube-Tutorials/tree/main/Langchain%20NL2SQL%20Chatbot\"\u003eStreamlit Code\u003c/a\u003e are available to explore these concepts further. These resources offer visual demonstrations and hands-on examples to help bring these ideas to life in your own projects.\u003c/p\u003e\n\u003cp\u003eThe journey toward more natural and efficient database interactions is ongoing, and with each step, we're making the world of data more accessible to all.\u003c/p\u003e\n\u003cp\u003eIf you're curious about the latest in AI technology, I invite you to visit my project, AI Demos, at \u003ca target=\"_blank\" href=\"http://aidemos.com/\"\u003e\u003cstrong\u003eaidemos.com\u003c/strong\u003e\u003c/a\u003e\u003cstrong\u003e. It's a rich resource offering a wide array of video demos showcasing the most advanced AI tools. My goal with AI Demos is to educate and illuminate the diverse possibilities of AI.\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eFor even more in-depth exploration, be sure to visit my YouTube channel at \u003ca target=\"_blank\" href=\"https://www.youtube.com/@aidemos.videos\"\u003ehttps://www.youtube.com/@aidemos.videos\u003c/a\u003e\u003cstrong\u003e. Here, you'll find a wealth of content that delves into the exciting future of AI and its various applications.\u003c/strong\u003e\u003c/p\u003e\n","markdown":"## Introduction\n\nWelcome to our deep dive into revolutionizing the way we interact with databases using Natural Language Processing (NLP) and LangChain. In today's data-driven world, the ability to query databases without needing to know complex SQL syntax opens up a myriad of possibilities across various industries, from healthcare to finance, making data more accessible to everyone.\n\nThis blog post aims to guide you through a comprehensive journey to master NL2SQL using LangChain. We will explore the steps necessary to build an intuitive, efficient, and intelligent NL2SQL model that can understand and process natural language queries, dynamically select relevant database tables, and maintain a conversational context to handle follow-up questions effectively.\n\nBy the end of this post, you'll have a solid understanding of:\n\n1. **Building a Basic NL2SQL Model**: The foundation of translating natural language queries into SQL commands.\n    \n2. **Incorporating Few-Shot Learning**: Enhancing model accuracy with examples.\n    \n3. **Dynamic Few-Shot Example Selection**: Tailoring examples to the query context for improved relevance.\n    \n4. **Dynamic Relevant Table Selection**: Automatically identifying which tables to query based on the natural language input.\n    \n5. **Customizing Prompts and Responses**: Fine-tuning the model's interaction to provide clear, concise, and relevant answers.\n    \n6. **Adding Memory to Chatbots**: Enabling the model to handle follow-up questions by remembering the context of the conversation.\n    \n\nThrough each of these steps, we'll discuss the concepts, show you how to implement them , and illustrate the outcomes , ensuring you have the tools and knowledge needed to bring the power of NL2SQL to your databases.\n\nLet's embark on this exciting journey to unlock the full potential of your data, making database queries as simple as conversing with a friend.\n\n## Building a Basic NL2SQL Model\n\nThe first step in our journey to revolutionize database querying with natural language is constructing a basic NL2SQL model using LangChain. This foundational model serves as the cornerstone for more advanced functionalities we'll explore later. Here's how we begin:\n\n#### Understanding the Basics\n\nAt its core, an NL2SQL model aims to translate natural language queries into SQL commands. But how do we start building such a model with LangChain?\n\n#### Setting Up LangChain\n\nLangChain simplifies the process of creating NL2SQL models by providing a flexible framework that integrates seamlessly with existing databases and natural language processing (NLP) models. To get started, you'll need to:\n\n1. **Install LangChain**: Ensure that LangChain is installed in your environment.\n    \n    ```bash\n    pip install langchain_openai langchain_community langchain pymysql chromadb -q\n    ```\n    \n2. **Connect to Your Database**: The next step involves establishing a connection to your database. LangChain supports various database systems, so you'll likely find your database among the supported ones. You'll use the database credentials to create a connection that LangChain can use to interact with your data\n    \n    ```python\n    import os\n    os.environ[\"OPENAI_API_KEY\"] = \"\"\n    \n    db_user = \"\"\n    db_password = \"\"\n    db_host = \"\"\n    db_name = \"classicmodels\"\n    from langchain_community.utilities.sql_database import SQLDatabase\n    # db = SQLDatabase.from_uri(f\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\",sample_rows_in_table_info=1,include_tables=['customers','orders'],custom_table_info={'customers':\"customer\"})\n    db = SQLDatabase.from_uri(f\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\")\n    print(db.dialect)\n    print(db.get_usable_table_names())\n    print(db.table_info)\n    ```\n    \n\n#### The First Query\n\nOnce the setup is complete, the real magic begins. You can start by formulating a simple query in natural language, such as \"Show me all products priced above $100.\" LangChain takes this input and, through its integration with language models like ChatGPT and your database, generates an SQL query that precisely captures the intent of your request\n\n```python\nfrom langchain.chains import create_sql_query_chain\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\ngenerate_query = create_sql_query_chain(llm, db)\nquery = generate_query.invoke({\"question\": \"what is price of `1968 Ford Mustang`\"})\n# \"what is price of `1968 Ford Mustang`\"\nprint(query)\n```\n\n#### Seeing the Results\n\nExecuting the generated SQL query against your database retrieves the data you're looking for, which LangChain can then present in a user-friendly format.\n\n```python\nfrom langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\nexecute_query = QuerySQLDataBaseTool(db=db)\nexecute_query.invoke(query)\n```\n\n#### Moving Forward\n\nWith the basic NL2SQL model set up, you've taken the first step towards transforming how we interact with databases. However, this is just the beginning. As we progress, we'll explore how to enhance the model's accuracy, handle more complex queries, and even maintain context over a conversation for follow-up questions.\n\n## Rephrasing Answers for Enhanced Clarity\n\nAfter your NL2SQL model successfully executes a SQL query, the next pivotal step is to present the data in a manner that's easily understandable by your users. This is where the art of rephrasing SQL results into clear, natural language answers comes into play. Here's how you can achieve this with LangChain:\n\n#### Implementing Rephrasing with LangChain\n\n1. **Use Prompt Templates**: LangChain allows you to create prompt templates that can guide the model in how to rephrase SQL results. These templates can include placeholders for the original question, the SQL query, and the query result, setting the stage for generating a natural language response\n    \n    ```python\n    from operator import itemgetter\n    \n    from langchain_core.output_parsers import StrOutputParser\n    from langchain_core.prompts import PromptTemplate\n    from langchain_core.runnables import RunnablePassthrough\n    \n    answer_prompt = PromptTemplate.from_template(\n        \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n    \n    Question: {question}\n    SQL Query: {query}\n    SQL Result: {result}\n    Answer: \"\"\"\n    )\n    \n    rephrase_answer = answer_prompt | llm | StrOutputParser()\n    \n    chain = (\n        RunnablePassthrough.assign(query=generate_query).assign(\n            result=itemgetter(\"query\") | execute_query\n        )\n        | rephrase_answer\n    )\n    \n    chain.invoke({\"question\": \"How many customers have an order count greater than 5\"})\n    ```\n    \n\n#### Example: Transforming SQL Results into User-Friendly Responses\n\nLet's consider a user asks, \"How many customers have an order count greater than 5?\" and the SQL query returns a raw numerical result. The rephrasing process would convert this into a more readable answer, such as \"There are 2 customers with an order count of more than 5.\" This step is vital in closing the loop between user queries and database responses, ensuring that the information provided is both useful and easily digestible\n\n```plaintext\nThere are 2 customers with an order count of more than 5.\n```\n\nIn the next section, we'll dive into the exciting world of few-shot learning and how it can be used to improve the performance of your NL2SQL model with LangChain. Stay tuned to unlock the full potential of natural language database querying.\n\n## Enhancing NL2SQL Models with Few-Shot Examples\n\nThis technique involves providing the model with a small set of carefully selected examples that demonstrate how to convert natural language questions into SQL queries. Few-shot learning can significantly improve the model's ability to understand and generate precise SQL commands based on user queries, bridging the gap between human language and database querying.\n\n#### Incorporating Few-Shot Examples into LangChain\n\n1. **Selecting Relevant Examples**: The first step is to curate a set of examples that cover a broad range of query types and complexities. These examples should ideally reflect the most common or critical queries your users might perform\n    \n    ```plaintext\n    examples = [\n        {\n            \"input\": \"List all customers in France with a credit limit over 20,000.\",\n            \"query\": \"SELECT * FROM customers WHERE country = 'France' AND creditLimit \u003e 20000;\"\n        },\n        {\n            \"input\": \"Get the highest payment amount made by any customer.\",\n            \"query\": \"SELECT MAX(amount) FROM payments;\"\n        },\n       .....\n    ]\n    ```\n    \n2. **Creating a Few-Shot Learning Template**: With LangChain, you can design a prompt template that incorporates these examples into the model's workflow. The template instructs the model to consider the examples when generating SQL queries from new user questions\n    \n    ```python\n    from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder,FewShotChatMessagePromptTemplate,PromptTemplate\n    \n    example_prompt = ChatPromptTemplate.from_messages(\n        [\n            (\"human\", \"{input}\\nSQLQuery:\"),\n            (\"ai\", \"{query}\"),\n        ]\n    )\n    few_shot_prompt = FewShotChatMessagePromptTemplate(\n        example_prompt=example_prompt,\n        examples=examples,\n        # input_variables=[\"input\",\"top_k\"],\n        input_variables=[\"input\"],\n    )\n    print(few_shot_prompt.format(input1=\"How many products are there?\"))\n    ```\n    \n    ```plaintext\n    Human: List all customers in France with a credit limit over 20,000.\n    SQLQuery:\n    AI: SELECT * FROM customers WHERE country = 'France' AND creditLimit \u003e 20000;\n    Human: Get the highest payment amount made by any customer.\n    SQLQuery:\n    AI: SELECT MAX(amount) FROM payments;\n    ......\n    ```\n    \n\n#### The Impact of Few-Shot Learning\n\nBy integrating few-shot examples, your NL2SQL model becomes more adept at handling a wider variety of user queries. This not only improves the user experience by providing more accurate and relevant responses but also reduces the potential for errors in SQL query generation.\n\nIn the next section, we'll explore the integration of dynamic example selection to further enhance the model's accuracy and relevance, ensuring that your NL2SQL system remains adaptive and responsive to user queries.\n\n## Dynamic Few-Shot Example Selection:\n\nThis advanced technique tailors the few-shot examples provided to the model based on the specific context of the user's query. It ensures that the guidance offered to the model is not just relevant but optimally aligned with the query's nuances, significantly boosting the model's ability to generate accurate SQL queries.\n\n#### The Need for Dynamism\n\nStatic few-shot examples, though highly effective, have their limitations. Dynamic selection addresses this by intelligently choosing examples that closely match the intent and context of each new query, providing a customized learning experience for the model with every interaction.\n\n#### Implementing Dynamic Few-Shot Selection\n\n1. **Example Selector Configuration**: Begin by setting up an example selector that can analyze the semantics of the user's query and compare it with a repository of potential examples. Tools like semantic similarity algorithms and vector embeddings come into play here, identifying which examples are most relevant to the current query\n    \n    ```python\n    from langchain_community.vectorstores import Chroma\n    from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n    from langchain_openai import OpenAIEmbeddings\n    \n    vectorstore = Chroma()\n    vectorstore.delete_collection()\n    example_selector = SemanticSimilarityExampleSelector.from_examples(\n        examples,\n        OpenAIEmbeddings(),\n        vectorstore,\n        k=2,\n        input_keys=[\"input\"],\n    )\n    example_selector.select_examples({\"input\": \"how many employees we have?\"})\n    few_shot_prompt = FewShotChatMessagePromptTemplate(\n        example_prompt=example_prompt,\n        example_selector=example_selector,\n        input_variables=[\"input\",\"top_k\"],\n    )\n    print(few_shot_prompt.format(input=\"How many products are there?\"))\n    ```\n    \n2. **Integrating with LangChain**: Integrate the example selector with your LangChain workflow. When a new query is received, the selector determines the most relevant few-shot examples before the model generates the SQL query. This ensures that the guidance provided to the model is tailored to the specific requirements of the query\n    \n    ```python\n    final_prompt = ChatPromptTemplate.from_messages(\n        [\n            (\"system\", \"You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run. Unless otherwise specificed.\\n\\nHere is the relevant table info: {table_info}\\n\\nBelow are a number of examples of questions and their corresponding SQL queries.\"),\n            few_shot_prompt,\n            (\"human\", \"{input}\"),\n        ]\n    )\n    print(final_prompt.format(input=\"How many products are there?\",table_info=\"some table info\"))\n    generate_query = create_sql_query_chain(llm, db,final_prompt)\n    chain = (\n    RunnablePassthrough.assign(query=generate_query).assign(\n        result=itemgetter(\"query\") | execute_query\n    )\n    | rephrase_answer\n    )\n    chain.invoke({\"question\": \"How many csutomers with credit limit more than 50000\"})\n    ```\n    \n    ```plaintext\n    There are 85 customers with a credit limit greater than 50000.\n    ```\n    \n\nBy ensuring that the examples used for guidance are always contextually relevant, the model can generate more precise SQL queries, reducing errors and improving user satisfaction. of NL2SQL technology, making data insights more accessible to everyone.\n\nIn the following section, we will explore the integration of dynamic relevant table selection, further advancing our NL2SQL model's capabilities to efficiently parse and respond to user queries.\n\n## Dynamic Relevant Table Selection\n\nIn the realm of NL2SQL models, especially when dealing with complex databases featuring 100+ tables. With databases growing in complexity and size, it's impractical and costly in terms of prompt token usage to include the schema of every table in the initial prompt for generating SQL queries. The sheer volume of information would overwhelm the model, leading to slower response times and increased computational costs. Dynamic relevant table selection emerges as a solution to this challenge, focusing the model's attention only on the tables pertinent to the user's query.\n\n```python\nfrom operator import itemgetter\nfrom langchain.chains.openai_tools import create_extraction_chain_pydantic\nfrom langchain_core.pydantic_v1 import BaseModel, Field\nfrom typing import List\nimport pandas as pd\n\ndef get_table_details():\n    # Read the CSV file into a DataFrame\n    table_description = pd.read_csv(\"database_table_descriptions.csv\")\n    table_docs = []\n\n    # Iterate over the DataFrame rows to create Document objects\n    table_details = \"\"\n    for index, row in table_description.iterrows():\n        table_details = table_details + \"Table Name:\" + row['Table'] + \"\\n\" + \"Table Description:\" + row['Description'] + \"\\n\\n\"\n\n    return table_details\n\n\nclass Table(BaseModel):\n    \"\"\"Table in SQL database.\"\"\"\n\n    name: str = Field(description=\"Name of table in SQL database.\")\n\n# table_names = \"\\n\".join(db.get_usable_table_names())\ntable_details = get_table_details()\nprint(table_details)\n```\n\n```plaintext\nTable Name:productlines\nTable Description:Stores information about the differ....\n\nTable Name:products\nTable Description:Contains de....\n```\n\n#### Leveraging Smaller, Focused Prompts for Faster Execution\n\nDynamic relevant table selection hinges on the principle that \"less is more.\" By reducing the scope of information the model needs to consider for each query:\n\n1. **Improved Model Performance**: Smaller prompts mean the model has fewer tokens to process, which translates to faster execution times. This is particularly crucial for interactive applications where response time is a key component of user satisfaction.\n    \n2. **Enhanced Accuracy**: Focusing on only the relevant tables minimizes the risk of generating incorrect SQL queries. This specificity ensures that the model's computational resources are dedicated to understanding and processing only the most pertinent data.\n    \n3. **Cost-Efficiency**: Reducing the amount of prompt information also means fewer token usage costs. In the context of cloud-based NLP services, where processing costs can accumulate rapidly, this efficiency is not only a technical but also a financial advantage.\n    \n\n```python\ntable_details_prompt = f\"\"\"Return the names of ALL the SQL tables that MIGHT be relevant to the user question. \\\nThe tables are:\n\n{table_details}\n\nRemember to include ALL POTENTIALLY RELEVANT tables, even if you're not sure that they're needed.\"\"\"\n\ntable_chain = create_extraction_chain_pydantic(Table, llm, system_message=table_details_prompt)\ntables = table_chain.invoke({\"input\": \"give me details of customer and their order count\"})\ntables\n```\n\n```plaintext\n[Table(name='customers'), Table(name='orders')]\n```\n\n```python\ndef get_tables(tables: List[Table]) -\u003e List[str]:\n    tables  = [table.name for table in tables]\n    return tables\n\nselect_table = {\"input\": itemgetter(\"question\")} | create_extraction_chain_pydantic(Table, llm, system_message=table_details_prompt) | get_tables\nselect_table.invoke({\"question\": \"give me details of customer and their order count\"})\n```\n\n```plaintext\n['customers', 'orders']\n```\n\n```python\nchain = (\nRunnablePassthrough.assign(table_names_to_use=select_table) |\nRunnablePassthrough.assign(query=generate_query).assign(\n    result=itemgetter(\"query\") | execute_query\n)\n| rephrase_answer\n)\nchain.invoke({\"question\": \"How many cutomers with order count more than 5\"})\n```\n\n## Enhancing Chatbots with Memory for Follow-up Database Queries\n\nOne of the most advanced steps in creating a user-friendly NL2SQL interface is endowing your chatbot with memory. This feature enables the chatbot to handle follow-up questions related to the database intelligently, providing users with a seamless conversational experience. Let's explore how adding memory to your chatbot can revolutionize interactions with your database.\n\n#### The Significance of Memory in Chatbots\n\nIn real-world conversations, context matters. A question might relate to or build upon previous interactions. Similarly, when users interact with a database through a chatbot, their follow-up questions often depend on the context established by earlier queries and responses. A chatbot equipped with memory can retain this context, allowing it to generate more accurate and relevant SQL queries for follow-up questions.\n\n#### Implementing Memory in Your NL2SQL Model\n\nTo equip your NL2SQL model with memory, consider incorporating a chat message history that tracks the conversation's flow. This history should include both the questions posed by the user and the chatbot's responses, enabling the model to reference previous interactions when generating SQL queries for new questions.\n\n1. **Setting Up Message History**: Implement a mechanism to record each user query and the corresponding chatbot response. This can be achieved by defining a `ChatMessageHistory` object that stores this information and can be accessed when needed\n    \n    ```python\n    from langchain.memory import ChatMessageHistory\n    history = ChatMessageHistory()\n    ```\n    \n2. **Leveraging Previous Interactions**: Integrate this message history into your prompt generation process. Before generating a new SQL query, the model should consider the recorded history to understand the conversation's context\n    \n    ```python\n    final_prompt = ChatPromptTemplate.from_messages(\n        [\n            (\"system\", \"You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run. Unless otherwise specificed.\\n\\nHere is the relevant table info: {table_info}\\n\\nBelow are a number of examples of questions and their corresponding SQL queries. Those examples are just for referecne and hsould be considered while answering follow up questions\"),\n            few_shot_prompt,\n            MessagesPlaceholder(variable_name=\"messages\"),\n            (\"human\", \"{input}\"),\n        ]\n    )\n    print(final_prompt.format(input=\"How many products are there?\",table_info=\"some table info\",messages=[]))\n    ```\n    \n3. **Dynamic Prompt Adaptation**: Use the chat message history to dynamically adapt the prompts sent to the model for generating SQL queries. This adaptation should include information from previous queries and responses, guiding the model in understanding the context of the follow-up question\n    \n    ```python\n    generate_query = create_sql_query_chain(llm, db,final_prompt)\n    \n    chain = (\n    RunnablePassthrough.assign(table_names_to_use=select_table) |\n    RunnablePassthrough.assign(query=generate_query).assign(\n        result=itemgetter(\"query\") | execute_query\n    )\n    | rephrase_answer\n    )\n    ```\n    \n\n#### Example Scenario: Handling Follow-Up Questions\n\nImagine a user first asks, \"How many customers have an order count more than 5?\" After receiving the answer, they follow up with, \"Can you list their names?\" With a memory feature, the chatbot can understand that the second question relates to the subset of customers identified in response to the first question, allowing it to generate an accurate follow-up query without needing the user to re-specify the context.\n\n```python\nquestion = \"How many cutomers with order count more than 5\"\nresponse = chain.invoke({\"question\": question,\"messages\":history.messages})\nThere are 2 customers with an order count of more than 5.\n```\n\n```python\nhistory.add_user_message(question)\nhistory.add_ai_message(response)\nhistory.messages\n[HumanMessage(content='How many cutomers with order count more than 5'),\n AIMessage(content='There are 2 customers with an order count of more than 5.')]\n```\n\n```python\nresponse = chain.invoke({\"question\": \"Can you list there names?\",\"messages\":history.messages})\nresponse\nThe names of the customers with more than 5 orders are Mini Gifts Distributors Ltd. and Euro+ Shopping Channel.\n```\n\n## **Conclusion:**\n\nThrough this guide, we've journeyed through the process of enhancing NL2SQL models using LangChain, showcasing how to transform natural language queries into precise SQL commands. This exploration not only highlights the power of LangChain in making database queries more accessible but also underscores the broader impact of integrating advanced NLP techniques for intuitive data interaction.\n\nFor those interested in delving deeper, a [video walkthrough](https://youtu.be/fss6CrmQU2Y) and a comprehensive [GitHub notebook](https://github.com/PradipNichite/Youtube-Tutorials/blob/main/Langchain_NL2SQL_2024.ipynb) and [Streamlit Code](https://github.com/PradipNichite/Youtube-Tutorials/tree/main/Langchain%20NL2SQL%20Chatbot) are available to explore these concepts further. These resources offer visual demonstrations and hands-on examples to help bring these ideas to life in your own projects.\n\nThe journey toward more natural and efficient database interactions is ongoing, and with each step, we're making the world of data more accessible to all.\n\nIf you're curious about the latest in AI technology, I invite you to visit my project, AI Demos, at [**aidemos.com**](http://aidemos.com/)**. It's a rich resource offering a wide array of video demos showcasing the most advanced AI tools. My goal with AI Demos is to educate and illuminate the diverse possibilities of AI.**\n\nFor even more in-depth exploration, be sure to visit my YouTube channel at [https://www.youtube.com/@aidemos.videos](https://www.youtube.com/@aidemos.videos)**. Here, you'll find a wealth of content that delves into the exciting future of AI and its various applications.**"},"views":39122,"preferences":{"pinnedToBlog":false,"disableComments":false,"stickCoverToBottom":false,"isDelisted":false},"readTimeInMinutes":14,"series":null,"tags":[{"id":"63f859c05e428f179a5cf8f3","slug":"langchain","name":"langchain"},{"id":"63fef3fddc65a8ca9c1e0b0d","slug":"nl2sql","name":"NL2SQL"},{"id":"635ad52efe8087002dee4707","slug":"llm","name":"llm"},{"id":"642f259f311bf43ae82a8390","slug":"text-to-sql","name":"text to sql"},{"id":"5f1a7b4309e95d4d18c3b2ee","slug":"openai","name":"openai"},{"id":"638891761e50d717cbfd7b5b","slug":"chatgpt","name":"chatgpt"}],"ogMetaData":{"image":null},"canonicalUrl":null,"hasLatexInPost":false,"audioUrls":null,"isFollowed":null,"bookmarked":false,"features":{"tableOfContents":{"isEnabled":true,"items":[{"__typename":"TableOfContentsItem","id":"6a4b64cc-4dc7-498c-babd-f79152ec0916","level":2,"slug":"introduction","title":"Introduction","parentId":null},{"__typename":"TableOfContentsItem","id":"89f6377b-515f-410a-b612-3b1926dd7e4a","level":2,"slug":"building-a-basic-nl2sql-model","title":"Building a Basic NL2SQL Model","parentId":null},{"__typename":"TableOfContentsItem","id":"bb4ff478-b5bb-4962-9895-16c826212a1b","level":4,"slug":"understanding-the-basics","title":"Understanding the Basics","parentId":"89f6377b-515f-410a-b612-3b1926dd7e4a"},{"__typename":"TableOfContentsItem","id":"ea22420b-75d2-492c-9394-425d5309cb14","level":4,"slug":"setting-up-langchain","title":"Setting Up LangChain","parentId":"89f6377b-515f-410a-b612-3b1926dd7e4a"},{"__typename":"TableOfContentsItem","id":"622473cc-a30e-490d-a5a6-055c1bb8156f","level":4,"slug":"the-first-query","title":"The First Query","parentId":"89f6377b-515f-410a-b612-3b1926dd7e4a"},{"__typename":"TableOfContentsItem","id":"6163595a-a60a-492a-acc2-8301e380bb3a","level":4,"slug":"seeing-the-results","title":"Seeing the Results","parentId":"89f6377b-515f-410a-b612-3b1926dd7e4a"},{"__typename":"TableOfContentsItem","id":"3ab1b020-4a7e-49e8-b8b9-8327280d5c38","level":4,"slug":"moving-forward","title":"Moving Forward","parentId":"89f6377b-515f-410a-b612-3b1926dd7e4a"},{"__typename":"TableOfContentsItem","id":"23abf3fc-5dce-4913-bd2e-6f4deefc4c80","level":2,"slug":"rephrasing-answers-for-enhanced-clarity","title":"Rephrasing Answers for Enhanced Clarity","parentId":null},{"__typename":"TableOfContentsItem","id":"2723367f-11b2-4b0b-8f80-ac78795c0455","level":4,"slug":"implementing-rephrasing-with-langchain","title":"Implementing Rephrasing with LangChain","parentId":"23abf3fc-5dce-4913-bd2e-6f4deefc4c80"},{"__typename":"TableOfContentsItem","id":"723b6b1a-9890-423f-9e23-39705a3d3a0b","level":4,"slug":"example-transforming-sql-results-into-user-friendly-responses","title":"Example: Transforming SQL Results into User-Friendly Responses","parentId":"23abf3fc-5dce-4913-bd2e-6f4deefc4c80"},{"__typename":"TableOfContentsItem","id":"6c7b4aff-61de-4eef-92f6-0d3509afb5f7","level":2,"slug":"enhancing-nl2sql-models-with-few-shot-examples","title":"Enhancing NL2SQL Models with Few-Shot Examples","parentId":null},{"__typename":"TableOfContentsItem","id":"29b8ba8c-a202-42aa-bc3a-079048290ff2","level":4,"slug":"incorporating-few-shot-examples-into-langchain","title":"Incorporating Few-Shot Examples into LangChain","parentId":"6c7b4aff-61de-4eef-92f6-0d3509afb5f7"},{"__typename":"TableOfContentsItem","id":"48bfcd04-66ab-4ee5-b177-1a75ad1c7e4d","level":4,"slug":"the-impact-of-few-shot-learning","title":"The Impact of Few-Shot Learning","parentId":"6c7b4aff-61de-4eef-92f6-0d3509afb5f7"},{"__typename":"TableOfContentsItem","id":"145d30b6-096f-405f-a44c-c86b4279f723","level":2,"slug":"dynamic-few-shot-example-selection","title":"Dynamic Few-Shot Example Selection:","parentId":null},{"__typename":"TableOfContentsItem","id":"29c4be64-f1b4-4156-abc1-41e406f9bc47","level":4,"slug":"the-need-for-dynamism","title":"The Need for Dynamism","parentId":"145d30b6-096f-405f-a44c-c86b4279f723"},{"__typename":"TableOfContentsItem","id":"7f2d3a9d-cdba-4667-8813-116b0f92f119","level":4,"slug":"implementing-dynamic-few-shot-selection","title":"Implementing Dynamic Few-Shot Selection","parentId":"145d30b6-096f-405f-a44c-c86b4279f723"},{"__typename":"TableOfContentsItem","id":"8d8fc6ef-2108-4a4f-af9f-80f72789047a","level":2,"slug":"dynamic-relevant-table-selection","title":"Dynamic Relevant Table Selection","parentId":null},{"__typename":"TableOfContentsItem","id":"6b7f41f4-1020-416a-b891-50a1373b6a91","level":4,"slug":"leveraging-smaller-focused-prompts-for-faster-execution","title":"Leveraging Smaller, Focused Prompts for Faster Execution","parentId":"8d8fc6ef-2108-4a4f-af9f-80f72789047a"},{"__typename":"TableOfContentsItem","id":"0039f550-0787-4861-9971-1cd12bc7f576","level":2,"slug":"enhancing-chatbots-with-memory-for-follow-up-database-queries","title":"Enhancing Chatbots with Memory for Follow-up Database Queries","parentId":null},{"__typename":"TableOfContentsItem","id":"633b8ee7-b47b-4fa2-b05b-e3ab6e26626a","level":4,"slug":"the-significance-of-memory-in-chatbots","title":"The Significance of Memory in Chatbots","parentId":"0039f550-0787-4861-9971-1cd12bc7f576"},{"__typename":"TableOfContentsItem","id":"c24d59b1-7af7-4601-8f48-0c67f3210e3b","level":4,"slug":"implementing-memory-in-your-nl2sql-model","title":"Implementing Memory in Your NL2SQL Model","parentId":"0039f550-0787-4861-9971-1cd12bc7f576"},{"__typename":"TableOfContentsItem","id":"4323aad8-b5b2-4ade-9d71-61fdcdc71b2f","level":4,"slug":"example-scenario-handling-follow-up-questions","title":"Example Scenario: Handling Follow-Up Questions","parentId":"0039f550-0787-4861-9971-1cd12bc7f576"},{"__typename":"TableOfContentsItem","id":"b7148ae5-6032-4ffd-bd89-102a74b799a5","level":2,"slug":"conclusion","title":"Conclusion:","parentId":null}]},"badges":{"isEnabled":true,"items":[]}},"isAutoPublishedFromRSS":false,"authenticatedUserLikes":{"edges":[]},"totalUserLikes":{"totalDocuments":17},"isShadowBanned":false,"isAskMeAnything":false},"redirectedPost":null,"staticPage":null},"series":null}},"__N_SSP":true},"page":"/[...slug]","query":{"x-host":"blog.futuresmart.ai","slug":["mastering-natural-language-to-sql-with-langchain-nl2sql"]},"buildId":"Q0O1Km9pEjq-uqsmUGqXF","isFallback":false,"dynamicIds":[87179],"gssp":true,"scriptLoader":[]}</script><div id="hn-modal"></div><div id="hn-toast"></div><next-route-announcer><p aria-live="assertive" id="__next-route-announcer__" role="alert" style="border: 0px; clip: rect(0px, 0px, 0px, 0px); height: 1px; margin: -1px; overflow: hidden; padding: 0px; position: absolute; top: 0px; width: 1px; white-space: nowrap; overflow-wrap: normal;"></p></next-route-announcer><script src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/5772-330b7829e95060dd.js.download"></script><script src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/4960-b70b6f04f379686e.js.download"></script><iframe allow="join-ad-interest-group" data-tagging-id="AW-344963816" data-load-time="1740811077277" height="0" width="0" src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/344963816.html" style="display: none; visibility: hidden;"></iframe><iframe height="0" width="0" style="display: none; visibility: hidden;" src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/saved_resource.html"></iframe><script src="./Mastering Natural Language to SQL with LangChain _ NL2SQL_files/index-77bcfcca4712573b.js.download"></script></body></html>